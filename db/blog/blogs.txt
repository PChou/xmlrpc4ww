id#filename#content#title#layout#description#thumbimg#categories#tags#createdate#moddate#
inc#str#str#str#str#str#str#str#str#str#str#
1#filename#content#title#layout#description#thumbimg#categories#tags#createdate#moddate#
4#2013-10-23-526712a543031.html#<h1>缘起</h1> <p>在之前的文章<a href="http://pchou.info/web-build/2013/01/20/build-github-blog-page-07.html">一步步在GitHub上创建博客主页(7)--兼容Windows Writer的服务提供器</a>中，为了使编写博客和发布博客更加方便，我实现了一个windows writer的服务提供器，基于.NET和XML-RPC.NET。在实际使用过程中其实遇到不少问题，比如文章的二次编辑修改将无法支持，多个windows writer客户端无法同步编辑，提供器部署复杂等。思考下来觉得还是得有数据库支持，而且要尽可能的方便部署和同步数据。于是决定用PHP重新实现一个，PHP有以下特点：</p> <ul> <li>轻巧，部署方便  <li>能够轻便的支持基于文本的数据库，可以实现多客户端“分布式编辑”</li></ul> <p>&nbsp;</p> <h1>系统运作方式</h1> <p>假设用户现在只有一台PC1用来写blog，系统运行机制如下：</p> <p><img style="background-image: none; border-right-width: 0px; padding-left: 0px; padding-right: 0px; display: inline; border-top-width: 0px; border-bottom-width: 0px; border-left-width: 0px; padding-top: 0px" class="img-responsive" title="image" border="0" alt="image" src="http://fakelocalhost/assert/img/2013-10-23-5267cbc7d3656.png" width="313" height="440"></p> <ol> <li>在PC1上克隆好了github page的项目  <li>用户在PC1上部署一个PHP站点，并配置指向上面的github page的项目目录  <li>在PC1上使用windows writer配置这个站点为日志帐户  <li>在PC1上使用windows writer编写文章  <li>在PC1上将文章发布到PHP站点  <li>打开PHP站点的页面，修改分类、标签等必要信息，点击发布，PHP站点将把文章创建在github page的项目目录的对应文件夹中（包括图片）  <li>（可选）用jekyll测试页面，返回4，直到满意  <li>在PC1上使用git将github page的项目push到github</li></ol> <p>图中黄色的2、3步骤是一次性的配置工作，以后不需要重复进行。另外可以看到这里的PHP站点起到了“代理”的作用，因为github不能支持windows writer嘛，所以只能依靠代理了；而且这个代理是在你PC本机的，链接你的Writer和本地的仓库。</p> <p>&nbsp;</p> <p>如果你在家中和公司各有一台PC，可能希望在两台PC上都能编写博客，甚至发布博客，而这个代理是本机的，如何能实现在博客正式发布前”共享“呢？答案是文本数据库。来看多客户端情况下的工作机制（左边是之前的PC1）：</p> <p><img style="background-image: none; border-right-width: 0px; padding-left: 0px; padding-right: 0px; display: inline; border-top-width: 0px; border-bottom-width: 0px; border-left-width: 0px; padding-top: 0px" class="img-responsive" title="image" border="0" alt="image" src="http://fakelocalhost/assert/img/2013-10-23-5267ce0633ef9.png" width="545" height="426"></p> <ul style="list-style-type: none"> <li>1.这个PHP站点包含一个基于文本的数据库，用来存放每一篇发布到PHP站点的文章。<font color="%hff0000">并将这个PHP站点本身作为一个仓库推送到github</font>  <li>2.在另一台PC2上克隆或拉取仓库代码（包括文本数据库）  <li>3～5步跟上面的1～3相同，克隆或拉取github page所在仓库，配置PHP站点，配置writer  <li>6.利用writer的”打开远程文章“的功能，从PHP站点上得到文章标题、内容等  <li>7.继续编辑文章  <li>8.将文章发布到PHP站点  <li>9.打开PHP站点的页面，修改分类、标签等必要信息，点击发布，PHP站点将把文章创建在github page的项目目录的对应文件夹中（包括图片）  <li>10.（可选）用jekyll测试页面，返回7，直到满意  <li>11.在PC2上使用git将github page的项目push到github</li></ul> <p>&nbsp;</p> <p>通过上面的步骤可以继续编辑文章，达到共享的目的。起作用的关键其实是，PHP站点利用文本数据库和站点本身作为仓库这两点，保存了在PC1上的文章内容，可供PC2克隆或拉取。同理，也可以将PC2的PHP站点（及其数据文件）推送到github上，供PC1继续编辑发布。</p> <p>&nbsp;</p> <p>本文介绍了系统的工作机制。虽说有了这套东西，写博客会方便不少，但是操作还是比较琐碎的，因此需要对工作机制有比较清晰的了解，这对于用户来说是十分重要的。下一篇将指导用户具体操作过程。</p>#基于PHP的Windows Writer服务提供器--介绍#postlayout#介绍一个支持Windows Writer的PHP服务的实现和运行机制，有了这个PHP服务，用Writer来编写博客，插入图片就简单方便许多了。#1346208288725.jpg#[web-build]#[PHP,github-page]#2013-10-23 08:04:53#2013-10-27 22:01:24#
5#2013-10-23-5267e1c65917c.html#<p>在<a href="http://pchou.info/web-build/2013/10/23/526712a543031.html" target="_blank">上一篇</a>中介绍了系统的运行机制，本文将引导读者一步步部署并使用。首先，假设您已经完成了github博客的搭建工作，并理解基本的博客维护方式以及jekyll的基本原理和使用方法。</p> <p>&nbsp;</p> <h2>部署本地的PHP站点</h2> <p>PHP项目的主页地址：<a href="https://github.com/PChou/xmlrpc4ww">https://github.com/PChou/xmlrpc4ww</a></p> <p>用您自己的帐户登录github，在浏览器中键入上述地址，点击页面右上方的<code>Fork</code>。Fork的意思是将这个项目复制到您自己的代码仓库中，您就可以自由的修改编辑了，还能在需要的时候对原代码仓库贡献代码，或者同步原代码仓库的变化。</p> <p>将Fork出来的仓库clone到本地,，这地址应该像下面这样：</p><pre>git clone https://github.com/<em>{yourusername}</em>/xmlrpc4ww.git</pre>%n<p>项目目录中的文件结构如下（省略无关紧要的文件）</p><pre>/xmlrpc4ww%n  |--content //存放js和css%n  |--db%n      |--blog	//文本数据库%n           |--__blogs.txt //数据文件模板%n           |--blogs.txt	//数据文件%n  |--txtdb	//文本数据库支持库%n  |--xmlrpc	//xmlrpc api支持库%n  |--__config.php   //配置文件模板%n  |--post.php       //文章发布页面%n  |--postlist.php   //文章列表页面%n  |--server.php     //writer服务提供页面和文章列表入口%n  |--util2.php      //支持方法%n</pre>%n<p>将__config.php在同一目录复制一份，取名为<code>config.php</code>，修改config.php：</p><pre>define("LOCALPATH", "D:\\Project\\Git\\NRemedy");    \\本地github page项目所在目录，注意双斜杠%ndefine("IMGPATH", "assert\\img");		     \\图片的相对路径，此处就表示我的博客的图片规划在D:\Project\Git\NRemedy\assert\img下，注意双斜杠%ndefine("IMGPATH2", "/assert/img/");		     \\图片的url相对路径，与上面应对应，但注意斜杠的方向%n%ndefine("DEFAULT_LAYOUT", "postlayout");		      \\每个post的jekyll模板使用的默认的layout名称，配置这个后可以简化将来发布填写的东西%n%ndefine("BLOGNAME", "ghpage");			     \\blog名称，可以不作修改%ndefine("BLOGID","67322");			     \\blogid，可以不作修改%ndefine("BLOGURL","http://fakelocalhost");            \\blog地址，不要修改，保持fakelocalhost%n%n%n</pre>%n<p><font color="%hff0000">注意：上面的前三项务必配置准确，否则将无法正常使用</font></p>%n<p>删除<code>db/blog/blogs.txt</code>，将<code>__blogs.txt</code>重命名为<code>blogs.txt</code>。原先的blogs.txt是我的文章数据库，您需要的是空的数据库文件，所以从__blogs.txt这个空的数据文件模板开始，完成之后您的目录结构将是这样：</p><pre>/xmlrpc4ww%n  |--content //存放js和css%n  |--db%n      |--blogs	//文本数据库%n           |--blogs.txt	//空数据文件%n  |--txtdb	//文本数据库支持库%n  |--xmlrpc	//xmlrpc api支持库%n  |--config.php     //配置文件模板%n  |--post.php       //文章发布页面%n  |--postlist.php   //文章列表页面%n  |--server.php     //writer服务提供页面和文章列表入口%n  |--util2.php      //支持方法%n</pre>%n<p>接下来要做的是配置一个php运行环境，如果您已经配置过php环境，那么恭喜你，可以跳过这个步骤了。下载并安装php环境，读者可参考<a href="http://www.cnblogs.com/zengxiangzhan/archive/2010/03/05/1679286.html">http://www.cnblogs.com/zengxiangzhan/archive/2010/03/05/1679286.html</a></p>%n<p>&nbsp;</p>%n<p>在IIS中创建一个站点，指向xmlrpc4ww，启动该网站，并用浏览器访问<a href="http://localhost{:port}/server.php">http://localhost<em>{:port}</em>/server.php</a>，看到如下页面说明php站点部署完毕（请注意，您的端口可能与我不同）</p>%n<p><img style="background-image: none; border-right-width: 0px; padding-left: 0px; padding-right: 0px; display: inline; border-top-width: 0px; border-bottom-width: 0px; border-left-width: 0px; padding-top: 0px" class="img-responsive" title="559EHMUA36]Z76X}}OP0V`L" border="0" alt="559EHMUA36]Z76X}}OP0V`L" src="http://fakelocalhost/assert/img/2013-10-23-5267e1c64ed6a.jpeg" width="638" height="28"> %n<p>&nbsp;</p>%n<h2>配置Windows Writer</h2>%n<p>点击“添加日志帐户”，选择“其他服务”</p><img style="display: inline" class="img-responsive" title="image" alt="image" src="http://fakelocalhost/assert/img/2013-01-20-build-github-blog-page-07-img1.png" width="403" height="379"> %n<p>按照下图输入日志网址，注意，你本机的PHP站点的端口可能与我不同，用户名和密码随便填，无所谓，暂时不要记住密码</p>%n<p><img style="background-image: none; border-right-width: 0px; padding-left: 0px; padding-right: 0px; display: inline; border-top-width: 0px; border-bottom-width: 0px; border-left-width: 0px; padding-top: 0px" class="img-responsive" title="image" border="0" alt="image" src="http://fakelocalhost/assert/img/2013-10-24-52692c3153e36.png" width="398" height="375"></p>%n<p>点击“下一步”，按下图填写，注意这里的远程发布网址是关键点，必须填写正确，还是一样，请注意您本机的端口可能与我不同</p>%n<p><img style="background-image: none; border-right-width: 0px; padding-left: 0px; padding-right: 0px; display: inline; border-top-width: 0px; border-bottom-width: 0px; border-left-width: 0px; padding-top: 0px" class="img-responsive" title="image" border="0" alt="image" src="http://fakelocalhost/assert/img/2013-10-24-52692c315bb38.png" width="402" height="379"></p>%n<p>点击“下一步”，windows writer会开始检测服务端设置</p>%n<p><img style="background-image: none; border-right-width: 0px; padding-left: 0px; padding-right: 0px; display: inline; border-top-width: 0px; border-bottom-width: 0px; border-left-width: 0px; padding-top: 0px" class="img-responsive" title="image" border="0" alt="image" src="http://fakelocalhost/assert/img/2013-10-24-52692c3165392.png" width="403" height="380"></p>%n<p>最后会成功提示如下，可以点击Yes，发布一个测试日志，如下图。至此Writer和PHP站点打通了</p>%n<p><img style="background-image: none; border-right-width: 0px; padding-left: 0px; padding-right: 0px; display: inline; border-top-width: 0px; border-bottom-width: 0px; border-left-width: 0px; padding-top: 0px" class="img-responsive" title="image" border="0" alt="image" src="http://fakelocalhost/assert/img/2013-10-24-52692c316efd4.png" width="419" height="179"></p>%n<p>将来发布日志的时候请选择ghpage发布</p>%n<p><img style="background-image: none; border-right-width: 0px; padding-left: 0px; padding-right: 0px; display: inline; border-top-width: 0px; border-bottom-width: 0px; border-left-width: 0px; padding-top: 0px" class="img-responsive" title="image" border="0" alt="image" src="http://fakelocalhost/assert/img/2013-10-24-52692c317594e.png" width="220" height="84"> %n<p>&nbsp;</p>%n<h2>将日志发布到本地的gh-page</h2>%n<p>用浏览器访问<a href="http://localhost{:port}/server.php">http://localhost<em>{:port}</em>/server.php</a>，应该看到多出一条记录，这条记录就是刚刚发布的临时日志。点击“编辑和发布”，显示类似下面的页面</p>%n<p><img style="background-image: none; border-right-width: 0px; padding-left: 0px; padding-right: 0px; display: inline; border-top-width: 0px; border-bottom-width: 0px; border-left-width: 0px; padding-top: 0px" class="img-responsive" title="JWAF752I~RH(OCJT5(`P`NT" border="0" alt="JWAF752I~RH(OCJT5(`P`NT" src="http://fakelocalhost/assert/img/2013-10-24-52692c317c2c7.jpeg" width="295" height="267"> %n<p>我们知道基于jekyll的post都应该有如下开头： <pre>---%nlayout: postlayout%ntitle: Hello GitHub!%ndescription: 该博客的开篇之文%nthumbimg: 1346208288725.jpg%ncategories: [life]%ntags: [github-page, jekyll]%n---%n</pre>%n<p>其中layout、title、categories、tags是jekyll默认支持的变量， 而且categories和tags有特定的格式。用户也可以自定义变量，可以在jekyll的post对象中获得这些变量。上面的description和thumnimg都是我自定义的变量，分别用于显示摘要和首页缩略图。 %n<p>与之对应的，上面的页面就是用来配置这些变量的。 %n<ul>%n<li>文件名是自动生成的，如果要修改的话请保持jekyll的日期规则，而且点击“保存并生成”后尽量不要再修改，否则，会生成两个日志； %n<li>标题来源于Writer中的标题，不能修改，只能由Writer发布上来； %n<li>layout的默认值来源与上面对PHP部署时的基础配置，应该修改成你希望的layout文件名； %n<li>分类和标签，请自行添加，但要符合jekyll规则</li></ul>%n<blockquote>%n<p>如果您的变量与我不同的话，需要自己修改php代码和数据库文件来支持。如果您希望修改的话，请将你fork的仓库地址发在下面的留言板里面，我可能考虑帮你修改。当然也许将来的版本我会发布一个可配置的版本</p></blockquote>%n<p>配置完成后，点击“保存并生成”，如果显示“成功”的话，恭喜您，文章已经在您本地的git仓库中拉。</p>%n<p>接下来您可以用本地的jekyll测试和发布你刚刚发布的文章，具体可以参考<a href="http://pchou.info/web-build/2013/01/05/build-github-blog-page-04.html">一步步在GitHub上创建博客主页(4)</a>以及相关的系列文章 %n<p>让我们来查看一下/xmlprc4ww/db/blogs.txt，此时，该文件应该已经包含了刚刚发布的日志以及post变量的配置等。顺便说一下，这个文件就是blogs的数据库文件，将来Writer从PHP站点获取或者写入的日志内容都将存放在这个文件中。 该文件除了前三行外，其他行都是数据，每一行由多个字段组成，每个字段用”%h“区隔，详见：<a href="http://www.c-worker.ch/txtdbapi/index.php">http://www.c-worker.ch/txtdbapi/index.php</a>&nbsp; <h2>&nbsp;</h2>%n<h2>编辑修改文章 </h2>%n<p>如果您的文章已经从Writer发布到PHP站点，甚至是发布到了github，但是此时需要修改一下，怎么办呢？很简单，您只需要在Writer中打开需要修改的文章，编辑好之后，点击发布，循环上面的步骤就可以了。 %n<blockquote>%n<p>您可能会发现再次打开后图片无法正常显示，这没关系，如果这导致Writer崩溃的话，请下载最新的Writer客户端；另外如果文章有图片的话在发布前请将图片“格式”设置成“链接至无”，否则会有两张图片上传到服务端</p></blockquote>%n<p>如果您只是用上面配置好的机器来编写博客的话，至此就足够了，下面介绍多客户端该怎么协同编辑。 %n<p>&nbsp; <h2>多客户端编辑</h2>%n<p>也许读者已经猜到了，没错，只要将xmlrpc4ww这个项目也push到github的仓库就可以了！上文提到，xmlprc4ww/db/blogs.txt保存了文章的内容，该内容是与本地Writer的内容同步的，于是只要将这个文件push到github上，然后在另外一台机器上pull过来，并且重复一次配置工作（包括站点配置、writer配置）就可以获得文章内容了。而在Writer的客户端上只要点击“打开最近使用过的日志”就可以从“另一个服务端”上获取文章内容了： %n<p><img style="background-image: none; border-right-width: 0px; padding-left: 0px; padding-right: 0px; display: inline; border-top-width: 0px; border-bottom-width: 0px; border-left-width: 0px; padding-top: 0px" class="img-responsive" title="image" border="0" alt="image" src="http://fakelocalhost/assert/img/2013-10-24-52692c3183411.png" width="390" height="285"> %n<blockquote>%n<p>特别需要注意的是，您PC2上的日志仓库可能与PC1不同，在配置PHP站点的时候需要特别留意 </p></blockquote>%n<p>&nbsp;</p>%n<h2>删除文章</h2>%n<p>xmlrpc4ww没有实现删除的功能，您可能需要手动完成，除了把github page所在的仓库中的日志文件和对应图片删除外，还需要删除xmlprc4ww/db/blogs.txt中的对应记录行。</p>%n<p>&nbsp;</p>%n<p>本文详细介绍了<a href="https://github.com/PChou/xmlrpc4ww" target="_blank">xmlrpc4ww</a>这个工具的使用方法，如果读者有任何问题，可以给我发邮件或者在下面留言，您的意见或建议是完善这个工具重要的途径，当然您也可以帮忙共享您的代码，发扬开源精神。</p>#基于PHP的Windows Writer服务提供器--如何使用#postlayout#详细描述如何配置php站点、如何配置Windows Writer、如何发布文章等细节#1346208288725.jpg#[web-build]#[PHP,github-page]#2013-10-23 22:48:38#2013-10-27 22:02:10#
6#2013-10-27-526d0f1648b1d.html#<p>公司部署网络环境，安装Esxi，去电脑城配了两台台式机当服务器，为了充分利用资源，准备安装Esxi。以前在公司里面也用PC装过Esxi，从来没有出过岔子。但是这次出了不少岔子。  <p>先是没有安装光盘，但是这个很快通过U盘引导解决了。具体使用的是一个叫unetbootin-windows-latest.exe工具，可以一键将iso写入U盘：  <p><img style="background-image: none; border-right-width: 0px; padding-left: 0px; padding-right: 0px; display: inline; border-top-width: 0px; border-bottom-width: 0px; border-left-width: 0px; padding-top: 0px" title="Image" border="0" alt="Image" src="http://fakelocalhost/assert/img/2013-10-27-526d0f162be26.png" width="449" height="332">  <p>然后，在安装过程中，报错说无法找到Network Adapter，寻寻觅觅，得知可能是vmware提供的安装包中没有我的网卡驱动，从这里可以查看自己的网卡是否被支持  <p><a href="http://www.vmware.com/resources/compatibility/search.php?deviceCategory=io">http://www.vmware.com/resources/compatibility/search.php?deviceCategory=io</a>  <p>如果不被支持的话必须，有三种解决途径  <p>1、如果是正规的品牌服务器的话，可以从服务器提供的光盘中找找有没有Esxi安装镜像，一般dell和hp都有提供各自定制化过的iso  <p>2、如果没有人家做好的iso的话，可以自己来做，去vmware网站上找驱动，然后用vmware提供的定制化iso工具ESXi-Customizer-v2.7.1，生成添加过驱动的iso  <p><img style="background-image: none; border-right-width: 0px; padding-left: 0px; padding-right: 0px; display: inline; border-top-width: 0px; border-bottom-width: 0px; border-left-width: 0px; padding-top: 0px" title="Image(1)" border="0" alt="Image(1)" src="http://fakelocalhost/assert/img/2013-10-27-526d0f1633f10.png" width="449" height="286">  <p>3、上面两种方法都没有成功的话，只能考虑重新购买被支持的网卡，intel的千兆网卡一般都支持，笔者从电脑城弄了一块就OK了  <p>网卡关过了以后，又碰到无法找到硬盘的问题，这个问题可能是由于两个原因：  <p>1、如果是用U盘引导的，在loading界面结束后，U盘就可以拔掉了，否则可能只识别出U盘  <p>2、可能需要在BIOS中设置SATA的工作方式为AHCI  <p>最后，还会有个警告说硬件不支持虚拟化技术，这时，需要将BIOS中的CPU开启虚拟化支持，具体操作由于BIOS版本很杂，自己找吧  <p>Esxi5.1激活码0F0KM-FLL4L-NZHG1-1CA56-9CU4J  <p>输入激活码的方法是在vSphere Client中，选择“配置”，然后选“已获选可的功能”，再点“编辑”就能看到输入序列号的界面了。  #Esxi安装手记#postlayout#网卡驱动、硬盘模式、CPU模式是安装Esxi经常碰到的问题。本文记录了实际在部署Esxi的时候碰到的这些困难和解决方案。#image0021229433128273.jpg#[hardware]#[Esxi,iso,Driver]#2013-10-27 21:03:18#2013-10-27 21:03:18#
7#2013-11-07-527ba36a16888.html#<p>数据库是一种十分复杂的软件，它为用户提供了可靠的数据存储与查询机制，本文将来探讨一下其中的“可靠存储”这个问题。数据库的可靠存储特性主要体现在如下几个方面：</p> <ol> <li>当出现硬件错误时，保证数据的一致性  <li>保证一系列的操作是原子的，要么成功要么失败  <li>当数据备份多处时，保证不同数据备份的一致性</li></ol> <p>&nbsp;</p> <h2>单库事务控制，预写日志</h2> <p>数据一致性经常也被称为“事务一致性”，也就是保证一系列的操作，要么都成功要么都失败。例如有下面的关系数据表，存储了用户的账户信息：</p> <table class="table"> <tbody> <tr> <td valign="top" width="133"><strong>账户名称</strong></td> <td valign="top" width="133"><strong>账户类型</strong></td> <td valign="top" width="133"><strong>账户余额</strong></td></tr> <tr> <td valign="top" width="133">扎迪</td> <td valign="top" width="133">支票</td> <td valign="top" width="133">800</td></tr> <tr> <td valign="top" width="133">扎迪</td> <td valign="top" width="133">存款</td> <td valign="top" width="133">300</td></tr> <tr> <td valign="top" width="133">皮德罗</td> <td valign="top" width="133">支票</td> <td valign="top" width="133">150</td></tr></tbody></table> <p>现在希望将扎迪的支票账户中的200元转移到扎迪存款账户里，最终结果希望是</p> <table class="table"> <tbody> <tr> <td valign="top" width="133"><strong>账户名称</strong></td> <td valign="top" width="133"><strong>账户类型</strong></td> <td valign="top" width="133"><strong>账户余额</strong></td></tr> <tr> <td valign="top" width="133">扎迪</td> <td valign="top" width="133">支票</td> <td valign="top" width="133"><font color="%hff0000"><strong>600</strong></font></td></tr> <tr> <td valign="top" width="133">扎迪</td> <td valign="top" width="133">存款</td> <td valign="top" width="133"><font color="%hff0000"><strong>500</strong></font></td></tr> <tr> <td valign="top" width="133">皮德罗</td> <td valign="top" width="133">支票</td> <td valign="top" width="133">150</td></tr></tbody></table> <p>那么，我们需要将这个任务分两步来执行：</p> <ol> <li>先将扎迪的支票账户更新为600  <li>再将扎迪的存款账户更新为500</li></ol> <p>但是，如果这两个步骤不能保证，要么同时成功要么同时失败的话，将出现很严重的后果。比如：当完成第一步后，突然断电了，扎迪会发现他的支票账户少了200元，但是存款账户仍然是300，凭空少了200元！尽管说，像断电这样的都是小概率事件，但是在上面这个例子中是绝对不被允许的。</p> <p>在数据库中为了解决这个问题，提出了事务的概念，程序员可以将两个步骤包装在一个事务中提交给数据库，数据库能够保证“事务一致性”。这样神奇的效果是如何实现的呢？其实原理很简单，就是所谓的“<strong>预写日志</strong>”，我们来看下具体的过程</p> <p>程序员在程序中依次将下面的指令发送给数据库，以完成更新</p> <ol> <li>开始事务  <li>将扎迪的支票账户余额<font color="%hff0000"><strong>变为600</strong></font>  <li>将扎迪的存款账户余额<strong><font color="%hff0000">变成500</font></strong>  <li>结束事务</li></ol> <p>这些指令被数据库程序接收后，将在转化为如下操作：</p> <ol> <li>开始事务  <li>将扎迪的支票账户余额<font color="%hff0000"><strong>从800变为600</strong></font>  <li>将扎迪的存款账户余额<strong><font color="%hff0000">从300变成500</font></strong>  <li>结束事务</li></ol> <p>数据库并不是立刻执行事务中的操作，而是将这些操作依次写入“预写日志”，预写日志是保存在磁盘上的。随后，数据库程序将执行“预写日志”中的内容，将更新操作体现在数据文件中。在正常的情况下，当完成“结束事务”操作后，删除上面的日志，并告知程序执行成功，这样，正常的操作就完成了。（有些数据库会在日志删除前再次写入“归档日志”中，以便可以通过归档日志恢复整个库）</p> <p>这里有一个需要注意的问题，程序在将事务操作发送给数据库的过程中，数据库也可能崩溃，也就是说“预写日志”可能记录不完整。这样，当数据库从崩溃中重启后可能发生的两种情况：</p> <ul> <li>数据库崩溃重启后，查看预写日志，发现一个事务，并且该事务的最后一个操作是“结束事务”。那么此时可以推断：这个事务有可能执行成功了，但日志没来得及删除；也有可能这个事务没有执行完，甚至还没有执行。不过无论如何，数据库将进行“<font color="%hff0000"><strong>前滚</strong></font>”恢复，将事务中剩下操作执行一遍。但是问题是，怎么才能知道究竟执行到哪一步了呢？事实上，这一点根本不重要，因为哪怕重新回放整个预写日志中的内容也仍然可以达到一致性。对于这种无论执行多少次都不会影响最终结果的特性称为“<font color="%hff0000"><strong>幂等</strong></font>”。  <li>数据库崩溃重启后，查看预写日志，发现一个事务，并且该事务的最后一个操作不是“结束事务”。那么可以推断：可能是程序指令在发送到数据库的过程中，数据库崩溃了，而且事务一定没有正确执行。这个时候由于无法确定，这个事务后面时候还有其他的操作没有接收，所以数据库只能执行“<font color="%hff0000"><strong>回滚</strong></font>”恢复，将已经在日志中的操作反过来恢复。读者可能已经注意到了，数据库在记入预写日志的时候，不仅记录的新值，同时还记录的原值，这样就能将数据回退到初始状态。</li></ul> <p>这里实际上解释了两个概念：前滚和回滚，这是数据库事务控制中很重要的概念，读者可以自行查询其他资料以便了解更多的细节。</p> <p>&nbsp;</p> <h2>跨库事务控制，二阶段提交</h2> <p>在很多数据库系统中，不仅支持单库的事务一致性，还支持多个库的事务一致性，虽然不同的数据库产品在实现这个功能的时候，所使用的细节技术不同，但是大致都是采用了”二阶段提交“这个方法，下面我们来看下它是如何工作的。</p> <p>一般来说，多个库中在一次事务中需要有一个事务发起者，称为”主库”，其他的库称为“从库”。假设需要执行一个在所有库的某个表中插入一行数据的事务。</p> <ul> <li>第一阶段，主库锁定表，并将事务写入自己的预写日志；主库将事务发给从库，从库也各自锁定自己的表，并把事务写入预写日志，完成后返回告诉主库一阶段完成  <li>第二阶段，主库开始执行自己的事务，并通知从库提交事务。如果在这个过程中没有任何错误，那么操作将在多个库中完成；如果发生错误，比如从库锁表失败，或者从库没有响应，或者从库磁盘满…主库将通知所有参与事务的从库回滚该事务，并且回滚主库的事务。回滚就是根据预写日志的内容回滚事务的操作，可见预写日志的重要性。</li></ul> <p>下图分别展示了两种过程</p> <p><img style="background-image: none; border-right-width: 0px; padding-left: 0px; padding-right: 0px; display: inline; border-top-width: 0px; border-bottom-width: 0px; border-left-width: 0px; padding-top: 0px" class="img-responsive" title="WOTV@KHBEKPVL2IP7{1LAVN" border="0" alt="WOTV@KHBEKPVL2IP7{1LAVN" src="http://fakelocalhost/assert/img/2013-11-10-527ef3942296b.jpeg" width="270" height="552">  <p>成功的二阶段提交，A为主库，B、C为从库  <p><img style="background-image: none; border-right-width: 0px; padding-left: 0px; padding-right: 0px; display: inline; border-top-width: 0px; border-bottom-width: 0px; border-left-width: 0px; padding-top: 0px" class="img-responsive" title="WPNN6Z0_VS9RVUMJ`}UCBO8" border="0" alt="WPNN6Z0_VS9RVUMJ`}UCBO8" src="http://fakelocalhost/assert/img/2013-11-10-527ef39432b3f.jpeg" width="271" height="553">  <p>失败的二阶段提交，A为主库，B、C为从库</p> <p>&nbsp;</p> <h2>总结</h2> <p>可见，“预写日志”对于事务前滚或回滚来说是非常重要的，这个精巧的设计保证了数据库的“一致性”，进而保证了“可靠存储”。而“二阶段提交”也是一个十分精巧而简单的方法，在数据库的“主从复制”、“跨库事务”等方面都有应用。</p> <p>不过事实上，上面的讨论都是基于单用户的，但数据库还需要解决多用户并发问题，这是通过“锁”的机制来实现的，锁也同样重要，不过本文不再阐述。</p>#数据库一致性原理浅析#postlayout#数据库一致性是数据库非常重要的特性，高端的数据库产品往往也是在一致性上，下了很多功夫，本文从单库一致性和多库一致性两个方面介绍了数据库的实现原理#W020110914489795789471.jpg#[algorithm]#[database,consistency]#2013-11-07 22:27:54#2013-11-10 11:04:03#
8#2013-11-10-527f6ec41d6ad.html#<p>Require.js是一个支持javascript模块化编程的类库，不了解的读者请移步至：<a href="http://www.ruanyifeng.com/blog/2012/11/require_js.html" target="_blank">Javascript模块化编程（三）：require.js的用法</a>。</p> <p>require在单页面应用中能够如鱼得水，然而对于传统的多页面应用，使用require多少会有些困惑和不方便。</p> <p>多页面应用的一个典型的例子是<a href="https://github.com/requirejs/example-multipage">https://github.com/requirejs/example-multipage</a>，读者可以clone下来参考。本文参考这个例子在ASP.NET MVC的结构中应用require，并且给出了压缩脚本，实现半自动化压缩。</p> <h2>将js代码分离</h2> <p>一般而言ASP.NET MVC的一个路由对应一个视图，视图的文件结构可能如下：</p><pre>Views%n |--Shared%n     |--_layout.cshtml%n |--Home%n     |--Index.cshtml%n |--Blog%n     |--Create.cshtml%n     |--Edit.cshtml%n     |--Detail.cshtml%n     |--Index.cshtml%n</pre>%n<p>这里假设<code>_layout.cshtml</code>是所有页面共享的。一般情况下，我们会在_layout中引用公共的js类库，比如<strong>jQuery</strong>，<strong>bootstrap</strong>等，这样的话其他的页面就不需要对这些类库再引用一遍，提高了编码的效率。然而，不同的页面终究会依赖不同的js，尤其是实现页面本身功能的自定义的js，这样我们不得不在其他页面中再引用特殊的js，甚至将js直接写在页面中，例如下面的代码经常会出现在View中：</p><pre>&lt;script type="text/javascript"&gt;%n   $(function(){...});%n&lt;/script&gt;%n</pre>%n<p>这样会导致页面比较混乱，而且页面&lt;script&gt;标签中代码不能被浏览器缓存，增加了页面代码的长度。更为重要的缺陷是，诸如jQuery之类的类库会在加载到页面后执行匿名函数，这需要一些时间，而如果有些页面根本不需要jQuery的话，只要页面把_layout作为布局页面，那么jQuery的初始化代码将不可避免的执行，这是一种浪费。事实上，javascript的模块化加载的思想就是为了解决这些问题的。</p>%n<p>接下来我们来用require规划我们的js，构建诸如下面结构的js目录</p><pre>js%n|--app%n    |--home.index.js%n    |--blog.create.js%n    |--blog.edit.js%n    |--blog.detail.js%n    |--blog.index.js%n|--jquery.js%n|--bootstrap.js%n|--underscore.js%n|--jquery.ui.js%n|--jquery.customplugin.js%n|--config.js%n|--require.js%n</pre>%n<p>把公共的类库级别的js模块直接放在js目录下，而把页面级别的js放在一个app的子目录下。注意，在app中，每个页面一个js文件，这意味着我们需要把页面各自的js提取出来，虽然这样增加了结构复杂度，但是避免了在页面中随手写&lt;script&gt;标签的陋习。另外，在js目录下的公共库，除了第三方的库，还包括自己开发的库，还有一个叫<code>config.js</code>的文件，这个文件很关键，稍后会说到。</p>%n<p>然后，我们可以删除_layout中所有的js引用，并使用@RenderSection的命令要求子页面提供js引用：</p>%n<p><em><font color="%hff0000">_layout.cshtml</font></em></p><pre>&lt;head&gt;%n...%n@RenderSection("require_js_module", false)%n...%n&lt;/head&gt;%n</pre>%n<p>这样对js的需求就下放到每个view页面中了，根据require的用法，我们需要在各个子View中引用require.js，并指定主模块，而这些主模块就是上面app目录下的一个个js</p><pre>@section require_js_module{%n    &lt;script src="@Url.Content("~/js/require.js")" data-main="@Url.Content("~/js/app/home.index.js")" &gt;&lt;/script&gt;%n}%n</pre>%n<p>所有的js代码都将写到app下的js中，这样规范了js，使得页面更干净，更为重要的是这些js还可以经过压缩，以及被浏览器缓存等，进一步提高执行效率</p>%n<h2>公共的config</h2>%n<p>我们知道主模块除了使用<code>require</code>方法外，经常需要通过<code>require.config</code>来配置其他模块的路径，甚至需要<code>shim</code>，例如下面的代码经常会出现在主模块的开头：</p><pre>require.config({%n	paths: {%n　　　　　　"jquery": "lib/jquery.min",%n　　　　　　"underscore": "lib/underscore.min",%n　　　　　　"backbone": "lib/backbone.min"%n　　　　},%n　　　　shim: {%n　　　　　　'underscore':{%n　　　　　　　　exports: '_'%n　　　　　　},%n　　　　　　'backbone': {%n　　　　　　　　deps: ['underscore', 'jquery'],%n　　　　　　　　exports: 'Backbone'%n　　　　　　}%n　　　　}%n　　});%n</pre>%n<p>对于单页面应用来说，主模块往往只有一个，所以上面的代码写一遍也就OK了。但是，在多页面的情况下，主模块有多个，每个主模块都要包含这样的代码，岂不是很不科学？于是，希望有一个统一配置的地方，但是应该如何来写呢？我们想到，将这些配置作为一个模块config.js，让其他的主模块对这个模块产生依赖就可以了，例如下面的config.js：</p>%n<p><em><font color="%hff0000">config.js</font></em></p><pre>requirejs.config({%n	paths: {%n　　　　　　"jquery": "/js/jquery.min",%n	    "bootstrap": "/js/bootstrap"%n　　　　},%n　　　　shim: {%n	    'bootstrap': {%n                deps: ['jquery'],%n                exports: "jQuery.fn.popover"%n            }%n　　　　}%n　　});%n%n</pre>%n<p>config.js的写法没有什么特别的，接下来只要在home.index.js中引用</p>%n<p><em><font color="%hff0000">home.index.js</font></em></p><pre>require(['../config','jquery', 'bootstrap'], function () {%n    //main module code here%n%n});%n</pre>%n<p>不过这样写还是不对的，因为，被主模块依赖的模块(这里的config,jquery,bootstrap)，在加载的时候，加载顺序是不确定的，但是又需要config模块在其他模块之前加载，怎么办呢？一个折衷的方案是修改home.index.js，成为如下代码：</p>%n<p><em><font color="%hff0000">home.index.js</font></em></p><pre>require(['../config'], function () {%n    require(['home.index2']);%n})%n, define("home.index2", ['jquery', 'bootstrap'], function () {%n	//main module code here%n})%n</pre>%n<p>使用一个命名的模块home.index2作为过渡，在主模块中手动require，这样可以保证config在主模块执行之前加载，也就使得home.index2在加载的时候已经加载了config了。</p>%n<h2>压缩</h2>%n<p>require提供一个压缩工具，用于压缩和合并js，详情请移步至<a href="http://requirejs.org/docs/optimization.html">http://requirejs.org/docs/optimization.html</a>。简单的说，require提供一个叫<code>r.js</code>的文件，通过本地的node程序（Node.js），执行这个r.js并传入一些参数，即可自动分析模块互相之间的依赖，以达到合并和压缩的目的。同样的，这对于单页面应用来说是容易的，因为主模块只有一个，但是对于多页面又如何做呢？好在这个压缩工具支持用一个配置文件来指导压缩，这样的话，我们可以编写下面的配置脚本：</p>%n<p><em><font color="%hff0000">build.js</font></em></p><pre>var build = {%n    appDir: '../js',%n    baseUrl: '.',%n    dir: '../js-built',%n    modules: [%n        //First set up the common build layer.%n        {%n            //module names are relative to baseUrl%n            name: 'config',%n            //List common dependencies here. Only need to list%n            //top level dependencies, "include" will find%n            //nested dependencies.%n            include: ["bootstrap", "config","jquery"]%n        },%n	//Now set up a build layer for each page, but exclude%n        //the common one. "exclude" will exclude nested%n        //the nested, built dependencies from "common". Any%n        //"exclude" that includes built modules should be%n        //listed before the build layer that wants to exclude it.%n        //"include" the appropriate "app/main*" module since by default%n        //it will not get added to the build since it is loaded by a nested%n        //require in the page*.js files.%n	{%n	    name:"app/home.index",%n	    exclude:["config"]%n	},%n	{%n	    name:"app/blog.create",%n	    exclude:["config"]%n	},%n	...%n    ]%n%n}%n</pre>%n<p>通过这个命令来执行压缩，压缩的结果将被保存到js-build目录：</p><pre>node.exe r.js -o build.js%n</pre>%n<p>build.js脚本实际上是一个js对象，我们将config加入公共模块，而在各个主模块中将其排除。这样，所有的公共库包括config将压缩成一个js，而主模块又不会包含多余的config。这样可想而知，每个页面在加载时最多只会下载两个js，而且公共模块的代码会“按需执行”。</p>%n<p>执行上面的脚本压缩，需要安装有node。可以在从这里<a href="http://nodejs.org/download/" target="_blank">下载</a>。</p>%n<h2>自动脚本</h2>%n<p>但是，随着主模块的增加，需要随时跟踪和修改这个build文件，这也是很麻烦的。于是，笔者基于node.js开发了一个叫<code>build-build.js</code>的脚本，用来根据目录结构自动生成build.js：</p>%n<p><em><font color="%hff0000">build-build.js</font></em></p><pre>fs = require('fs');%nvar target_build = process.argv[2];%n//console.log(__filename);%nvar pwd = __dirname;%nvar js_path = pwd.substring(0,pwd.lastIndexOf('\\')) + '\\js';%nconsole.log('js path : ' + js_path);%nvar app_path = js_path + '\\app';%nconsole.log('js app path : ' +app_path);%n%nvar app_modules = [];%nvar global_modules = [];%n%n//build json object%nvar build = {%n	appDir: '../js',%n    baseUrl: '.',%n    dir: '../js-built',%n    modules: [%n        //First set up the common build layer.%n        {%n            //module names are relative to baseUrl%n            name: 'config',%n            //List common dependencies here. Only need to list%n            //top level dependencies, "include" will find%n            //nested dependencies.%n            include: []%n        }%n    ]%n}%n%nfs.readdir(app_path,function (err,files) {%n	// body...%n	if (err) throw err;%n	for(var i in files){%n		//put module in app_modules%n		var dotindex = files[i].lastIndexOf('.');%n		if(dotindex &gt;= 0){%n			var extension = files[i].substring(dotindex+1,files[i].length);%n			if(extension == 'js'){%n				app_modules.push({%n					name: 'app/' + files[i].substring(0,dotindex),%n            		exclude: ['config']%n				});%n			}%n		}%n	}%n%n	for(var j in app_modules){%n		build.modules.push(app_modules[j]);%n	}%n	%n	fs.readdir(js_path,function (err,files){%n		if (err) throw err;%n		for(var i in files){%n			//put module in app_modules%n			var dotindex = files[i].lastIndexOf('.');%n			if(dotindex &gt;= 0){%n				var extension = files[i].substring(dotindex+1,files[i].length);%n				if(extension == 'js'){%n					global_modules.push(files[i].substring(0,dotindex));%n				}%n			}	%n		}%n%n		build.modules[0].include = global_modules;%n		//console.log(build);%n		var t = pwd + '\\' + target_build;%n		console.log(t);%n		var fd = fs.openSync(t, 'w');%n		fs.closeSync(fd);%n		var json = JSON.stringify(build);%n		fs.writeFileSync(t, json);%n	});%n});%n</pre>%n<p>这里的代码并不复杂，主要是遍历目录，生成对象，最后将对象序列化为build.js。读者可以自行阅读并修改。最后，编写一个bat，完成一键压缩功能：</p>%n<p><em><font color="%hff0000">build.bat</font></em></p><pre>@echo off%nset PWD=%p~p0%nset PWD=%pPWD:\=/%p%ncd "D:\node"%nnode.exe %pPWD%pbuild-build.js build.js%nnode.exe %pPWD%pr.js -o %pPWD%pbuild.js%ncd %p~dp0%n</pre>%n<p>这样，我们就简单实现了一个方便的多页面require方案，最后项目目录可能是这样的：</p><pre>Views%n |--Shared%n     |--_layout.cshtml%n |--Home%n     |--Index.cshtml%n |--Blog%n     |--Create.cshtml%n     |--Edit.cshtml%n     |--Detail.cshtml%n     |--Index.cshtml%n%nbuild%n|--build.js%n|--r.js%n|--build-build.js%n|--build.bat%n%njs%n|--app%n    |--home.index.js%n    |--blog.create.js%n    |--blog.edit.js%n    |--blog.detail.js%n    |--blog.index.js%n|--jquery.js%n|--bootstrap.js%n|--underscore.js%n|--jquery.ui.js%n|--jquery.customplugin.js%n|--config.js%n|--require.js%n</pre>%n<p>可以从<a href="https://github.com/PChou/mvc-require-mutilpage-example" target="_blank">这里</a>fork示例程序</p>#ASP.NET MVC应用require.js实践#postlayout#本文探讨如何在ASP.NET MVC多页面环境下应用js的模块化编程框架require，并给出压缩相关的自动化脚本#require_logo.png#[javascript,asp.net]#[require.js,asp.net mvc,node.js]#2013-11-10 19:32:20#2013-11-11 13:30:11#
9#2013-11-28-529753c0d8e54.html#<p>同一个网段需要用2层设备互联  <ul> <li>Hub：共享性网络，同一个Hub上的设备实际上可以看成连接在同一根线上，产生冲突的可能性很大，所以带宽是平分的，现在基本已经淘汰  <li>网桥：二层隔离性，能够互联多个网段，并隔离不同的网段。软件实现不同网段数据之间的过滤 </li></ul> <p><img style="background-image: none; border-right-width: 0px; padding-left: 0px; padding-right: 0px; display: inline; border-top-width: 0px; border-bottom-width: 0px; border-left-width: 0px; padding-top: 0px" class="img-responsive" title="image" border="0" alt="image" src="http://fakelocalhost/assert/img/2013-11-28-529753c09bdb6.png" width="508" height="378"></p> <ul> <li>交换机：多端口网桥，硬件实现过滤，能够达到线速转发。微分段（micro segmentation）技术：每个端口处在独立的冲突域（multiple collision domain）中，所以网络中不会出现线路冲突 </li></ul> <p><strong></strong>&nbsp; <p><strong><u>交换机的特点</u></strong>  <ol> <li>可靠安全的通信  <li>多端口链接  <li>全双工模式（Full-Duplex Communication）  <li>适应接口的不同速率（Media-Rate Adaptation）  <li>交换机通过桥接表来过滤和转发数据帧，并且具有学习能力  <li>交换机对广播和组播一般执行泛洪操作（交换机一般无法识别组播组），所以交换机一共会对3种包执行泛洪操作，分别为：目标地址未知的单播包（学习桥接表时）、广播包、组播包 </li></ol> <p><img style="background-image: none; border-right-width: 0px; padding-left: 0px; padding-right: 0px; display: inline; border-top-width: 0px; border-bottom-width: 0px; border-left-width: 0px; padding-top: 0px" class="img-responsive" title="image" border="0" alt="image" src="http://fakelocalhost/assert/img/2013-11-28-529753c0b5bcc.png" width="532" height="338">  <p><strong></strong>&nbsp; <p><strong><u>交换机的工作方式 </u></strong> <ul> <li>直通模式：当交换机读到源和目标mac地址时就开始转发（一般只需要读取20-30字节），不进行校验，无法识别碎片帧和损坏帧，最快但最不可靠  <li>无碎片转发：读前64个字节，然后立刻转发数据帧，因为一般冲突的数据碎片大小小于64字节，能够识别碎片帧，无法识别损坏帧  <li>存储转发：完整读取数据帧，并校验后转发，可靠性最高但最慢 </li></ul> <p><img style="background-image: none; border-right-width: 0px; padding-left: 0px; padding-right: 0px; display: inline; border-top-width: 0px; border-bottom-width: 0px; border-left-width: 0px; padding-top: 0px" class="img-responsive" title="image" border="0" alt="image" src="http://fakelocalhost/assert/img/2013-11-28-529753c0c2307.png" width="535" height="332"></p> <p>&nbsp; <p><strong><u>交换机指标</u></strong>  <ul> <li>接口数量  <li>接口速率  <li>背板带宽：即交换机的总流量速率。假设24口，每个口1000M，那么理论速率总速率为24G，但是背板带宽可能会限制这个速率。背板带宽实际上表征了交换机内部交换处理速度。例如思科6500系列核心交换机的背板带宽可达720G/s </li></ul> <p><img style="background-image: none; border-right-width: 0px; padding-left: 0px; padding-right: 0px; display: inline; border-top-width: 0px; border-bottom-width: 0px; border-left-width: 0px; padding-top: 0px" class="img-responsive" title="image" border="0" alt="image" src="http://fakelocalhost/assert/img/2013-11-28-529753c0cbf49.png" width="238" height="216"></p> <p><a href="http://itercast.com/lecture/195" target="_blank">源视频地址</a></p> <p><a href="http://pchou.info/resource/2013/01/06/linuxcast-video-link.html" target="_blank">视频教学资源汇总</a></p>#交换基础#postlayout#简单概括了交换机的基础知识，包括交换机优于网桥、交换机的特点、交换机的工作方式，交换机的选择指标#Services-network-cloud.jpg#[network,hardware]#[network,switch]#2013-11-28 22:31:28#2013-12-19 15:26:34#
10#2013-11-29-529882f34bf57.html#<p>现代企业网络架构：核心层、汇聚层、接入层，冗余链路  <ul> <li>接入层：直接连接终端设备，一般在大楼的每层都有若干接入层设备。通常只做基本的安全防护策略。常用中低端交换机，常见的有2960、3560  <li>汇聚层：连接接入层设备，而且一般都是带路由功能的交换机。大多数策略在这层应用。常用中高端交换机，常见的有3560、3750、4500  <li>核心层：连接汇聚层设备，通常为了高速转发数据，不做策略。常用高端交换机，常见的有4500、6500  <li>冗余链路：为了保证可靠性，采用双核心多汇聚多线路互联 </li></ul> <p><img style="background-image: none; border-right-width: 0px; padding-left: 0px; padding-right: 0px; display: inline; border-top-width: 0px; border-bottom-width: 0px; border-left-width: 0px; padding-top: 0px" class="img-responsive" title="Image" border="0" alt="Image" src="http://fakelocalhost/assert/img/2013-11-29-529882f2e778a.png" width="605" height="372"> </p> <p>交换机隔离冲突域，但是不隔离广播域，容易造成广播风暴。为了解决这个问题，交换机开始支持<font color="%hff0000"><strong>VLAN</strong></font>（虚拟局域网）：可以将同一个交换机的物理端口划分在不同的网段中，这样2层的广播就被限制在某个网段中，不同的VLAN之间需要通过3层设备才能通信  <p><img style="background-image: none; border-right-width: 0px; padding-left: 0px; padding-right: 0px; display: inline; border-top-width: 0px; border-bottom-width: 0px; border-left-width: 0px; padding-top: 0px" class="img-responsive" title="Image(1)" border="0" alt="Image(1)" src="http://fakelocalhost/assert/img/2013-11-29-529882f3111e1.png" width="612" height="392">  <p>一般划分VLAN基于两种策略：基于职能部门或基于数据流量（比如语音流量、管理流量跟一般的不同）  <p>根据交换机对VLAN的设计，一个端口只能属于一个VLAN，特定VLAN的数据帧也只会从属于该VLAN的端口发出，那么不同交换机之间VLAN的通信怎么实现？如下图，只能将交换机互联，并且互联的两端都属于同一个VLAN，这样有几个VLAN，交换机之间就需要几根线：  <p><img style="background-image: none; border-right-width: 0px; padding-left: 0px; padding-right: 0px; display: inline; border-top-width: 0px; border-bottom-width: 0px; border-left-width: 0px; padding-top: 0px" class="img-responsive" title="Image(2)" border="0" alt="Image(2)" src="http://fakelocalhost/assert/img/2013-11-29-529882f31e8bc.png" width="618" height="354">  <p>但是这样做显然不科学。使用Trunk可以允许在一根线路上承载多个VLAN的数据。trunk的实现原理是在Trunk的入口对数据打上标记，在出口的地方进行再分类。有两种trunk协议：802.1Q（标准协议）、ISL（思科私有）。思科的交换机能够自动识别并自动配置端口为Trunk  <p><img style="background-image: none; border-right-width: 0px; padding-left: 0px; padding-right: 0px; display: inline; border-top-width: 0px; border-bottom-width: 0px; border-left-width: 0px; padding-top: 0px" class="img-responsive" title="Image(3)" border="0" alt="Image(3)" src="http://fakelocalhost/assert/img/2013-11-29-529882f32755e.png" width="585" height="442">  <p>ISL：思科私有协议，支持PVST，使用封装算法，在数据帧的前端加入26字节的报头表征VLAN，尾部增加4字节的校验，优点是不修改原始数据帧  <p><img style="background-image: none; border-right-width: 0px; padding-left: 0px; padding-right: 0px; display: inline; border-top-width: 0px; border-bottom-width: 0px; border-left-width: 0px; padding-top: 0px" class="img-responsive" title="Image(4)" border="0" alt="Image(4)" src="http://fakelocalhost/assert/img/2013-11-29-529882f335bda.png" width="571" height="202">  <p>802.1Q：IEEE标准协议，在数据帧中增加4字节的标记，并重新计算校验。所有没有打标记的数据包，统一划归为Native VLAN（这种情况很少见）  <p><img style="background-image: none; border-right-width: 0px; padding-left: 0px; padding-right: 0px; display: inline; border-top-width: 0px; border-bottom-width: 0px; border-left-width: 0px; padding-top: 0px" class="img-responsive" title="Image(5)" border="0" alt="Image(5)" src="http://fakelocalhost/assert/img/2013-11-29-529882f33dcc4.png" width="472" height="258"> <p><a href="http://itercast.com/lecture/196" target="_blank">源视频地址</a></p> <p><a href="http://pchou.info/resource/2013/01/06/linuxcast-video-link.html" target="_blank">视频教学资源汇总</a></p>#交换机VLAN和Trunks#postlayout#现代企业网通常以三层架构，配合VLAN实现。VLAN的划分和原理，Trunk解决VLAN跨交换机通信的问题，Trunk有两种常见的协议#Services-network-cloud.jpg#[network,hardware]#[network,switch,VLAN,Trunk]#2013-11-29 20:05:07#2013-12-19 15:23:20#
11#2013-12-08-52a4192fa4715.html#<p>VTP协议用来简化和方便企业网的VLAN管理，实现动态的集中化的VLAN管理。采用C/S结构，用户只需要在一个“服务端交换机”配置VLAN信息，即可以自动同步到其他交换机。VTP只会通过交换机之间的Trunk发送  <p><img title="Image" class="img-responsive" style="border-left-width: 0px; border-right-width: 0px; background-image: none; border-bottom-width: 0px; padding-top: 0px; padding-left: 0px; display: inline; padding-right: 0px; border-top-width: 0px" border="0" alt="Image" src="http://fakelocalhost/assert/img/2013-12-08-52a4192f9d5cb.png" width="577" height="376">  <p>针对VTP协议，交换机可以配置成三种工作方式：  <ul> <li>服务端：能够创建、修改、删除VLAN，并将配置定期或立即转发，实现同步  <li>客户端：不能创建、修改、删除VLAN，能够同步服务端的配置，也可以转发  <li>透明模式：能够创建、修改、删除私有的VLAN，不同步服务端的通告，但可以转发通告 </li></ul> <p>VTP通过2层组播发送，每5分钟同步一次，或者当有更新时立刻同步。每个VTP通告会有一个序列号标识（revision number），序列号自增长，客户端交换机只会选择序列号较大的通告作为最新的通告。这个因为，VTP会在所有的Trunk间转发，有可能会在较短的时间内从其他交换机接收到一个版本较老的通告。因此，需要注意的是将一台曾经工作过的交换机加入到网络中时，务必要将配置清空后加入，否则该交换机的序列号有可能大于当前网络的VTP序列号，这样会使得这台交换机的VLAN配置覆盖当前网络的VLAN配置</p> <p><a href="http://itercast.com/lecture/197" target="_blank">源视频地址</a></p> <p><a href="http://pchou.info/resource/2013/01/06/linuxcast-video-link.html" target="_blank">视频教学资源汇总</a></p>#VTP协议#postlayout#VTP是专为VLAN开发的，用于快速维护全网VLAN配置，避免单台交换机逐一配置的协议#Services-network-cloud.jpg#[network,hardware]#[network,switch,VLAN,VTP]#2013-12-08 15:01:03#2013-12-19 15:22:25#
12#2013-12-19-52b293e0c4123.html#<h2>问题</h2> <p>为了提高网络的可用性，需要进行冗余和备份。但是冗余路径会产生环路  <p><img title="Image(1)" class="img-responsive" style="border-left-width: 0px; border-right-width: 0px; background-image: none; border-bottom-width: 0px; padding-top: 0px; padding-left: 0px; display: inline; padding-right: 0px; border-top-width: 0px" border="0" alt="Image(1)" src="http://fakelocalhost/assert/img/2013-12-19-52b293e073d9c.png" width="539" height="337">  <p>环路会导致以下问题  <ul> <li>广播风暴：由于交换机会对广播、多播、和未知目标MAC的单播包进行泛洪，在存在环路的情况下，很短的时间内就会产生风暴</li></ul> <p><img title="Image(2)" class="img-responsive" style="border-left-width: 0px; border-right-width: 0px; background-image: none; border-bottom-width: 0px; padding-top: 0px; padding-left: 0px; display: inline; padding-right: 0px; border-top-width: 0px" border="0" alt="Image(2)" src="http://fakelocalhost/assert/img/2013-12-19-52b293e080ef7.png" width="531" height="349"></p> <ul> <li>多帧拷贝、MAC地址表不稳定：当交换机刚刚启动时，MAC地址表是空的，所以，所有的单播帧都会进行泛洪操作。但是如果存在环路的话，交换机在特定情况下，会从不同的接口收到相同的MAC地址，这样的话，MAC地址表将不稳定</li></ul> <p><img title="Image(3)" class="img-responsive" style="border-left-width: 0px; border-right-width: 0px; background-image: none; border-bottom-width: 0px; padding-top: 0px; padding-left: 0px; display: inline; padding-right: 0px; border-top-width: 0px" border="0" alt="Image(3)" src="http://fakelocalhost/assert/img/2013-12-19-52b293e08a579.png" width="531" height="354"></p> <p>STP（spanning tree protocal，IEEE802.1D）就是通过软件防止环路的产生，通过逻辑的禁用接口，使得环路在逻辑上不存在；当线路出现故障时，将禁用的接口启用，使得网络能够发挥物理冗余路径带来的高可用性  <p>&nbsp; <h2>STP协议的工作原理</h2> <p>STP协议的原则如下：  <ol> <li>每个广播域中只有一个<b>根网桥</b>，根网桥的接口都是指定接口  <li>每一个非根网桥上都有一个<b>根接口</b>，根接口就是到达根网桥最近（带宽最高，开销最小）的接口  <li>每个网段中只有一个<b>指定接口（</b>发送方的桥ID较小的，或者端口优先级较小，或者端口ID较小的）  <li><b>非指定接口</b>不使用</li></ol> <p><img title="Image(4)" class="img-responsive" style="border-left-width: 0px; border-right-width: 0px; background-image: none; border-bottom-width: 0px; padding-top: 0px; padding-left: 0px; display: inline; padding-right: 0px; border-top-width: 0px" border="0" alt="Image(4)" src="http://fakelocalhost/assert/img/2013-12-19-52b293e09c65a.png" width="550" height="197"></p> <p>假如上图的Switch X是根网桥，那么它的两个接口都是指定接口；Switch Y是非根网桥，由于100BASE的带宽更高，所以Switch Y上面的接口是根接口；上下两个segement中，s1和s2都已经有指定接口了，所以Switch Y下面的接口既不是根接口，也不是指定接口，那么将其阻断。  <p>上述的过程是交换机通过STP协议和交换<strong>BPDU</strong>（Bridge Protocol Data Unit）桥接协议数据单元，自动协商得到的。BPDU每2秒钟发送一次。  <p>BPDU的数据结构  <p><img title="Image(5)" class="img-responsive" style="border-left-width: 0px; border-right-width: 0px; background-image: none; border-bottom-width: 0px; padding-top: 0px; padding-left: 0px; display: inline; padding-right: 0px; border-top-width: 0px" border="0" alt="Image(5)" src="http://fakelocalhost/assert/img/2013-12-19-52b293e0a407a.png" width="201" height="229">  <p><strong>Root ID（8Bytes）：</strong>根网桥ID，每个交换机通过桥ID进行标识，桥ID由桥优先级+MAC地址组成（64个字节）。桥优先级的默认值为32768，最大值为65535。<b>桥ID最小的为根网桥</b>  <p><strong>Cost of path（4Bytes）：</strong>接口的Cost值，端口速率对应的开销值如下：  <p><img title="Image(6)" class="img-responsive" style="border-left-width: 0px; border-right-width: 0px; background-image: none; border-bottom-width: 0px; padding-top: 0px; padding-left: 0px; display: inline; padding-right: 0px; border-top-width: 0px" border="0" alt="Image(6)" src="http://fakelocalhost/assert/img/2013-12-19-52b293e0ab96e.png" width="365" height="161">  <p><strong>Bridge ID（8Bytes）：</strong>本网桥（交换机）的桥ID  <p><strong>Port ID（2Bytes）：</strong>端口编号  <p><strong>Hellotime（2Bytes）：</strong>BPDU间隔发送时间，默认为2秒  <p><strong>Max age：</strong>详见下面  <p><strong>Forward delay：</strong>详见下面  <p>&nbsp; <p>上述四个字段，在交换机交换BPDU的过程中就能够协商出结果。  <p>在STP协议故障转移过程中，交换机接口状态有如下四个状态  <p><img title="Image(7)" class="img-responsive" style="border-left-width: 0px; border-right-width: 0px; background-image: none; border-bottom-width: 0px; padding-top: 0px; padding-left: 0px; display: inline; padding-right: 0px; border-top-width: 0px" border="0" alt="Image(7)" src="http://fakelocalhost/assert/img/2013-12-19-52b293e0b393b.png" width="534" height="256">  <p>当某个指定接口出现故障时，需要将原先的非指定接口转为指定接口。如何检测故障呢？  <p>一种情况是，直接端口故障，交换机能够立即得知这样的故障，则将Blocking的非指定接口立即切换到Listening状态  <p>另一种情况是，线路故障，交换机无法直接检测到，此时通过BPDU检测。正常情况下两台交换机之间会每两秒钟收到对方的BPDU，如果在<strong>Max age</strong>时间后，仍然无法收到BPDU的话，需要进行重选举，将原先Blocking的非指定接口，切换到Listening状态。  <p>Listening状态持续<strong>Forward Delay</strong>时间，这段时间后，选举完成。之后进入Learning状态，交换机在该端口上进行学习MAC地址，但是不转发数据，以防止对未知单播帧的广播，这个时间持续<strong>Forward Delay</strong>时间；最后进入正常的Forwarding状态  <p>一般情况下根据超时时间的设置，最长有可能需要经过30-50秒，STP协议才能重新选举完成  <p>总结：  <ul> <li>Blocking：非指定接口的状态，即不转发数据也不学习MAC地址  <li>Forwarding：指定接口或根接口，转发数据和学习MAC地址  <li>Listening：进入重选举的状态  <li>Learning：重选举完成后，进入MAC地址学习，但不转发数据</li></ul> <p>&nbsp;</p> <p>下面是一个例子  <p><img title="Image(8)" class="img-responsive" style="border-left-width: 0px; border-right-width: 0px; background-image: none; border-bottom-width: 0px; padding-top: 0px; padding-left: 0px; display: inline; padding-right: 0px; border-top-width: 0px" border="0" alt="Image(8)" src="http://fakelocalhost/assert/img/2013-12-19-52b293e0bd010.png" width="532" height="322">  <ol> <li>SWR的网桥优先级最小，所以SWR为根网桥，其接口为指定接口  <li>SWA、SWD的上面的两个接口到SWR的开销最小（都是19），所以都是根接口；同理，可以得到SWB和SWC的根接口  <li>SWA和SWD下面的端口都是其各自segement的指定接口（每个segment有且只有一个指定接口）  <li>SWB和SWC组成的segement还没有指定接口，此时由于SWB的桥优先级较小，所以SWB侧的接口为指定接口，而SWC侧的接口即为非指定接口，进入Blocking状态</li></ol> <p>&nbsp; <h2>PortFast</h2> <p>如果终端设备直接连接在交换机上，也需要等待30秒的话，会出现问题，比如DHCP超时。所以，可以配置交换机的接口为PortFast模式，PortFast的接口不会介入STP选举的过程，不需要等待30秒的选举过程。但是不能用在Trunck接口上，因为如果用在Trunck接口上启用PortFast，交换机之间无法进行STP选举，极易产生环路。所以PortFast一般只用在直连终端的“接入接口”。  <p><a href="http://itercast.com/lecture/198" target="_blank">源视频地址</a></p> <p><a href="http://pchou.info/resource/2013/01/06/linuxcast-video-link.html" target="_blank">视频教学资源汇总</a></p>#STP生成树协议#postlayout#交换机由于冗余拓扑会产生环路，导致广播风暴等问题，STP生成树协议利用软件协议暂时逻辑上阻断冗余接口，使得全网没有环路。当网络出现故障的时候，逻辑上被阻断的接口能够自动在30-50秒内重新开启并保证全网的畅通#Services-network-cloud.jpg#[network,hardware]#[network,switch,STP]#2013-12-19 14:36:16#2013-12-19 15:21:19#
13#2014-01-05-52c8e87d41fab.html#<p><img title="Happy-New-Year.-Inscription-2014-Image-5" class="img-responsive" style="display: inline" alt="Happy-New-Year.-Inscription-2014-Image-5" src="http://fakelocalhost/assert/img/2014-01-05-52c8e9a40fadd.jpeg" width="335" height="251">  <p>上次写类似的年终总结恐怕要追溯到大学了，这些年鲜有心情和动力，另外就是我对待事物喜欢往坏的方面想，消极的情绪也不便传播。元旦这段时间因为公司装修，有了一些时间静下来思考，回顾过去展望未来。  <p>过去的一年，外包在携程待了大半年，要说技术上的收获倒是不多，更多的是见识了大型互联网民企公司的状态：跟外企相比员工的工作积极性要高不少，沟通交流也更趋于高效和实际，也是人才辈出的地方。国企就不谈了，大家都有数。  <p>之后由于个人发展方面的考虑，来到现在这家创业公司。走之前是挺纠结的，身边比我年长的几乎都不支持。有人说，难以决定的时候就抛硬币吧，也许当你拿起硬币的时候你已经有了选择了。其实我一旦心动恐怕覆水也难收了。每个人都有对未知未来的恐惧，但是在现在社会，变化如此之快，“已知的未来”难道就不让人不安吗？联想当年父母下岗这么个社会变化，不就是不能适应变化而带来的“灾难”吗？因此，这样想来没有必要恐惧什么，只要努力去付出，成不成功只在天，但求无怨无悔。  <p>在新公司的几个月，由于公司小，凡事亲历亲为，IT管理、招聘都要自己做，没有专门的人协助。不过这段时间虽然辛苦，但是乐在其中，这种状态就像刚刚参加工作一般，很积极很乐观，每天工作到很晚也没什么倦意。反而，不在踌躇，不在犹豫，生活也多了几分乐趣的东西：养花、旅游、博客...  <p>过去的一年，过的很快，说不浮躁，那是假的，开始收藏各种文章却鲜有打开看看。开始关心时政、经济。  <p>新的一年要办件人生大事，希望顺利。希望家人身体健康，小伙伴们安居乐业，更快的成长，自己也要对自己好些。希望公司继续在正确的轨道上前行。  #过去的2013#postlayout#2013年度总结#2014-01-05-52c8e9a40fadd.jpeg#[life]#[life]#2014-01-05 13:07:09#2014-01-05 13:12:04#
14#2014-01-05-52c91a4fdf938.html#<p>STP标准生成树协议中，每个物理的交换机只能有一个STP实例，也就是说一个物理交换机只能接受一套STP协定结果。然而，STP通过阻断冗余链路，达到防环的目的，但是这样做，也使得无法最大限度的利用交换机的带宽资源。因为，如果冗余链路能够在某些特定情况下仍然工作，那么就能够在一定程度上利用这些原本阻断的接口提供额外的带宽。  <p>思科的交换机实现每VLAN生成树协议（Per VLAN Spanning Tree）。顾名思义，思科的交换机为每个VLAN维护独立的STP实例，这样用户可以配置不同的VLAN使用不同的根交换机，达到这样的负载均衡效果。  <p><img title="Image(9)" class="img-responsive" style="display: inline" alt="Image(9)" src="http://fakelocalhost/assert/img/2014-01-05-52c91a4fcb6e5.png" width="523" height="257">  <p>如上图，有两个VLAN：VLAN1和VLAN2，可以将SW1配置成VLAN1的根交换机，将SW2配置成VLAN2的根交换机，这样VLAN1的数据都会通过SW1转发，而VLAN2的数据都会通过SW2转发，一定程度上实现了带宽的负载均衡  <p>PVST协议通过拆分标准生成树的2个字节的birdge ID实现，如下图：</p> <p><img title="Image(10)" class="img-responsive" style="display: inline" alt="Image(10)" src="http://fakelocalhost/assert/img/2014-01-05-52c91a4fd7947.png" width="515" height="333"></p> <p>将bridge ID的后12位作为“系统扩展”来表示VLAN，仅保留4位给网桥优先级。这样就能精确的表征VLAN和桥ID的关系。但是，4位的桥ID显然不能用来表示0~65535的范围。所以，思科规定，在PVST中配置网桥优先级的时候，只能是4096(2的12次方)的倍数。所以针对上面的例子可以做如下配置： </p> <p><img title="KU~K]GL930_%p~7~}@EAZ$6C" style="display: inline" alt="KU~K]GL930_%p~7~}@EAZ$6C" src="http://fakelocalhost/assert/img/2014-01-05-52c91bdea8646.jpeg" width="541" height="284"> <p>将SWA的网桥优先级配置成<font color="%hff0000"><strong>VLAN1：4096、VLAN2：32768</strong></font>  <p>将SWB的网桥优先级配置成<font color="%hff0000"><strong>VLAN1：32768、VLAN2：4096</strong></font>  <p>&nbsp; <p>思科的交换机已经不支持标准STP，而是支持如下几种：  <ol> <li>PVST+（默认）  <li>PVRST+  <li>MSTP</li></ol>#PVST - 每VLAN生成树#postlayout#思科扩展了STP协议，实现了每VLAN STP，即每个VLAN实现一个STP协商实例，这样即可以避免冗余链路成环，又能够在逻辑层面复用这些冗余链路，以达到一定程度上的负载均衡#Services-network-cloud.jpg#[network,hardware]#[network,switch,PVST]#2014-01-05 16:39:43#2014-01-05 16:47:19#
15#2014-01-14-52d542e7c6ced.html#<p>前段时间听说一个新名词："全栈程序员"，google了一下，被引导到了知乎的一个讨论上： <a href="http://www.zhihu.com/question/22420900">http://www.zhihu.com/question/22420900</a> 。楼主提出了一个问题：怎样成为全栈程工程师，本人也在上面情不自禁地回复了一下。回头想来似乎还有话要说。由于这个话题很容易跑偏，本文只把范围限定在全栈Web软件工程师，简称<strong>FSD（Full Stack Developer）</strong>。  <p>&nbsp; <h3><font style="font-weight: bold">把技术当成生活，自己逼自己的结果</font></h3> <p>其实在任何公司工作，光凭工作的内容，很难成为FSD。有朋友可能不同意了，说在创业公司有很多机会做不同的工作啊，我想说的是，即便是创业公司，公司总是有主营的业务和方向的，就算能从前到后一个人做一个网站，那又怎样，从技术上说，无非也就是掌握了一种或几种数据库，一门或几门后台语言，掌握了html,js,css...大公司呢？更难了，大公司虽然方向很多，但是越是大的公司，个人的螺丝钉效应越明显，你可能成为领域专家，但很难有机会成为完整的机器的。那么全栈程序员的磨练靠的是什么？靠的是一种打心底里的执着和毅力，把技术当成生活，自己逼自己不断的猎取知识。  <p>&nbsp; <h3><strong>难以界定，每个人都有不同的理解</strong></h3> <p>刚才其实没有鄙视能够完整做网站的人，相反，很是钦佩。至少本人现在在css上还不能算能完全独立。不过每个人对FSD的定义其实不一样，这跟个人的阅历有一定的关系。只想说，既不要对自己过分自信，也不要过分贬低。一方面，人外有人，天外有天，每个人覆盖到技术领域是有差异的；另一方面，FSD其实挺不容易的，不仅不容易达到，而且不容易获得存在感。正因为见的多，所以就越觉得自己渺小，我们经常说的，真正的大牛从来就是低调和谦虚的。而FSD在任何领域都不是那种呼风唤雨的专家，别人在讨论的时候可能永远都没有你插话的机会，其实你心里知道，自己还很肤浅。个人自认为是比较接近这么一个性质的程序猿，可以从我的博客的文章内容略窥一二。但是正如我不敢斩钉截铁地将自己定性到这么个层次，恐怕很多全栈程序员也不能将自己明确在这个定位上，因为总有人能站出来给你一个"反例"。  <p>&nbsp; <h3><strong>何去何从</strong></h3> <p>从知乎上的回答来看，FSD似乎并不吃香。纵观人类发展历程，更细致的社会分工造就了生产力的提高。就程序员行业而言，越来越趋于细分话，似乎也是正常的趋势。作为FSD，实际上挺难的，主要是因为精力的限制，无法在广度和深度上兼顾。尽管如此，个人觉得FSD还是有很明显的优势的：  <ol> <li>见多识广，解决问题的手段比较多，而且往往能够触类旁通的思考；  <li>不容易被某种技术的新衰而左右，很容易转型；  <li>合格的FSD往往具有超强的毅力和极客精神，这在某些情况下是很有用的；  <li>由于能力广泛，又吃苦耐劳，适合创业；</li></ol> <p>&nbsp;</p> <h3><strong>个人理解</strong></h3> <p>针对Web开发的话，稍稍谈一谈个人对全栈程序员能力的界定，大牛们轻拍：  <ol> <li>用户体验层面，<code>html45</code>，<code>javascript</code>，<code>css23</code>，各种前端的框架...  <li>后台业务逻辑层面，各种编程语言，现在主流的有<code>Java</code>、<code>C%h</code>、<code>Python</code>、<code>Ruby</code>、<code>PHP</code>、<code>Node.js</code>...，以及配套的各种开发框架...  <li>辅助层面可能会涉及到<code>C</code>、<code>C++</code>等较为古老的编程语言，需要一定程度上熟悉掌握...  <li>数据库，会设计和使用几种常用的数据库，<code>mssql</code>、<code>mysql</code>、<code>oracle</code>...，数据库分析和优化  <li>架构层面，能够设计灵活可靠，易扩展的软件架构和硬件架构。这个层面上要掌握的东西就很多了，网络、存储、操作系统、web服务器、web架构，安全等等...  <li>一些基础理论层面的东西，算法数据结构、编译原理、网络基础...  <li>数据分析，数据挖掘  <li>管理层面，众人拾柴火焰高，一个人再牛b，精力是有限的，如果能够聚集并领导更多的人，那就更全面了。这包括项目管理，持续集成，敏捷开发，版本控制...  <li>移动开发</li></ol> <p>如果你是FSD，有什么想说的呢？欢迎全栈程序员们留言交流</p> <p>&nbsp;</p> <h3><font style="font-weight: bold">程序员能力矩阵</font></h3> <p>一个挺有意思的程序员能力界定，从<a href="http://static.icybear.net/%p5BCN%p5DProgrammer%p20competency%p20matrix.htm" target="_blank">程序员能力矩阵</a>转载：</p> <blockquote>注意:每个层次的知识都是渐增的，位于层次<em>n</em>，也蕴涵了你需了解所有低于层次<em>n</em>的知识。 </blockquote> <div class="table-responsive"> <table class="table-bordered table"> <caption>计算机科学 Computer Science</caption> <tbody> <tr class="headers"> <td>&nbsp;</td> <td>2<sup>n</sup> <span class="explain">(Level 0)</span></td> <td>n<sup>2</sup> <span class="explain">(Level 1)</span></td> <td>n <span class="explain">(Level 2)</span></td> <td>log(n) <span class="explain">(Level 3)</span></td></tr> <tr class="q"> <td>数据结构</td> <td>不知道数组和链表的差异 </td> <td>能够解释和使用数组，链表，字典等，并且能够用于实际的编程任务。</td> <td>了解基本数据结构时间和空间的折中，比如数组vs 链表，能够解释如何实现哈希表和处理冲突，了解优先队列及其实现。 </td> <td>高等的数据结构的知识，比如B-树、二项堆、斐波那契堆、AVL树、红黑树、伸展树、跳跃表以及前缀树等。</td></tr> <tr class="q"> <td>算法</td> <td>不能够找出一个数组各数的平均值(这令人难以置信，但是我的确在应聘者中遇到过) </td> <td>基本的排序，搜索和数据的遍历和检索算法。</td> <td>树，图，简单的贪婪算法和分而治之算法，能够适度了解矩阵该层的含义。</td> <td>能够辨识和编写动态规划方案，良好的图算法知识，良好的数值估算的知识，能够辨别NP问题等。 </td></tr> <tr class="q"> <td>编程体系</td> <td>不知道何为编译器、链接器和解释器。 </td> <td>对编译器、链接器、解释器有基本的了解。知道什么是汇编代码以及在硬件层如何工作。有一些虚拟内存和分页知识。 </td> <td>了解内核模式vs用户模式,多线程，同步原语以及它们如何实现，能够阅读汇编代码。了解网络如何工作，了解网络协议和socket级别编程。 </td> <td>了解整个程序堆栈、硬件(CPU+内存+中断+微码)、二进制代码、汇编、静态和动态链接、编码、解释、JIT（just-in-time）编译、内存碎片回收、堆、栈、存储器编址…</td></tr></tbody></table></div> <div class="table-responsive"> <table class="table-bordered table"> <caption>软件工程 Software Engineering </caption> <tbody> <tr class="headers"> <td>&nbsp;</td> <td>2<sup>n</sup> <span class="explain">(Level 0)</span></td> <td>n<sup>2</sup> <span class="explain">(Level 1)</span></td> <td>n <span class="explain">(Level 2)</span></td> <td>log(n) <span class="explain">(Level 3)</span></td></tr> <tr class="q"> <td>源码版本控制</td> <td>通过日期备份文件夹 </td> <td>VSS和初级的CVS/SVN用户</td> <td>熟练地使用CVS和SVN特性。知道如何分支和归并，使用程序库补丁安装特性等 </td> <td>有分布式VCS系统的知识。尝试过Bzr/Mercurial/Darcs/Git</td></tr> <tr class="q"> <td>自动化编译</td> <td>只知道在IDE下编译 </td> <td>知道如何编译在命令行下编译系统 </td> <td>能够安装一个脚本构建基本的系统 </td> <td>能够安装一个脚本来构建系统并且归档，安装程序，生成发布记录和给源码控制中的代码分配标签。</td></tr> <tr class="q"> <td>自动化测试</td> <td>认为所有的测试都是测试员的工作。 </td> <td>能够编写自动化的单元测试，能够为正在编写的代码提出良好的测试用例。 </td> <td>按照TDD （Test Driven Development）方式编写代码。</td> <td>了解并且能够有效自动化安装，载入/性能和UI测试</td></tr> <tr></tr></tbody></table></div> <div class="table-responsive"> <table class="table-bordered table"> <caption>程序设计 Programming</caption> <tbody> <tr class="headers"> <td>&nbsp;</td> <td>2<sup>n</sup> <span class="explain">(Level 0)</span></td> <td>n<sup>2</sup> <span class="explain">(Level 1)</span></td> <td>n <span class="explain">(Level 2)</span></td> <td>log(n) <span class="explain">(Level 3)</span></td></tr> <tr class="q"> <td>问题分解</td> <td>只有直线式的代码，通过复制粘贴来复用 </td> <td>能够把问题分散到多个函数中 </td> <td>能够想出可复用的函数/对象来解决大题的问题 </td> <td>使用适宜的数据结构和算法，写出通用的/面向对象的代码来封装问题的易改变的层面。</td></tr> <tr class="q"> <td>系统分解</td> <td>N想不出比单一的文件/类更好的层面 </td> <td>如果不在同一平台或没采用相同的技术，能够把问题空间和设计方案分解。 </td> <td>能够设计跨技术/平台的系统。 </td> <td>能够在多个产品线和与外部体系一体化中虚拟化和设计复制的系统。同时也能够设计支持系统监视、报告、故障恢复等。</td></tr> <tr class="q"> <td>交流</td> <td>不能向同伴表达想法/主意。匮乏拼写和语法的能力。 </td> <td>同伴能了解你在说什么。有良好的拼写和语法能力。 </td> <td>能够和同伴进行高效的交流</td> <td>能够使用清晰的方式了解和交流想法/设计/主意/细则，能适应每种环境的交流 </td></tr> <tr class="q"> <td>同一文件中代码组织</td> <td>同一文件中组织没有依据 </td> <td>按照逻辑性或者易接近的方法 </td> <td>代码分块和对于其他源文件来说是易于是释,引用其他源文件时有良好的注释 </td> <td>文档头部有许可声明，总结，良好的注释，一致的空格缩进。文档外观美观。</td></tr> <tr class="q"> <td>跨文件代码组织</td> <td>没够想过给代码跨文件组织</td> <td>相关文件按文件夹分组 </td> <td>每个物理文件都有独立的目的，比如一个类的定义，一个特性的实现等。 </td> <td>代码在物理层组织紧密，在文件名上与设计和外观相匹配，可以通过文件分布方式洞察设计理念。</td></tr> <tr class="q"> <td>源码树组织</td> <td>一切都放在一个文件夹内 </td> <td>初步地将代码分散进对应逻辑的文件夹。 </td> <td>没有循环依赖，二进制文件，库，文档，构建，第三方的代码都组织进合适的文件夹内。 </td> <td>源码树的物理布局与逻辑层次、组织方式相匹配。可以通过目录名称和组织方式洞察设计理念。 </td></tr> <tr class="q"> <td>代码可读性</td> <td>单音节的名称（在国内应该是那些类似用汉语拼音命名的习惯） </td> <td>对文件、变量、类、方法等，有良好的命名。 </td> <td>没有长函数、注释解释不常规的代码，bug修复,代码假设。 </td> <td>代码假设验证使用断言，自然的代码流，没有深层嵌套的条件和方法</td></tr> <tr class="q"> <td>防御性编码</td> <td>不知道这个概念</td> <td>检查代码中所有的参数，对关键的假设进行断言 </td> <td>确保检查了返回值和使代码失败的异常。 </td> <td>有自己的库来帮助防御性编程、编写单元测试模拟故障</td></tr> <tr class="q"> <td>错误处理</td> <td>只给乐观的情形编码 </td> <td>基本的代码错误处理，抛出异常/生成错误 </td> <td>确保错误/异常留在程序中有良好的状态，资源，连接，内存都有被合适的清理。 </td> <td>在编码之前察觉可能出现的异常，在代码的所有层次中维持一致性的异常处理策略，提出整个系统的错误处理准则。</td></tr> <tr class="q"> <td>IDE</td> <td>IDE大部分用来进行文本编辑 </td> <td>了解其周围的接口，能够高效地通过菜单来使用IDE</td> <td>了解最常操作的键盘快捷键 </td> <td>编写自定义宏</td></tr> <tr class="q"> <td>API</td> <td>需要频繁地查阅文档 </td> <td>把最频繁使用的API记在脑子里 </td> <td>广阔且深入的API知识。 </td> <td>为了使实际任务中常用API使用更加便捷，编写过API的上层库，填补API之间的缺口。 </td></tr> <tr class="q"> <td>框架</td> <td>没有使用过主平台外的任何框架 </td> <td>听过但没用过平台下流行的可用框架</td> <td>在专业的职位中使用过一个以上的框架，通晓各框架的特色。</td> <td>某框架的作者</td></tr> <tr class="q"> <td>需求分析</td> <td>接受给定的需求和代码规格 </td> <td>能对规格的遗漏提出疑问 </td> <td>了解全面情况，提出需要被规格化的整体范围。</td> <td>能够提出更好的可选方案，根据经验的浮现给出需求</td></tr> <tr class="q"> <td>脚本</td> <td>不具备脚本工具的知识 </td> <td>批处理文件/shell脚本 </td> <td>Perl/Python/Ruby/VBScript/Powershell </td> <td>写过并且发表过可重用的代码</td></tr> <tr class="q"> <td>数据库</td> <td>认为Excel就是数据库 </td> <td>知道基本的数据库概念，规范化、ACID（原子性Atomicity、一致性Consistency、隔离性Isolation、持久性Durability）、事务化，能够写简单的select语句 </td> <td>能够牢记在运行时必要查询中设计良好的规范化数据库模式， 精通用户视图，存储过程，触发器和用户定义类型。知道聚集与非聚集索引之间的差异。精通使用ORM（Object Relational Mapping对象关系映射）工具 </td> <td>能做基本的数据库管理，性能优化，索引优化，编写高级的select查询，能够使用相关sql来替换游标，理解数据内部的存储，了解如何镜像、复制数据库。知道两段数据提交如何工作</td></tr></tbody></table></div> <div class="table-responsive"> <table class="table-bordered table"> <caption>经验 Experience </caption> <tbody> <tr class="headers"> <td>&nbsp;</td> <td>2<sup>n</sup> <span class="explain">(Level 0)</span></td> <td>n<sup>2</sup> <span class="explain">(Level 1)</span></td> <td>n <span class="explain">(Level 2)</span></td> <td>log(n) <span class="explain">(Level 3)</span></td></tr> <tr class="q"> <td>专业语言经验</td> <td>命令式语言和面向对象语言 </td> <td>命令式语言,面向对象语言和说明型语言(SQL),如果了解静态类型vs动态类型，弱类型vs强类型则有加分 </td> <td>函数式语言,如果了解延缓求值，局部套用函数，延续则有加分 </td> <td>并发语言(Erlang, Oz) 逻辑语言(Prolog)</td></tr> <tr class="q"> <td>专业平台经验</td> <td>1 </td> <td>2-3 </td> <td>4-5 </td> <td>6+</td></tr> <tr class="q"> <td>专业经验年龄</td> <td>1 </td> <td>2-5 </td> <td>6-9 </td> <td>10+</td></tr> <tr class="q"> <td>领域知识</td> <td>没有该领域的知识 </td> <td>在该领域中曾经至少为一个产品工作过</td> <td>在同一领域中为多个产品工作过 </td> <td>领域专家。在该领域设计和实现数种产品/方案。精通该领域使用的标准条款和协议</td></tr></tbody></table></div> <div class="table-responsive"> <table class="table-bordered table"> <caption>学识 Knowledge </caption> <tbody> <tr class="headers"> <td>&nbsp;</td> <td>2<sup>n</sup> <span class="explain">(Level 0)</span></td> <td>n<sup>2</sup> <span class="explain">(Level 1)</span></td> <td>n <span class="explain">(Level 2)</span></td> <td>log(n) <span class="explain">(Level 3)</span></td></tr> <tr class="q"> <td>工具知识</td> <td>仅限于主要的IDE(VS.Net, Eclipse等) </td> <td>知道一些流行和标准工具的备选方案 </td> <td>对编辑器、调试器、IDE、开源的备选方案有很好的了解。比如某人了解大多数Scott Hanselman的威力工具列表中的工具，使用过ORM工具。</td> <td>实际地编写过工具和脚本，如果这些被发布则有加分</td></tr> <tr class="q"> <td>语言接触</td> <td>命令式语言和面向对象语言</td> <td>命令式语言、面向对象语言和说明型语言(SQL),如果了解静态类型vs动态类型、弱类型vs强类型则有加分 </td> <td>函数式语言,如果了解延缓求值、局部套用函数、continuations （源于scheme中的一种高级控制结构）则有加分 </td> <td>并发语言(Erlang, Oz) 逻辑语言(Prolog) </td></tr> <tr class="q"> <td>代码库知识</td> <td>从来没有查询过代码库 </td> <td>基本的代码层知识，了解如果构建系统 </td> <td>良好的代码库工作知识，实现过几次bug修复或者完成了一些细小的特性 </td> <td>实现了代码库中多个大型特性，能够轻松地将多数特性的需求变更具体化，从容地处理bug修复。</td></tr> <tr class="q"> <td>下一代技术知识</td> <td>从来没听说过即将到来的技术 </td> <td>听说过某领域即将到来的技术 </td> <td>下载过alpha preview/CTP/beta版本，并且读过一些文章和手册 </td> <td>试用过预览版而且实际地构建过某物，如果共享给其他人的话则有加分</td></tr> <tr class="q"> <td>平台内部</td> <td>对平台内部毫无所知 </td> <td>有平台基本的内部工作的知识 </td> <td>深度的平台内部知识，能够设想平台如何将程序转换成可执行代码。 </td> <td>编写过增强平台或者为其平台内部提供信息的工具。比如，反汇编工具，反编译工具，调试工具等。</td></tr> <tr class="q"> <td>书籍</td> <td>菜鸟系列，21天系列，24小时系列，蠢货系列... </td> <td>《代码大全》，《别让我思考》, 《精通正则表达式》 </td> <td>《设计模式》，《人件》，《代码珠玑》，《算法设计手册》，《程序员修炼之道》，《人月神话》 </td> <td>《计算机程序设计与解释》，《事务处理:概念与技术》，《计算机程序设计模型》，《计算机程序设计艺术》，《数据库系统导论》 C.J Date版，《Thinking Forth》 ，《Little Schemer》（没找到其中译本）</td></tr> <tr class="q"> <td>博客</td> <td>听过但是从来抽不出空去接触 </td> <td>阅读一些科技/编程/软件工程的博客，并且经常的收听一些播客</td> <td>维护一些博客的链接，收集博主分享的有用的文章和工具</td> <td>维护一个在编程方面，分享有个人见解和思考的博客</td></tr></tbody></table></div>#伤不起的全栈程序员#postlayout#全栈程序员是一群特殊的程序员，他们从前到后，由内而外，几乎无所不能。很多全栈程序员都认为创业是最好的体现能力和价值的地方#138_120531111023_1.jpg#[life]#[FSD,Programmer]#2014-01-14 22:00:07#2014-01-15 13:09:36#
16#2014-01-18-52da47204d4cb.html#<p>本文是<a href="http://www.dabeaz.com/ply/ply.html" target="_blank">PLY (Python Lex-Yacc)</a>的中文翻译版。转载请注明出处。</p> <p>如果你从事编译器或解析器的开发工作，你可能对lex和yacc不会陌生，PLY是<a href="http://www.dabeaz.com/" target="_blank">David Beazley</a>实现的基于Python的lex和yacc。作者最著名的成就可能是其撰写的<a href="http://www.dabeaz.com/cookbook.html" target="_blank">Python Cookbook, 3rd Edition</a>。我因为偶然的原因接触了PLY，觉得是个好东西，但是似乎国内没有相关的资料。于是萌生了翻译的想法，虽然内容不算多，但是由于能力有限，很多概念不了解，还专门补习了编译原理，这对我有很大帮助。为了完成翻译，经过初译，复审，排版等，花费我很多时间，最终还是坚持下来了，希望对需要的人有所帮助。另外，第一次大规模翻译英文，由于水平有限，如果错误或者不妥的地方还请指正，非常感谢。</p> <div class="table-responsive"> <table class="table"> <caption>一些翻译约定</caption> <tbody> <tr> <td>token</td> <td>标记</td></tr> <tr> <td>context free grammar</td> <td>上下文无关文法</td></tr> <tr> <td>syntax directed translation</td> <td>语法制导的翻译</td></tr> <tr> <td>ambiguity</td> <td>二义</td></tr> <tr> <td>terminals</td> <td>终结符</td></tr> <tr> <td>non-terminals</td> <td>非终结符</td></tr> <tr> <td>documentation string</td> <td>文档字符串（python中的_docstring_）</td></tr></tbody></table></div> <h3><font style="font-weight: bold">目录</font></h3> <ul> <li><a href="%h1">1 前言和预备</a>  <li><a href="%h2">2 介绍</a>  <li><a href="%h3">3 PLY概要</a>  <li><a href="%h4">4 Lex</a>  <ul> <li><a href="%h4_1">4.1 Lex的例子</a>  <li><a href="%h4_2">4.2 标记列表</a>  <li><a href="%h4_3">4.3 标记的规则</a>  <li><a href="%h4_4">4.4 标记的值</a>  <li><a href="%h4_5">4.5 丢弃标记</a>  <li><a href="%h4_6">4.6 行号和位置信息</a>  <li><a href="%h4_7">4.7 忽略字符</a>  <li><a href="%h4_8">4.8 字面字符</a>  <li><a href="%h4_9">4.9 错误处理</a>  <li><a href="%h4_10">4.10 构建和使用lexer</a>  <li><a href="%h4_11">4.11 @TOKEN装饰器</a>  <li><a href="%h4_12">4.12 优化模式</a>  <li><a href="%h4_13">4.13 调试</a>  <li><a href="%h4_14">4.14 其他方式定义词法规则</a>  <li><a href="%h4_15">4.15 额外状态维护</a>  <li><a href="%h4_16">4.16 Lexer克隆</a>  <li><a href="%h4_17">4.17 Lexer的内部状态</a>  <li><a href="%h4_18">4.18 基于条件的扫描和启动条件</a>  <li><a href="%h4_19">4.19 其他问题</a></li></ul></li></ul> <p>&nbsp;</p> <p>&nbsp;</p><a name="1"></a> <h3><font style="font-weight: bold">1 前言和预备</font></h3> <p>本文指导你使用PLY进行词法分析和语法解析的，鉴于解析本身是个复杂性的事情，在你使用PLY投入大规模的开发前，我强烈建议你完整地阅读或者浏览本文档。</p> <p>PLY-3.0能同时兼容Python2和Python3。需要注意的是，对于Python3的支持是新加入的，还没有广泛的测试（尽管所有的例子和单元测试都能够在Pythone3下通过）。如果你使用的是Python2，应该使用Python2.4以上版本，虽然，PLY最低能够支持到Python2.2，不过一些可选的功能需要新版本模块的支持。</p> <p>&nbsp;</p><a name="2"></a> <h3><font style="font-weight: bold">2 介绍</font></h3> <p>PLY是纯粹由Python实现的Lex和yacc（流行的编译器构建工具）。PLY的设计目标是尽可能的沿袭传统lex和yacc工具的工作方式，包括支持LALR(1)分析法、提供丰富的输入验证、错误报告和诊断。因此，如果你曾经在其他编程语言下使用过yacc，你应该能够很容易的迁移到PLY上。</p> <p>2001年，我在芝加哥大学教授“编译器简介”课程时开发了的早期的PLY。学生们使用Python和PLY构建了一个类似Pascal的语言的完整编译器，其中的语言特性包括：词法分析、语法分析、类型检查、类型推断、嵌套作用域，并针对SPARC处理器生成目标代码等。学生们最终大约实现了30种不同的编译器！PLY的大多数影响使用的接口设计问题都是学号生们提出的。从2001年以来，PLY继续从用户的反馈中不断改进。为了适应对未来的改进需求，PLY3.0在原来基础上进行了重大的重构。</p> <p>由于PLY是作为教学工具来开发的，你会发现它对于标记和语法规则是相当严谨的，这一定程度上是为了帮助新手用户找出常见的编程错误。不过，高级用户也会反现这也有助于处理真实编程语言的复杂语法。还需要注意的是，PLY没有提供太多花哨的东西（例如，自动构建抽象语法树和遍历树），我也不认为它是个分析框架。相反，你会发现它是一个用Python实现的，基本的，但能够完全胜任的lex/yacc。</p> <p>本文的假设你多少熟悉分析理论、语法制导的翻译、基于其他编程语言使用过类似lex和yacc的编译构建工具。如果你对这些东西不熟悉，你可能需要去学习一些文章的介绍，比如：Aho, Sethi和Ullman的《Compilers: Principles, Techniques, and Tools》（《编译原理》），和O'Reilly'出版的John Levine的《lex and yacc》。事实上，《lex and yacc》和PLY使用的概念几乎相同。</p> <p>&nbsp;</p><a name="3"></a> <h3><font style="font-weight: bold">3 PLY概要</font></h3> <p>PLY包含两个独立的模块：lex.py和yacc.py，都定义在ply包下。lex.py模块用来将输入字符通过一系列的正则表达式分解成标记序列，yacc.py通过一些上下文无关的文法来识别编程语言语法。yacc.py使用LR解析法，并使用LALR(1)算法（默认）或者SLR算法生成分析表。</p> <p>这两个工具是为了一起工作的。lex.py通过向外部提供<code>token()</code>方法作为接口，方法每次会从输入中返回下一个有效的标记。yacc.py将会不断的调用这个方法来获取标记并匹配语法规则。yacc.py的的功能通常是生成抽象语法树(AST)，不过，这完全取决于用户，如果需要，yacc.py可以直接用来完成简单的翻译。</p> <p>就像相应的unix工具，yacc.py提供了大多数你期望的特性，其中包括：丰富的错误检查、语法验证、支持空产生式、错误的标记、通过优先级规则解决二义性。事实上，传统yacc能够做到的PLY都应该支持。</p> <p>yacc.py与Unix下的yacc的主要不同之处在于，yacc.py没有包含一个独立的代码生成器，而是在PLY中依赖反射来构建词法分析器和语法解析器。不像传统的lex/yacc工具需要一个独立的输入文件，并将之转化成一个源文件，Python程序必须是一个可直接可用的程序，这意味着不能有额外的源文件和特殊的创建步骤（像是那种执行yacc命令来生成Python代码）。又由于生成分析表开销较大，PLY会缓存生成的分析表，并将它们保存在独立的文件中，除非源文件有变化，会重新生成分析表，否则将从缓存中直接读取。</p> <p>&nbsp;</p><a name="4"></a> <h3><font style="font-weight: bold">4 Lex</font></h3> <p>lex.py是用来将输入字符串标记化。例如，假设你正在设计一个编程语言，用户的输入字符串如下：</p><pre><code>x = 3 + 42 * (s - t)</code></pre>%n<p>标记器将字符串分割成独立的标记：</p><pre><code>'x','=', '3', '+', '42', '*', '(', 's', '-', 't', ')'</code></pre>%n<p>标记通常用一组名字来命名和表示：</p><pre><code>'ID','EQUALS','NUMBER','PLUS','NUMBER','TIMES','LPAREN','ID','MINUS','ID','RPAREN'</code></pre>%n<p>将标记名和标记值本身组合起来：</p><pre><code>('ID','x'), ('EQUALS','='), ('NUMBER','3'),('PLUS','+'), ('NUMBER','42), ('TIMES','*'),('LPAREN','('), ('ID','s'),('MINUS','-'),('ID','t'), ('RPAREN',')</code></pre>%n<p>正则表达式是描述标记规则的典型方法，下一节展示如何用lex.py实现。</p>%n<p>&nbsp;</p><a name="4_1"></a>%n<h4><font style="font-weight: bold">4.1 Lex的例子</font></h4>%n<p>下面的例子展示了如何使用lex.py对输入进行标记</p><pre><code>%n%h ------------------------------------------------------------%n%h calclex.py%n%h%n%h tokenizer for a simple expression evaluator for%n%h numbers and +,-,*,/%n%h ------------------------------------------------------------%nimport ply.lex as lex%n%n%h List of token names.   This is always required%ntokens = (%n   'NUMBER',%n   'PLUS',%n   'MINUS',%n   'TIMES',%n   'DIVIDE',%n   'LPAREN',%n   'RPAREN',%n)%n%n%h Regular expression rules for simple tokens%nt_PLUS    = r'\+'%nt_MINUS   = r'-'%nt_TIMES   = r'\*'%nt_DIVIDE  = r'/'%nt_LPAREN  = r'\('%nt_RPAREN  = r'\)'%n%n%h A regular expression rule with some action code%ndef t_NUMBER(t):%n    r'\d+'%n    t.value = int(t.value)    %n    return t%n%n%h Define a rule so we can track line numbers%ndef t_newline(t):%n    r'\n+'%n    t.lexer.lineno += len(t.value)%n%n%h A string containing ignored characters (spaces and tabs)%nt_ignore  = ' \t'%n%n%h Error handling rule%ndef t_error(t):%n    print "Illegal character '%ps'" %p t.value[0]%n    t.lexer.skip(1)%n%n%h Build the lexer%nlexer = lex.lex()%n</code></pre>%n<p>为了使lexer工作，你需要给定一个输入，并传递给input()方法。然后，重复调用token()方法来获取标记序列，下面的代码展示了这种用法：</p><pre><code>%n%h Test it out%ndata = '''%n3 + 4 * 10%n  + -20 *2%n'''%n%n%h Give the lexer some input%nlexer.input(data)%n%n%h Tokenize%nwhile True:%n    tok = lexer.token()%n    if not tok: break      %h No more input%n    print tok%n</code></pre>%n<p>程序执行，将给出如下输出：</p><pre><code>$ python example.py%nLexToken(NUMBER,3,2,1)%nLexToken(PLUS,'+',2,3)%nLexToken(NUMBER,4,2,5)%nLexToken(TIMES,'*',2,7)%nLexToken(NUMBER,10,2,10)%nLexToken(PLUS,'+',3,14)%nLexToken(MINUS,'-',3,16)%nLexToken(NUMBER,20,3,18)%nLexToken(TIMES,'*',3,20)%nLexToken(NUMBER,2,3,21)%n</code></pre>%n<p>Lexers也同时支持迭代，你可以把上面的循环写成这样：</p><pre><code>%nfor tok in lexer:%n    print tok%n</code></pre>%n<p>由<code>lexer.token()</code>方法返回的标记是<code>LexToken</code>类型的实例，拥有<code>tok.type</code>,<code>tok.value</code>,<code>tok.lineno</code>和<code>tok.lexpos</code>属性，下面的代码展示了如何访问这些属性： </p><pre><code>%h Tokenize%nwhile True:%n    tok = lexer.token()%n    if not tok: break      %h No more input%n    print tok.type, tok.value, tok.line, tok.lexpos%n</code></pre>%n<p><code>tok.type</code>和<code>tok.value</code>属性表示标记本身的类型和值。<code>tok.line</code>和<code>tok.lexpos</code>属性包含了标记的位置信息，<code>tok.lexpos</code>表示标记相对于输入串起始位置的偏移。 </p>%n<p>&nbsp;</p><a name="4_2"></a>%n<h4><font style="font-weight: bold">4.2 标记列表</font></h4>%n<p>词法分析器必须提供一个标记的列表，这个列表将所有可能的标记告诉分析器，用来执行各种验证，同时也提供给yacc.py作为终结符。</p>%n<p>在上面的例子中，是这样给定标记列表的：</p><pre><code>tokens = (%n   'NUMBER',%n   'PLUS',%n   'MINUS',%n   'TIMES',%n   'DIVIDE',%n   'LPAREN',%n   'RPAREN',%n)</code></pre>%n<p>&nbsp;</p><a name="4_3"></a>%n<h4><font style="font-weight: bold">4.3 标记的规则</font></h4>%n<p>每种标记用一个正则表达式规则来表示，每个规则需要以"t_"开头声明，表示该声明是对标记的规则定义。对于简单的标记，可以定义成这样（在Python中使用raw string能比较方便的书写正则表达式）：</p><pre><code>t_PLUS = r'\+'</code></pre>%n<p>这里，紧跟在t_后面的单词，必须跟标记列表中的某个标记名称对应。如果需要执行动作的话，规则可以写成一个方法。例如，下面的规则匹配数字字串，并且将匹配的字符串转化成Python的整型：</p><pre><code>def t_NUMBER(t):%n    r'\d+'%n    t.value = int(t.value)%n    return t</code></pre>%n<p>如果使用方法的话，正则表达式写成方法的文档字符串。方法总是需要接受一个<code>LexToken</code>实例的参数，该实例有一个<code>t.type</code>的属性（字符串表示）来表示标记的类型名称，<code>t.value</code>是标记值（匹配的实际的字符串），<code>t.lineno</code>表示当前在源输入串中的作业行，<code>t.lexpos</code>表示标记相对于输入串起始位置的偏移。默认情况下，<code>t.type</code>是以t_开头的变量或方法的后面部分。方法可以在方法体里面修改这些属性。但是，如果这样做，应该返回结果token，否则，标记将被丢弃。 <br>在lex内部，lex.py用<code>re</code>模块处理模式匹配，在构造最终的完整的正则式的时候，用户提供的规则按照下面的顺序加入：</p>%n<ol>%n<li>所有由方法定义的标记规则，按照他们的出现顺序依次加入 %n<li>由字符串变量定义的标记规则按照其正则式长度倒序后，依次加入（长的先入） </li></ol>%n<p>顺序的约定对于精确匹配是必要的。比如，如果你想区分‘=’和‘==’，你需要确保‘==’优先检查。如果用字符串来定义这样的表达式的话，通过将较长的正则式先加入，可以帮助解决这个问题。用方法定义标记，可以显示地控制哪个规则优先检查。 <br>为了处理保留字，你应该单独为其编写规则，然后像下面这样做特殊的查询：</p><pre><code>reserved = {%n   'if' : 'IF',%n   'then' : 'THEN',%n   'else' : 'ELSE',%n   'while' : 'WHILE',%n   ...%n}%n%ntokens = ['LPAREN','RPAREN',...,'ID'] + list(reserved.values())%n%ndef t_ID(t):%n    r'[a-zA-Z_][a-zA-Z_0-9]*'%n    t.type = reserved.get(t.value,'ID')    %h Check for reserved words%n    return t</code></pre>%n<p>这样做可以大大减少正则式的个数，并稍稍加快处理速度。注意：你应该避免为保留字编写单独的规则，例如，如果你像下面这样写：</p><pre><code>t_FOR   = r'for'%nt_PRINT = r'print'</code></pre>%n<p>但是，这些规则照样也能够匹配以这些字符开头的单词，比如'forget'或者'printed'，这通常不是你想要的。</p>%n<p>&nbsp;</p><a name="4_4"></a>%n<h4><font style="font-weight: bold">4.4 标记的值</font></h4>%n<p>标记被lex返回后，它们的值被保存在<code>value</code>属性中。正常情况下，<code>value</code>是匹配的实际文本。事实上，<code>value</code>可以被赋为任何Python支持的类型。例如，当扫描到标识符的时候，你可能不仅需要返回标识符的名字，还需要返回其在符号表中的位置，可以像下面这样写：</p><pre><code>def t_ID(t):%n    ...%n    %h Look up symbol table information and return a tuple%n    t.value = (t.value, symbol_lookup(t.value))%n    ...%n    return t%n</code></pre>%n<p>需要注意的是，不推荐用其他属性来保存值，因为yacc.py模块只会暴露出标记的<code>value</code>属性，访问其他属性会变得不自然。如果想保存多种属性，可以将元组、字典、或者对象实例赋给value。</p>%n<p>&nbsp;</p><a name="4_5"></a>%n<h4><font style="font-weight: bold">4.5 丢弃标记</font></h4>%n<p>想丢弃像注释之类的标记，只要不返回value就行了，像这样：</p><pre><code>def t_COMMENT(t):%n    r'\%h.*'%n    pass%n    %h No return value. Token discarded</pre><p>为标记声明添加"ignore_"前缀同样可以达到目的：</p><pre>t_ignore_COMMENT = r'\%h.*'</code></pre>%n<p>如果有多种文本需要丢弃，建议使用方法来定义规则，因为方法能够提供更精确的匹配优先级控制（方法根据出现的顺序，而字符串的正则表达式依据正则表达式的长度）</p>%n<p>&nbsp;</p><a name="4_6"></a>%n<h4><font style="font-weight: bold">4.6 行号和位置信息</font></h4>%n<p>默认情况下，lex.py对行号一无所知。因为lex.py根本不知道何为"行"的概念（换行符本身也作为文本的一部分）。不过，可以通过写一个特殊的规则来记录行号：</p><pre><code>%h Define a rule so we can track line numbers%ndef t_newline(t):%n    r'\n+'%n    t.lexer.lineno += len(t.value)</code></pre>%n<p>在这个规则中，当前lexer对象t.lexer的lineno属性被修改了，而且空行被简单的丢弃了，因为没有任何的返回。</p>%n<p>lex.py也不自动做列跟踪。但是，位置信息被记录在了每个标记对象的lexpos属性中，这样，就有可能来计算列信息了。例如：每当遇到新行的时候就重置列值：</p><pre><code>%h Compute column. %n%h     input is the input text string%n%h     token is a token instance%ndef find_column(input,token):%n    last_cr = input.rfind('\n',0,token.lexpos)%n    if last_cr &lt; 0:%n        last_cr = 0%n    column = (token.lexpos - last_cr) + 1%n    return column</code></pre>%n<p>通常，计算列的信息是为了指示上下文的错误位置，所以只在必要时有用。</p>%n<p>&nbsp;</p><a name="4_7"></a>%n<h4><font style="font-weight: bold">4.7 忽略字符</font></h4>%n<p><code>t_ignore</code>规则比较特殊，是lex.py所保留用来忽略字符的，通常用来跳过空白或者不需要的字符。虽然可以通过定义像<code>t_newline()</code>这样的规则来完成相同的事情，不过使用t_ignore能够提供较好的词法分析性能，因为相比普通的正则式，它被特殊化处理了。</p>%n<p>&nbsp;</p><a name="4_8"></a>%n<h4><font style="font-weight: bold">4.8 字面字符</font></h4>%n<p>字面字符可以通过在词法模块中定义一个<code>literals</code>变量做到，例如：</p><pre><code>literals = [ '+','-','*','/' ]</code></pre>%n<p>或者</p><pre><code>literals = "+-*/"</code></pre>%n<p>字面字符是指单个字符，表示把字符本身作为标记，标记的<code>type</code>和<code>value</code>都是字符本身。不过，字面字符是在其他正则式之后被检查的，因此如果有规则是以这些字符开头的，那么这些规则的优先级较高。</p>%n<p>&nbsp;</p><a name="4_9"></a>%n<h4><font style="font-weight: bold">4.9 错误处理</font></h4>%n<p>最后，在词法分析中遇到非法字符时，<code>t_error()</code>用来处理这类错误。这种情况下，<code>t.value</code>包含了余下还未被处理的输入字串，在之前的例子中，错误处理方法是这样的：</p><pre><code>%h Error handling rule%ndef t_error(t):%n    print "Illegal character '%ps'" %p t.value[0]%n    t.lexer.skip(1)</code></pre>%n<p>这个例子中，我们只是简单的输出不合法的字符，并且通过调用<code>t.lexer.skip(1)</code>跳过一个字符。</p>%n<p>&nbsp;</p><a name="4_10"></a>%n<h4><font style="font-weight: bold">4.10 构建和使用lexer</font></h4>%n<p>函数<code>lex.lex()</code>使用Python的反射机制读取调用上下文中的正则表达式，来创建lexer。lexer一旦创建好，有两个方法可以用来控制lexer对象：</p>%n<ul>%n<li><code>lexer.input(data)</code> 重置lexer和输入字串 %n<li><code>lexer.token()</code> 返回下一个<code>LexToken</code>类型的标记实例，如果进行到输入字串的尾部时将返回<code>None</code> </li></ul>%n<p>推荐直接在<code>lex()</code>函数返回的lexer对象上调用上述接口，尽管也可以向下面这样用模块级别的<code>lex.input()</code>和<code>lex.token()</code>：</p><pre><code>lex.lex()%nlex.input(sometext)%nwhile 1:%n    tok = lex.token()%n    if not tok: break%n    print tok</code></pre>%n<p>在这个例子中，<code>lex.input()</code>和<code>lex.token()</code>是模块级别的方法，在lex模块中，<code>input()</code>和<code>token()</code>方法绑定到最新创建的lexer对象的对应方法上。最好不要这样用，因为这种接口可能不知道在什么时候就失效（译者注：垃圾回收？）</p>%n<p>&nbsp;</p><a name="4_11"></a>%n<h4><font style="font-weight: bold">4.11 @TOKEN装饰器</font></h4>%n<p>在一些应用中，你可能需要定义一系列辅助的记号来构建复杂的正则表达式，例如：</p><pre><code>digit            = r'([0-9])'%nnondigit         = r'([_A-Za-z])'%nidentifier       = r'(' + nondigit + r'(' + digit + r'|' + nondigit + r')*)'        %n%ndef t_ID(t):%n    %h want docstring to be identifier above. ?????%n    ...</code></pre>%n<p>在这个例子中，我们希望ID的规则引用上面的已有的变量。然而，使用文档字符串无法做到，为了解决这个问题，你可以使用<strong>@TOKEN</strong>装饰器：</p><pre><code>from ply.lex import TOKEN%n%n@TOKEN(identifier)%ndef t_ID(t):%n    ...</code></pre>%n<p>装饰器可以将identifier关联到t_ID()的文档字符串上以使lex.py正常工作，一种等价的做法是直接给文档字符串赋值：</p><pre><code>def t_ID(t):%n    ...%n%nt_ID.__doc__ = identifier</code></pre>%n<p>注意：@TOKEN装饰器需要Python-2.4以上的版本。如果你在意老版本Python的兼容性问题，使用上面的等价办法。</p>%n<p>&nbsp;</p><a name="4_12"></a>%n<h4><font style="font-weight: bold">4.12 优化模式</font></h4>%n<p>为了提高性能，你可能希望使用Python的优化模式（比如，使用-o选项执行Python）。然而，这样的话，Python会忽略文档字串，这是lex.py的特殊问题，可以通过在创建lexer的时候使用<code>optimize</code>选项：</p><pre><code>lexer = lex.lex(optimize=1)</code></pre>%n<p>接着，用Python常规的模式运行，这样，lex.py会在当前目录下创建一个lextab.py文件，这个文件会包含所有的正则表达式规则和词法分析阶段的分析表。然后，lextab.py可以被导入用来构建lexer。这种方法大大改善了词法分析程序的启动时间，而且可以在Python的优化模式下工作。</p>%n<p>想要更改生成的文件名，使用如下参数：</p><pre><code>lexer = lex.lex(optimize=1,lextab="footab")</code></pre>%n<p>在优化模式下执行，需要注意的是lex会被禁用大多数的错误检查。因此，建议只在确保万事俱备准备发布最终代码时使用。</p>%n<p>&nbsp;</p><a name="4_13"></a>%n<h4><font style="font-weight: bold">4.13 调试</font></h4>%n<p>如果想要调试，可以使lex()运行在调试模式：</p><pre><code>lexer = lex.lex(debug=1)</code></pre>%n<p>这将打出一些调试信息，包括添加的规则、最终的正则表达式和词法分析过程中得到的标记。</p>%n<p>除此之外，lex.py有一个简单的主函数，不但支持对命令行参数输入的字串进行扫描，还支持命令行参数指定的文件名：</p><pre><code>if __name__ == '__main__':%n     lex.runmain()</code></pre>%n<p>想要了解高级调试的详情，请移步至最后的“调试”部分。</p>%n<p>&nbsp;</p><a name="4_14"></a>%n<h4><font style="font-weight: bold">4.14 其他方式定义词法规则</font></h4>%n<p>上面的例子，词法分析器都是在单个的Python模块中指定的。如果你想将标记的规则放到不同的模块，使用<code>module</code>关键字参数。例如，你可能有一个专有的模块，包含了标记的规则：</p><pre><code>%h module: tokrules.py%n%h This module just contains the lexing rules%n%n%h List of token names.   This is always required%ntokens = (%n   'NUMBER',%n   'PLUS',%n   'MINUS',%n   'TIMES',%n   'DIVIDE',%n   'LPAREN',%n   'RPAREN',%n)%n%n%h Regular expression rules for simple tokens%nt_PLUS    = r'\+'%nt_MINUS   = r'-'%nt_TIMES   = r'\*'%nt_DIVIDE  = r'/'%nt_LPAREN  = r'\('%nt_RPAREN  = r'\)'%n%n%h A regular expression rule with some action code%ndef t_NUMBER(t):%n    r'\d+'%n    t.value = int(t.value)    %n    return t%n%n%h Define a rule so we can track line numbers%ndef t_newline(t):%n    r'\n+'%n    t.lexer.lineno += len(t.value)%n%n%h A string containing ignored characters (spaces and tabs)%nt_ignore  = ' \t'%n%n%h Error handling rule%ndef t_error(t):%n    print "Illegal character '%ps'" %p t.value[0]%n    t.lexer.skip(1)</code></pre>%n<p>现在，如果你想要从不同的模块中构建分析器，应该这样（在交互模式下）：</p><pre><code>&gt;&gt;&gt; import tokrules%n&gt;&gt;&gt; <b>lexer = lex.lex(module=tokrules)</b>%n&gt;&gt;&gt; lexer.input("3 + 4")%n&gt;&gt;&gt; lexer.token()%nLexToken(NUMBER,3,1,1,0)%n&gt;&gt;&gt; lexer.token()%nLexToken(PLUS,'+',1,2)%n&gt;&gt;&gt; lexer.token()%nLexToken(NUMBER,4,1,4)%n&gt;&gt;&gt; lexer.token()%nNone</code></pre>%n<p><code>module</code>选项也可以指定类型的实例，例如：</p><pre><code>import ply.lex as lex%n%nclass MyLexer:%n    %h List of token names.   This is always required%n    tokens = (%n       'NUMBER',%n       'PLUS',%n       'MINUS',%n       'TIMES',%n       'DIVIDE',%n       'LPAREN',%n       'RPAREN',%n    )%n%n    %h Regular expression rules for simple tokens%n    t_PLUS    = r'\+'%n    t_MINUS   = r'-'%n    t_TIMES   = r'\*'%n    t_DIVIDE  = r'/'%n    t_LPAREN  = r'\('%n    t_RPAREN  = r'\)'%n%n    %h A regular expression rule with some action code%n    %h Note addition of self parameter since we're in a class%n    def t_NUMBER(self,t):%n        r'\d+'%n        t.value = int(t.value)    %n        return t%n%n    %h Define a rule so we can track line numbers%n    def t_newline(self,t):%n        r'\n+'%n        t.lexer.lineno += len(t.value)%n%n    %h A string containing ignored characters (spaces and tabs)%n    t_ignore  = ' \t'%n%n    %h Error handling rule%n    def t_error(self,t):%n        print "Illegal character '%ps'" %p t.value[0]%n        t.lexer.skip(1)%n%n    <b>%h Build the lexer%n    def build(self,**kwargs):%n        self.lexer = lex.lex(module=self, **kwargs)</b>%n    %n    %h Test it output%n    def test(self,data):%n        self.lexer.input(data)%n        while True:%n             tok = lexer.token()%n             if not tok: break%n             print tok%n%n%h Build the lexer and try it out%nm = MyLexer()%nm.build()           %h Build the lexer%nm.test("3 + 4")     %h Test it</code></pre>%n<p>当从类中定义lexer，你需要创建类的实例，而不是类本身。这是因为，lexer的方法只有被绑定（bound-methods）对象后才能使PLY正常工作。 </p>%n<p>当给<code>lex()</code>方法使用<code>module</code>选项时，PLY使用<code>dir()</code>方法，从对象中获取符号信息，因为不能直接访问对象的<code>__dict__</code>属性。（译者注：可能是因为兼容性原因<code>，__dict__</code>这个方法可能不存在）</p>%n<p>最后，如果你希望保持较好的封装性，但不希望什么东西都写在类里面，lexers可以在闭包中定义，例如：</p><pre><code>import ply.lex as lex%n%n%h List of token names.   This is always required%ntokens = (%n  'NUMBER',%n  'PLUS',%n  'MINUS',%n  'TIMES',%n  'DIVIDE',%n  'LPAREN',%n  'RPAREN',%n)%n%ndef MyLexer():%n    %h Regular expression rules for simple tokens%n    t_PLUS    = r'\+'%n    t_MINUS   = r'-'%n    t_TIMES   = r'\*'%n    t_DIVIDE  = r'/'%n    t_LPAREN  = r'\('%n    t_RPAREN  = r'\)'%n%n    %h A regular expression rule with some action code%n    def t_NUMBER(t):%n        r'\d+'%n        t.value = int(t.value)    %n        return t%n%n    %h Define a rule so we can track line numbers%n    def t_newline(t):%n        r'\n+'%n        t.lexer.lineno += len(t.value)%n%n    %h A string containing ignored characters (spaces and tabs)%n    t_ignore  = ' \t'%n%n    %h Error handling rule%n    def t_error(t):%n        print "Illegal character '%ps'" %p t.value[0]%n        t.lexer.skip(1)%n%n    %h Build the lexer from my environment and return it    %n    return lex.lex()</code></pre>%n<p>&nbsp;</p><a name="4_15"></a>%n<h4><font style="font-weight: bold">4.15 额外状态维护</font></h4>%n<p>在你的词法分析器中，你可能想要维护一些状态。这可能包括模式设置，符号表和其他细节。例如，假设你想要跟踪<code>NUMBER</code>标记的出现个数。</p>%n<p>一种方法是维护一个全局变量：</p><pre><code>num_count = 0%ndef t_NUMBER(t):%n    r'\d+'%n    global num_count%n    num_count += 1%n    t.value = int(t.value)    %n    return t</code></pre>%n<p>如果你不喜欢全局变量，另一个记录信息的地方是lexer对象内部。可以通过标记的lexer属性访问：</p><pre><code>def t_NUMBER(t):%n    r'\d+'%n    t.lexer.num_count += 1     %h Note use of lexer attribute%n    t.value = int(t.value)    %n    return t%n%nlexer = lex.lex()%nlexer.num_count = 0            %h Set the initial count</code></pre>%n<p>上面这样做的优点是当同时存在多个lexer实例的情况下，简单易行。不过这看上去似乎是严重违反了面向对象的封装原则。lexer的内部属性（除了<code>lineno</code>）都是以lex开头命名的（<code>lexdata</code>、<code>lexpos</code>）。因此，只要不以lex开头来命名属性就很安全的。</p>%n<p>如果你不喜欢给lexer对象赋值，你可以自定义你的lexer类型，就像前面看到的那样：</p><pre><code>class MyLexer:%n    ...%n    def t_NUMBER(self,t):%n        r'\d+'%n        self.num_count += 1%n        t.value = int(t.value)    %n        return t%n%n    def build(self, **kwargs):%n        self.lexer = lex.lex(object=self,**kwargs)%n%n    def __init__(self):%n        self.num_count = 0</code></pre>%n<p>如果你的应用会创建很多lexer的实例，并且需要维护很多状态，上面的类可能是最容易管理的。</p>%n<p>状态也可以用闭包来管理，比如，在Python3中：</p><pre><code>def MyLexer():%n    num_count = 0%n    ...%n    def t_NUMBER(t):%n        r'\d+'%n        nonlocal num_count%n        num_count += 1%n        t.value = int(t.value)    %n        return t%n    ...</code></pre>%n<p>&nbsp;</p><a name="4_16"></a>%n<h4><font style="font-weight: bold">4.16 Lexer克隆</font></h4>%n<p>如果有必要的话，lexer对象可以通过<code>clone()</code>方法来复制：</p><pre><code>lexer = lex.lex()%n...%nnewlexer = lexer.clone()</code></pre>%n<p>当lexer被克隆后，复制品能够精确的保留输入串和内部状态，不过，新的lexer可以接受一个不同的输出字串，并独立运作起来。这在几种情况下也许有用：当你在编写的解析器或编译器涉及到递归或者回退处理时，你需要扫描先前的部分，你可以clone并使用复制品，或者你在实现某种预编译处理，可以clone一些lexer来处理不同的输入文件。</p>%n<p>创建克隆跟重新调用<code>lex.lex()</code>的不同点在于，PLY不会重新构建任何的内部分析表或者正则式。当lexer是用类或者闭包创建的，需要注意类或闭包本身的的状态。换句话说你要注意新创建的lexer会共享原始lexer的这些状态，比如：</p><pre><code>m = MyLexer()%na = lex.lex(object=m)      %h Create a lexer%n%nb = a.clone()              %h Clone the lexer</code></pre>%n<p>&nbsp;</p><a name="4_17"></a>%n<h4><font style="font-weight: bold">4.17 Lexer的内部状态</font></h4>%n<p>lexer有一些内部属性在特定情况下有用：</p>%n<ul>%n<li><code>lexer.lexpos</code>。这是一个表示当前分析点的位置的整型值。如果你修改这个值的话，这会改变下一个<code>token()</code>的调用行为。在标记的规则方法里面，这个值表示紧跟匹配字串后面的第一个字符的位置，如果这个值在规则中修改，下一个返回的标记将从新的位置开始匹配 %n<li><code>lexer.lineno</code>。表示当前行号。PLY只是声明这个属性的存在，却永远不更新这个值。如果你想要跟踪行号的话，你需要自己添加代码（ <a href="%h4_6">4.6 行号和位置信息</a>） </li></ul>%n<li><code>lexer.lexdata</code>。当前lexer的输入字串，这个字符串就是input()方法的输入字串，更改它可能是个糟糕的做法，除非你知道自己在干什么。 %n<li><code>lexer.lexmatch</code>。PLY内部调用Python的re.match()方法得到的当前标记的原始的Match对象，该对象被保存在这个属性中。如果你的正则式中包含分组的话，你可以通过这个对象获得这些分组的值。注意：这个属性只在有标记规则定义的方法中才有效。 </font>%n<p>&nbsp;</p><a name="4_18"></a>%n<h4><font style="font-weight: bold">4.18 基于条件的扫描和启动条件</font></h4>%n<p>在高级的分析器应用程序中，使用状态化的词法扫描是很有用的。比如，你想在出现特定标记或句子结构的时候触发开始一个不同的词法分析逻辑。PLY允许lexer在不同的状态之间转换。每个状态可以包含一些自己独特的标记和规则等。这是基于GNU flex的“启动条件”来实现的，关于flex详见<a href="http://flex.sourceforge.net/manual/Start-Conditions.html%hStart-Conditions">http://flex.sourceforge.net/manual/Start-Conditions.html%hStart-Conditions</a></p>%n<p>要使用lex的状态，你必须首先声明。通过在lex模块中声明"states"来做到：</p><pre><code>states = (%n   ('foo','exclusive'),%n   ('bar','inclusive'),%n)</code></pre>%n<p>这个声明中包含有两个状态：'foo'和'bar'。状态可以有两种类型：'排他型'和'包容型'。排他型的状态会使得lexer的行为发生完全的改变：只有能够匹配在这个状态下定义的规则的标记才会返回；包容型状态会将定义在这个状态下的规则添加到默认的规则集中，进而，能够匹配这个状态下的规则的标记，以及能够匹配默认规则的标记都会返回。</p>%n<p>一旦声明好之后，标记规则的命名需要包含状态名：</p><pre><code>t_foo_NUMBER = r'\d+'                      %h Token 'NUMBER' in state 'foo'        %nt_bar_ID     = r'[a-zA-Z_][a-zA-Z0-9_]*'   %h Token 'ID' in state 'bar'%n%ndef t_foo_newline(t):%n    r'\n'%n    t.lexer.lineno += 1</code></pre>%n<p>一个标记可以用在多个状态中，只要将多个状态名包含在声明中：</p><pre><code>t_foo_bar_NUMBER = r'\d+'         %h Defines token 'NUMBER' in both state 'foo' and 'bar'</code></pre>%n<p>同样的，在任何状态下都生效的声明可以在命名中使用<code>ANY</code>：</p><pre><code>t_ANY_NUMBER = r'\d+'         %h Defines a token 'NUMBER' in all states</code></pre>%n<p>不包含状态名的情况下，标记被关联到一个特殊的状态<code>INITIAL</code>，比如，下面两个声明是等价的：</p><pre><code>t_NUMBER = r'\d+'%nt_INITIAL_NUMBER = r'\d+'</code></pre>%n<p>特殊的<code>t_ignore()</code>和<code>t_error()</code>也可以用状态关联：</p><pre><code>t_foo_ignore = " \t\n"       %h Ignored characters for state 'foo'%n%ndef t_bar_error(t):          %h Special error handler for state 'bar'%n    pass </code></pre>%n<p>词法分析默认在<code>INITIAL</code>状态下工作，这个状态下包含了所有默认的标记规则定义。对于不希望使用“状态”的用户来说，这是完全透明的。在分析过程中，如果你想要改变词法分析器的这种的状态，使用<code>begin()</code>方法： </p><pre><code>def t_begin_foo(t):%n    r'start_foo'%n    t.lexer.begin('foo')             %h Starts 'foo' state</code></pre>%n<p>使用<code>begin()</code>切换回初始状态：</p><pre><code>def t_foo_end(t):%n    r'end_foo'%n    t.lexer.begin('INITIAL')        %h Back to the initial state</code></pre>%n<p>状态的切换可以使用栈：</p><pre><code>def t_begin_foo(t):%n    r'start_foo'%n    t.lexer.push_state('foo')             %h Starts 'foo' state%n%ndef t_foo_end(t):%n    r'end_foo'%n    t.lexer.pop_state()                   %h Back to the previous state</code></pre>%n<p>当你在面临很多状态可以选择进入，而又仅仅想要回到之前的状态时，状态栈比较有用。</p>%n<p>举个例子会更清晰。假设你在写一个分析器想要从一堆C代码中获取任意匹配的闭合的大括号里面的部分：这意味着，当遇到起始括号'{'，你需要读取与之匹配的'}'以上的所有部分。并返回字符串。使用通常的正则表达式几乎不可能，这是因为大括号可以嵌套，而且可以有注释，字符串等干扰。因此，试图简单的匹配第一个出现的'}'是不行的。这里你可以用lex的状态来做到：</p><pre><code>%h Declare the state%nstates = (%n  ('ccode','exclusive'),%n)%n%n%h Match the first {. Enter ccode state.%ndef t_ccode(t):%n    r'\{'%n    t.lexer.code_start = t.lexer.lexpos        %h Record the starting position%n    t.lexer.level = 1                          %h Initial brace level%n    t.lexer.begin('ccode')                     %h Enter 'ccode' state%n%n%h Rules for the ccode state%ndef t_ccode_lbrace(t):     %n    r'\{'%n    t.lexer.level +=1                %n%ndef t_ccode_rbrace(t):%n    r'\}'%n    t.lexer.level -=1%n%n    %h If closing brace, return the code fragment%n    if t.lexer.level == 0:%n         t.value = t.lexer.lexdata[t.lexer.code_start:t.lexer.lexpos+1]%n         t.type = "CCODE"%n         t.lexer.lineno += t.value.count('\n')%n         t.lexer.begin('INITIAL')           %n         return t%n%n%h C or C++ comment (ignore)    %ndef t_ccode_comment(t):%n    r'(/\*(.|\n)*?*/)|(//.*)'%n    pass%n%n%h C string%ndef t_ccode_string(t):%n   r'\"([^\\\n]|(\\.))*?\"'%n%n%h C character literal%ndef t_ccode_char(t):%n   r'\'([^\\\n]|(\\.))*?\''%n%n%h Any sequence of non-whitespace characters (not braces, strings)%ndef t_ccode_nonspace(t):%n   r'[^\s\{\}\'\"]+'%n%n%h Ignored characters (whitespace)%nt_ccode_ignore = " \t\n"%n%n%h For bad characters, we just skip over it%ndef t_ccode_error(t):%n    t.lexer.skip(1)</code></pre>%n<p>这个例子中，第一个'{'使得lexer记录了起始位置，并且进入新的状态'ccode'。一系列规则用来匹配接下来的输入，这些规则只是丢弃掉标记（不返回值），如果遇到闭合右括号，t_ccode_rbrace规则收集其中所有的代码（利用先前记录的开始位置），并保存，返回的标记类型为'CCODE'，与此同时，词法分析的状态退回到初始状态。</p>%n<p>&nbsp;</p><a name="4_19"></a>%n<h4><font style="font-weight: bold">4.19 其他问题</font></h4>%n<ul>%n<li>lexer需要输入的是一个字符串。好在大多数机器都有足够的内存，这很少导致性能的问题。这意味着，lexer现在还不能用来处理文件流或者socket流。这主要是受到re模块的限制。 %n<li>lexer支持用Unicode字符描述标记的匹配规则，也支持输入字串包含Unicode %n<li>如果你想要向re.compile()方法提供flag，使用reflags选项：<code>lex.lex(reflags=re.UNICODE)</code> %n<li>由于lexer是全部用Python写的，性能很大程度上取决于Python的re模块，即使已经尽可能的高效了。当接收极其大量的输入文件时表现并不尽人意。如果担忧性能，你可以升级到最新的Python，或者手工创建分析器，或者用C语言写lexer并做成扩展模块。</ul>%n<p>如果你要创建一个手写的词法分析器并计划用在yacc.py中，只需要满足下面的要求：</p>%n<ul>%n<li>需要提供一个<code>token()</code>方法来返回下一个标记，如果没有可用的标记了，则返回None。 %n<li><code>token()</code>方法必须返回一个tok对象，具有<code>type</code>和<code>value</code>属性。如果行号需要跟踪的话，标记还需要定义<code>lineno</code>属性。</ul>#【译】PLY手册Lex部分#postlayout#PLY是基于Python的lex和yacc实现，由David Beazley开发并维护。相比C语言版的lex和yacc，发挥了Python的语言特点，使得开发类似编译器或解释器变得更轻松。本文是其文档的Lex部分#Open-Source-Software-.jpg#[open-source]#[PLY,Python,Lex,Yacc]#2014-01-18 17:19:28#2014-01-18 18:42:24#