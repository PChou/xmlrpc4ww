id#filename#content#title#layout#description#thumbimg#categories#tags#createdate#moddate#
inc#str#str#str#str#str#str#str#str#str#str#
1#filename#content#title#layout#description#thumbimg#categories#tags#createdate#moddate#
4#2013-10-23-526712a543031.html#<h1>缘起</h1> <p>在之前的文章<a href="http://pchou.info/web-build/2013/01/20/build-github-blog-page-07.html">一步步在GitHub上创建博客主页(7)--兼容Windows Writer的服务提供器</a>中，为了使编写博客和发布博客更加方便，我实现了一个windows writer的服务提供器，基于.NET和XML-RPC.NET。在实际使用过程中其实遇到不少问题，比如文章的二次编辑修改将无法支持，多个windows writer客户端无法同步编辑，提供器部署复杂等。思考下来觉得还是得有数据库支持，而且要尽可能的方便部署和同步数据。于是决定用PHP重新实现一个，PHP有以下特点：</p> <ul> <li>轻巧，部署方便  <li>能够轻便的支持基于文本的数据库，可以实现多客户端“分布式编辑”</li></ul> <p>&nbsp;</p> <h1>系统运作方式</h1> <p>假设用户现在只有一台PC1用来写blog，系统运行机制如下：</p> <p><img style="background-image: none; border-right-width: 0px; padding-left: 0px; padding-right: 0px; display: inline; border-top-width: 0px; border-bottom-width: 0px; border-left-width: 0px; padding-top: 0px" class="img-responsive" title="image" border="0" alt="image" src="http://fakelocalhost/assert/img/2013-10-23-5267cbc7d3656.png" width="313" height="440"></p> <ol> <li>在PC1上克隆好了github page的项目  <li>用户在PC1上部署一个PHP站点，并配置指向上面的github page的项目目录  <li>在PC1上使用windows writer配置这个站点为日志帐户  <li>在PC1上使用windows writer编写文章  <li>在PC1上将文章发布到PHP站点  <li>打开PHP站点的页面，修改分类、标签等必要信息，点击发布，PHP站点将把文章创建在github page的项目目录的对应文件夹中（包括图片）  <li>（可选）用jekyll测试页面，返回4，直到满意  <li>在PC1上使用git将github page的项目push到github</li></ol> <p>图中黄色的2、3步骤是一次性的配置工作，以后不需要重复进行。另外可以看到这里的PHP站点起到了“代理”的作用，因为github不能支持windows writer嘛，所以只能依靠代理了；而且这个代理是在你PC本机的，链接你的Writer和本地的仓库。</p> <p>&nbsp;</p> <p>如果你在家中和公司各有一台PC，可能希望在两台PC上都能编写博客，甚至发布博客，而这个代理是本机的，如何能实现在博客正式发布前”共享“呢？答案是文本数据库。来看多客户端情况下的工作机制（左边是之前的PC1）：</p> <p><img style="background-image: none; border-right-width: 0px; padding-left: 0px; padding-right: 0px; display: inline; border-top-width: 0px; border-bottom-width: 0px; border-left-width: 0px; padding-top: 0px" class="img-responsive" title="image" border="0" alt="image" src="http://fakelocalhost/assert/img/2013-10-23-5267ce0633ef9.png" width="545" height="426"></p> <ul style="list-style-type: none"> <li>1.这个PHP站点包含一个基于文本的数据库，用来存放每一篇发布到PHP站点的文章。<font color="%hff0000">并将这个PHP站点本身作为一个仓库推送到github</font>  <li>2.在另一台PC2上克隆或拉取仓库代码（包括文本数据库）  <li>3～5步跟上面的1～3相同，克隆或拉取github page所在仓库，配置PHP站点，配置writer  <li>6.利用writer的”打开远程文章“的功能，从PHP站点上得到文章标题、内容等  <li>7.继续编辑文章  <li>8.将文章发布到PHP站点  <li>9.打开PHP站点的页面，修改分类、标签等必要信息，点击发布，PHP站点将把文章创建在github page的项目目录的对应文件夹中（包括图片）  <li>10.（可选）用jekyll测试页面，返回7，直到满意  <li>11.在PC2上使用git将github page的项目push到github</li></ul> <p>&nbsp;</p> <p>通过上面的步骤可以继续编辑文章，达到共享的目的。起作用的关键其实是，PHP站点利用文本数据库和站点本身作为仓库这两点，保存了在PC1上的文章内容，可供PC2克隆或拉取。同理，也可以将PC2的PHP站点（及其数据文件）推送到github上，供PC1继续编辑发布。</p> <p>&nbsp;</p> <p>本文介绍了系统的工作机制。虽说有了这套东西，写博客会方便不少，但是操作还是比较琐碎的，因此需要对工作机制有比较清晰的了解，这对于用户来说是十分重要的。下一篇将指导用户具体操作过程。</p>#基于PHP的Windows Writer服务提供器--介绍#postlayout#介绍一个支持Windows Writer的PHP服务的实现和运行机制，有了这个PHP服务，用Writer来编写博客，插入图片就简单方便许多了。#1346208288725.jpg#[web-build]#[PHP,github-page]#2013-10-23 08:04:53#2013-10-27 22:01:24#
5#2013-10-23-5267e1c65917c.html#<p>在<a href="http://pchou.info/web-build/2013/10/23/526712a543031.html" target="_blank">上一篇</a>中介绍了系统的运行机制，本文将引导读者一步步部署并使用。首先，假设您已经完成了github博客的搭建工作，并理解基本的博客维护方式以及jekyll的基本原理和使用方法。</p> <p>&nbsp;</p> <h2>部署本地的PHP站点</h2> <p>PHP项目的主页地址：<a href="https://github.com/PChou/xmlrpc4ww">https://github.com/PChou/xmlrpc4ww</a></p> <p>用您自己的帐户登录github，在浏览器中键入上述地址，点击页面右上方的<code>Fork</code>。Fork的意思是将这个项目复制到您自己的代码仓库中，您就可以自由的修改编辑了，还能在需要的时候对原代码仓库贡献代码，或者同步原代码仓库的变化。</p> <p>将Fork出来的仓库clone到本地,，这地址应该像下面这样：</p><pre>git clone https://github.com/<em>{yourusername}</em>/xmlrpc4ww.git</pre>%n<p>项目目录中的文件结构如下（省略无关紧要的文件）</p><pre>/xmlrpc4ww%n  |--content //存放js和css%n  |--db%n      |--blog	//文本数据库%n           |--__blogs.txt //数据文件模板%n           |--blogs.txt	//数据文件%n  |--txtdb	//文本数据库支持库%n  |--xmlrpc	//xmlrpc api支持库%n  |--__config.php   //配置文件模板%n  |--post.php       //文章发布页面%n  |--postlist.php   //文章列表页面%n  |--server.php     //writer服务提供页面和文章列表入口%n  |--util2.php      //支持方法%n</pre>%n<p>将__config.php在同一目录复制一份，取名为<code>config.php</code>，修改config.php：</p><pre>define("LOCALPATH", "D:\\Project\\Git\\NRemedy");    \\本地github page项目所在目录，注意双斜杠%ndefine("IMGPATH", "assert\\img");		     \\图片的相对路径，此处就表示我的博客的图片规划在D:\Project\Git\NRemedy\assert\img下，注意双斜杠%ndefine("IMGPATH2", "/assert/img/");		     \\图片的url相对路径，与上面应对应，但注意斜杠的方向%n%ndefine("DEFAULT_LAYOUT", "postlayout");		      \\每个post的jekyll模板使用的默认的layout名称，配置这个后可以简化将来发布填写的东西%n%ndefine("BLOGNAME", "ghpage");			     \\blog名称，可以不作修改%ndefine("BLOGID","67322");			     \\blogid，可以不作修改%ndefine("BLOGURL","http://fakelocalhost");            \\blog地址，不要修改，保持fakelocalhost%n%n%n</pre>%n<p><font color="%hff0000">注意：上面的前三项务必配置准确，否则将无法正常使用</font></p>%n<p>删除<code>db/blog/blogs.txt</code>，将<code>__blogs.txt</code>重命名为<code>blogs.txt</code>。原先的blogs.txt是我的文章数据库，您需要的是空的数据库文件，所以从__blogs.txt这个空的数据文件模板开始，完成之后您的目录结构将是这样：</p><pre>/xmlrpc4ww%n  |--content //存放js和css%n  |--db%n      |--blogs	//文本数据库%n           |--blogs.txt	//空数据文件%n  |--txtdb	//文本数据库支持库%n  |--xmlrpc	//xmlrpc api支持库%n  |--config.php     //配置文件模板%n  |--post.php       //文章发布页面%n  |--postlist.php   //文章列表页面%n  |--server.php     //writer服务提供页面和文章列表入口%n  |--util2.php      //支持方法%n</pre>%n<p>接下来要做的是配置一个php运行环境，如果您已经配置过php环境，那么恭喜你，可以跳过这个步骤了。下载并安装php环境，读者可参考<a href="http://www.cnblogs.com/zengxiangzhan/archive/2010/03/05/1679286.html">http://www.cnblogs.com/zengxiangzhan/archive/2010/03/05/1679286.html</a></p>%n<p>&nbsp;</p>%n<p>在IIS中创建一个站点，指向xmlrpc4ww，启动该网站，并用浏览器访问<a href="http://localhost{:port}/server.php">http://localhost<em>{:port}</em>/server.php</a>，看到如下页面说明php站点部署完毕（请注意，您的端口可能与我不同）</p>%n<p><img style="background-image: none; border-right-width: 0px; padding-left: 0px; padding-right: 0px; display: inline; border-top-width: 0px; border-bottom-width: 0px; border-left-width: 0px; padding-top: 0px" class="img-responsive" title="559EHMUA36]Z76X}}OP0V`L" border="0" alt="559EHMUA36]Z76X}}OP0V`L" src="http://fakelocalhost/assert/img/2013-10-23-5267e1c64ed6a.jpeg" width="638" height="28"> %n<p>&nbsp;</p>%n<h2>配置Windows Writer</h2>%n<p>点击“添加日志帐户”，选择“其他服务”</p><img style="display: inline" class="img-responsive" title="image" alt="image" src="http://fakelocalhost/assert/img/2013-01-20-build-github-blog-page-07-img1.png" width="403" height="379"> %n<p>按照下图输入日志网址，注意，你本机的PHP站点的端口可能与我不同，用户名和密码随便填，无所谓，暂时不要记住密码</p>%n<p><img style="background-image: none; border-right-width: 0px; padding-left: 0px; padding-right: 0px; display: inline; border-top-width: 0px; border-bottom-width: 0px; border-left-width: 0px; padding-top: 0px" class="img-responsive" title="image" border="0" alt="image" src="http://fakelocalhost/assert/img/2013-10-24-52692c3153e36.png" width="398" height="375"></p>%n<p>点击“下一步”，按下图填写，注意这里的远程发布网址是关键点，必须填写正确，还是一样，请注意您本机的端口可能与我不同</p>%n<p><img style="background-image: none; border-right-width: 0px; padding-left: 0px; padding-right: 0px; display: inline; border-top-width: 0px; border-bottom-width: 0px; border-left-width: 0px; padding-top: 0px" class="img-responsive" title="image" border="0" alt="image" src="http://fakelocalhost/assert/img/2013-10-24-52692c315bb38.png" width="402" height="379"></p>%n<p>点击“下一步”，windows writer会开始检测服务端设置</p>%n<p><img style="background-image: none; border-right-width: 0px; padding-left: 0px; padding-right: 0px; display: inline; border-top-width: 0px; border-bottom-width: 0px; border-left-width: 0px; padding-top: 0px" class="img-responsive" title="image" border="0" alt="image" src="http://fakelocalhost/assert/img/2013-10-24-52692c3165392.png" width="403" height="380"></p>%n<p>最后会成功提示如下，可以点击Yes，发布一个测试日志，如下图。至此Writer和PHP站点打通了</p>%n<p><img style="background-image: none; border-right-width: 0px; padding-left: 0px; padding-right: 0px; display: inline; border-top-width: 0px; border-bottom-width: 0px; border-left-width: 0px; padding-top: 0px" class="img-responsive" title="image" border="0" alt="image" src="http://fakelocalhost/assert/img/2013-10-24-52692c316efd4.png" width="419" height="179"></p>%n<p>将来发布日志的时候请选择ghpage发布</p>%n<p><img style="background-image: none; border-right-width: 0px; padding-left: 0px; padding-right: 0px; display: inline; border-top-width: 0px; border-bottom-width: 0px; border-left-width: 0px; padding-top: 0px" class="img-responsive" title="image" border="0" alt="image" src="http://fakelocalhost/assert/img/2013-10-24-52692c317594e.png" width="220" height="84"> %n<p>&nbsp;</p>%n<h2>将日志发布到本地的gh-page</h2>%n<p>用浏览器访问<a href="http://localhost{:port}/server.php">http://localhost<em>{:port}</em>/server.php</a>，应该看到多出一条记录，这条记录就是刚刚发布的临时日志。点击“编辑和发布”，显示类似下面的页面</p>%n<p><img style="background-image: none; border-right-width: 0px; padding-left: 0px; padding-right: 0px; display: inline; border-top-width: 0px; border-bottom-width: 0px; border-left-width: 0px; padding-top: 0px" class="img-responsive" title="JWAF752I~RH(OCJT5(`P`NT" border="0" alt="JWAF752I~RH(OCJT5(`P`NT" src="http://fakelocalhost/assert/img/2013-10-24-52692c317c2c7.jpeg" width="295" height="267"> %n<p>我们知道基于jekyll的post都应该有如下开头： <pre>---%nlayout: postlayout%ntitle: Hello GitHub!%ndescription: 该博客的开篇之文%nthumbimg: 1346208288725.jpg%ncategories: [life]%ntags: [github-page, jekyll]%n---%n</pre>%n<p>其中layout、title、categories、tags是jekyll默认支持的变量， 而且categories和tags有特定的格式。用户也可以自定义变量，可以在jekyll的post对象中获得这些变量。上面的description和thumnimg都是我自定义的变量，分别用于显示摘要和首页缩略图。 %n<p>与之对应的，上面的页面就是用来配置这些变量的。 %n<ul>%n<li>文件名是自动生成的，如果要修改的话请保持jekyll的日期规则，而且点击“保存并生成”后尽量不要再修改，否则，会生成两个日志； %n<li>标题来源于Writer中的标题，不能修改，只能由Writer发布上来； %n<li>layout的默认值来源与上面对PHP部署时的基础配置，应该修改成你希望的layout文件名； %n<li>分类和标签，请自行添加，但要符合jekyll规则</li></ul>%n<blockquote>%n<p>如果您的变量与我不同的话，需要自己修改php代码和数据库文件来支持。如果您希望修改的话，请将你fork的仓库地址发在下面的留言板里面，我可能考虑帮你修改。当然也许将来的版本我会发布一个可配置的版本</p></blockquote>%n<p>配置完成后，点击“保存并生成”，如果显示“成功”的话，恭喜您，文章已经在您本地的git仓库中拉。</p>%n<p>接下来您可以用本地的jekyll测试和发布你刚刚发布的文章，具体可以参考<a href="http://pchou.info/web-build/2013/01/05/build-github-blog-page-04.html">一步步在GitHub上创建博客主页(4)</a>以及相关的系列文章 %n<p>让我们来查看一下/xmlprc4ww/db/blogs.txt，此时，该文件应该已经包含了刚刚发布的日志以及post变量的配置等。顺便说一下，这个文件就是blogs的数据库文件，将来Writer从PHP站点获取或者写入的日志内容都将存放在这个文件中。 该文件除了前三行外，其他行都是数据，每一行由多个字段组成，每个字段用”%h“区隔，详见：<a href="http://www.c-worker.ch/txtdbapi/index.php">http://www.c-worker.ch/txtdbapi/index.php</a>&nbsp; <h2>&nbsp;</h2>%n<h2>编辑修改文章 </h2>%n<p>如果您的文章已经从Writer发布到PHP站点，甚至是发布到了github，但是此时需要修改一下，怎么办呢？很简单，您只需要在Writer中打开需要修改的文章，编辑好之后，点击发布，循环上面的步骤就可以了。 %n<blockquote>%n<p>您可能会发现再次打开后图片无法正常显示，这没关系，如果这导致Writer崩溃的话，请下载最新的Writer客户端；另外如果文章有图片的话在发布前请将图片“格式”设置成“链接至无”，否则会有两张图片上传到服务端</p></blockquote>%n<p>如果您只是用上面配置好的机器来编写博客的话，至此就足够了，下面介绍多客户端该怎么协同编辑。 %n<p>&nbsp; <h2>多客户端编辑</h2>%n<p>也许读者已经猜到了，没错，只要将xmlrpc4ww这个项目也push到github的仓库就可以了！上文提到，xmlprc4ww/db/blogs.txt保存了文章的内容，该内容是与本地Writer的内容同步的，于是只要将这个文件push到github上，然后在另外一台机器上pull过来，并且重复一次配置工作（包括站点配置、writer配置）就可以获得文章内容了。而在Writer的客户端上只要点击“打开最近使用过的日志”就可以从“另一个服务端”上获取文章内容了： %n<p><img style="background-image: none; border-right-width: 0px; padding-left: 0px; padding-right: 0px; display: inline; border-top-width: 0px; border-bottom-width: 0px; border-left-width: 0px; padding-top: 0px" class="img-responsive" title="image" border="0" alt="image" src="http://fakelocalhost/assert/img/2013-10-24-52692c3183411.png" width="390" height="285"> %n<blockquote>%n<p>特别需要注意的是，您PC2上的日志仓库可能与PC1不同，在配置PHP站点的时候需要特别留意 </p></blockquote>%n<p>&nbsp;</p>%n<h2>删除文章</h2>%n<p>xmlrpc4ww没有实现删除的功能，您可能需要手动完成，除了把github page所在的仓库中的日志文件和对应图片删除外，还需要删除xmlprc4ww/db/blogs.txt中的对应记录行。</p>%n<p>&nbsp;</p>%n<p>本文详细介绍了<a href="https://github.com/PChou/xmlrpc4ww" target="_blank">xmlrpc4ww</a>这个工具的使用方法，如果读者有任何问题，可以给我发邮件或者在下面留言，您的意见或建议是完善这个工具重要的途径，当然您也可以帮忙共享您的代码，发扬开源精神。</p>#基于PHP的Windows Writer服务提供器--如何使用#postlayout#详细描述如何配置php站点、如何配置Windows Writer、如何发布文章等细节#1346208288725.jpg#[web-build]#[PHP,github-page]#2013-10-23 22:48:38#2013-10-27 22:02:10#
6#2013-10-27-526d0f1648b1d.html#<p>公司部署网络环境，安装Esxi，去电脑城配了两台台式机当服务器，为了充分利用资源，准备安装Esxi。以前在公司里面也用PC装过Esxi，从来没有出过岔子。但是这次出了不少岔子。  <p>先是没有安装光盘，但是这个很快通过U盘引导解决了。具体使用的是一个叫unetbootin-windows-latest.exe工具，可以一键将iso写入U盘：  <p><img style="background-image: none; border-right-width: 0px; padding-left: 0px; padding-right: 0px; display: inline; border-top-width: 0px; border-bottom-width: 0px; border-left-width: 0px; padding-top: 0px" title="Image" border="0" alt="Image" src="http://fakelocalhost/assert/img/2013-10-27-526d0f162be26.png" width="449" height="332">  <p>然后，在安装过程中，报错说无法找到Network Adapter，寻寻觅觅，得知可能是vmware提供的安装包中没有我的网卡驱动，从这里可以查看自己的网卡是否被支持  <p><a href="http://www.vmware.com/resources/compatibility/search.php?deviceCategory=io">http://www.vmware.com/resources/compatibility/search.php?deviceCategory=io</a>  <p>如果不被支持的话必须，有三种解决途径  <p>1、如果是正规的品牌服务器的话，可以从服务器提供的光盘中找找有没有Esxi安装镜像，一般dell和hp都有提供各自定制化过的iso  <p>2、如果没有人家做好的iso的话，可以自己来做，去vmware网站上找驱动，然后用vmware提供的定制化iso工具ESXi-Customizer-v2.7.1，生成添加过驱动的iso  <p><img style="background-image: none; border-right-width: 0px; padding-left: 0px; padding-right: 0px; display: inline; border-top-width: 0px; border-bottom-width: 0px; border-left-width: 0px; padding-top: 0px" title="Image(1)" border="0" alt="Image(1)" src="http://fakelocalhost/assert/img/2013-10-27-526d0f1633f10.png" width="449" height="286">  <p>3、上面两种方法都没有成功的话，只能考虑重新购买被支持的网卡，intel的千兆网卡一般都支持，笔者从电脑城弄了一块就OK了  <p>网卡关过了以后，又碰到无法找到硬盘的问题，这个问题可能是由于两个原因：  <p>1、如果是用U盘引导的，在loading界面结束后，U盘就可以拔掉了，否则可能只识别出U盘  <p>2、可能需要在BIOS中设置SATA的工作方式为AHCI  <p>最后，还会有个警告说硬件不支持虚拟化技术，这时，需要将BIOS中的CPU开启虚拟化支持，具体操作由于BIOS版本很杂，自己找吧  <p>Esxi5.1激活码0F0KM-FLL4L-NZHG1-1CA56-9CU4J  <p>输入激活码的方法是在vSphere Client中，选择“配置”，然后选“已获选可的功能”，再点“编辑”就能看到输入序列号的界面了。  #Esxi安装手记#postlayout#网卡驱动、硬盘模式、CPU模式是安装Esxi经常碰到的问题。本文记录了实际在部署Esxi的时候碰到的这些困难和解决方案。#image0021229433128273.jpg#[hardware]#[Esxi,iso,Driver]#2013-10-27 21:03:18#2013-10-27 21:03:18#
7#2013-11-07-527ba36a16888.html#<p>数据库是一种十分复杂的软件，它为用户提供了可靠的数据存储与查询机制，本文将来探讨一下其中的“可靠存储”这个问题。数据库的可靠存储特性主要体现在如下几个方面：</p> <ol> <li>当出现硬件错误时，保证数据的一致性  <li>保证一系列的操作是原子的，要么成功要么失败  <li>当数据备份多处时，保证不同数据备份的一致性</li></ol> <p>&nbsp;</p> <h2>单库事务控制，预写日志</h2> <p>数据一致性经常也被称为“事务一致性”，也就是保证一系列的操作，要么都成功要么都失败。例如有下面的关系数据表，存储了用户的账户信息：</p> <table class="table"> <tbody> <tr> <td valign="top" width="133"><strong>账户名称</strong></td> <td valign="top" width="133"><strong>账户类型</strong></td> <td valign="top" width="133"><strong>账户余额</strong></td></tr> <tr> <td valign="top" width="133">扎迪</td> <td valign="top" width="133">支票</td> <td valign="top" width="133">800</td></tr> <tr> <td valign="top" width="133">扎迪</td> <td valign="top" width="133">存款</td> <td valign="top" width="133">300</td></tr> <tr> <td valign="top" width="133">皮德罗</td> <td valign="top" width="133">支票</td> <td valign="top" width="133">150</td></tr></tbody></table> <p>现在希望将扎迪的支票账户中的200元转移到扎迪存款账户里，最终结果希望是</p> <table class="table"> <tbody> <tr> <td valign="top" width="133"><strong>账户名称</strong></td> <td valign="top" width="133"><strong>账户类型</strong></td> <td valign="top" width="133"><strong>账户余额</strong></td></tr> <tr> <td valign="top" width="133">扎迪</td> <td valign="top" width="133">支票</td> <td valign="top" width="133"><font color="%hff0000"><strong>600</strong></font></td></tr> <tr> <td valign="top" width="133">扎迪</td> <td valign="top" width="133">存款</td> <td valign="top" width="133"><font color="%hff0000"><strong>500</strong></font></td></tr> <tr> <td valign="top" width="133">皮德罗</td> <td valign="top" width="133">支票</td> <td valign="top" width="133">150</td></tr></tbody></table> <p>那么，我们需要将这个任务分两步来执行：</p> <ol> <li>先将扎迪的支票账户更新为600  <li>再将扎迪的存款账户更新为500</li></ol> <p>但是，如果这两个步骤不能保证，要么同时成功要么同时失败的话，将出现很严重的后果。比如：当完成第一步后，突然断电了，扎迪会发现他的支票账户少了200元，但是存款账户仍然是300，凭空少了200元！尽管说，像断电这样的都是小概率事件，但是在上面这个例子中是绝对不被允许的。</p> <p>在数据库中为了解决这个问题，提出了事务的概念，程序员可以将两个步骤包装在一个事务中提交给数据库，数据库能够保证“事务一致性”。这样神奇的效果是如何实现的呢？其实原理很简单，就是所谓的“<strong>预写日志</strong>”，我们来看下具体的过程</p> <p>程序员在程序中依次将下面的指令发送给数据库，以完成更新</p> <ol> <li>开始事务  <li>将扎迪的支票账户余额<font color="%hff0000"><strong>变为600</strong></font>  <li>将扎迪的存款账户余额<strong><font color="%hff0000">变成500</font></strong>  <li>结束事务</li></ol> <p>这些指令被数据库程序接收后，将在转化为如下操作：</p> <ol> <li>开始事务  <li>将扎迪的支票账户余额<font color="%hff0000"><strong>从800变为600</strong></font>  <li>将扎迪的存款账户余额<strong><font color="%hff0000">从300变成500</font></strong>  <li>结束事务</li></ol> <p>数据库并不是立刻执行事务中的操作，而是将这些操作依次写入“预写日志”，预写日志是保存在磁盘上的。随后，数据库程序将执行“预写日志”中的内容，将更新操作体现在数据文件中。在正常的情况下，当完成“结束事务”操作后，删除上面的日志，并告知程序执行成功，这样，正常的操作就完成了。（有些数据库会在日志删除前再次写入“归档日志”中，以便可以通过归档日志恢复整个库）</p> <p>这里有一个需要注意的问题，程序在将事务操作发送给数据库的过程中，数据库也可能崩溃，也就是说“预写日志”可能记录不完整。这样，当数据库从崩溃中重启后可能发生的两种情况：</p> <ul> <li>数据库崩溃重启后，查看预写日志，发现一个事务，并且该事务的最后一个操作是“结束事务”。那么此时可以推断：这个事务有可能执行成功了，但日志没来得及删除；也有可能这个事务没有执行完，甚至还没有执行。不过无论如何，数据库将进行“<font color="%hff0000"><strong>前滚</strong></font>”恢复，将事务中剩下操作执行一遍。但是问题是，怎么才能知道究竟执行到哪一步了呢？事实上，这一点根本不重要，因为哪怕重新回放整个预写日志中的内容也仍然可以达到一致性。对于这种无论执行多少次都不会影响最终结果的特性称为“<font color="%hff0000"><strong>幂等</strong></font>”。  <li>数据库崩溃重启后，查看预写日志，发现一个事务，并且该事务的最后一个操作不是“结束事务”。那么可以推断：可能是程序指令在发送到数据库的过程中，数据库崩溃了，而且事务一定没有正确执行。这个时候由于无法确定，这个事务后面时候还有其他的操作没有接收，所以数据库只能执行“<font color="%hff0000"><strong>回滚</strong></font>”恢复，将已经在日志中的操作反过来恢复。读者可能已经注意到了，数据库在记入预写日志的时候，不仅记录的新值，同时还记录的原值，这样就能将数据回退到初始状态。</li></ul> <p>这里实际上解释了两个概念：前滚和回滚，这是数据库事务控制中很重要的概念，读者可以自行查询其他资料以便了解更多的细节。</p> <p>&nbsp;</p> <h2>跨库事务控制，二阶段提交</h2> <p>在很多数据库系统中，不仅支持单库的事务一致性，还支持多个库的事务一致性，虽然不同的数据库产品在实现这个功能的时候，所使用的细节技术不同，但是大致都是采用了”二阶段提交“这个方法，下面我们来看下它是如何工作的。</p> <p>一般来说，多个库中在一次事务中需要有一个事务发起者，称为”主库”，其他的库称为“从库”。假设需要执行一个在所有库的某个表中插入一行数据的事务。</p> <ul> <li>第一阶段，主库锁定表，并将事务写入自己的预写日志；主库将事务发给从库，从库也各自锁定自己的表，并把事务写入预写日志，完成后返回告诉主库一阶段完成  <li>第二阶段，主库开始执行自己的事务，并通知从库提交事务。如果在这个过程中没有任何错误，那么操作将在多个库中完成；如果发生错误，比如从库锁表失败，或者从库没有响应，或者从库磁盘满…主库将通知所有参与事务的从库回滚该事务，并且回滚主库的事务。回滚就是根据预写日志的内容回滚事务的操作，可见预写日志的重要性。</li></ul> <p>下图分别展示了两种过程</p> <p><img style="background-image: none; border-right-width: 0px; padding-left: 0px; padding-right: 0px; display: inline; border-top-width: 0px; border-bottom-width: 0px; border-left-width: 0px; padding-top: 0px" class="img-responsive" title="WOTV@KHBEKPVL2IP7{1LAVN" border="0" alt="WOTV@KHBEKPVL2IP7{1LAVN" src="http://fakelocalhost/assert/img/2013-11-10-527ef3942296b.jpeg" width="270" height="552">  <p>成功的二阶段提交，A为主库，B、C为从库  <p><img style="background-image: none; border-right-width: 0px; padding-left: 0px; padding-right: 0px; display: inline; border-top-width: 0px; border-bottom-width: 0px; border-left-width: 0px; padding-top: 0px" class="img-responsive" title="WPNN6Z0_VS9RVUMJ`}UCBO8" border="0" alt="WPNN6Z0_VS9RVUMJ`}UCBO8" src="http://fakelocalhost/assert/img/2013-11-10-527ef39432b3f.jpeg" width="271" height="553">  <p>失败的二阶段提交，A为主库，B、C为从库</p> <p>&nbsp;</p> <h2>总结</h2> <p>可见，“预写日志”对于事务前滚或回滚来说是非常重要的，这个精巧的设计保证了数据库的“一致性”，进而保证了“可靠存储”。而“二阶段提交”也是一个十分精巧而简单的方法，在数据库的“主从复制”、“跨库事务”等方面都有应用。</p> <p>不过事实上，上面的讨论都是基于单用户的，但数据库还需要解决多用户并发问题，这是通过“锁”的机制来实现的，锁也同样重要，不过本文不再阐述。</p>#数据库一致性原理浅析#postlayout#数据库一致性是数据库非常重要的特性，高端的数据库产品往往也是在一致性上，下了很多功夫，本文从单库一致性和多库一致性两个方面介绍了数据库的实现原理#W020110914489795789471.jpg#[algorithm]#[database,consistency]#2013-11-07 22:27:54#2013-11-10 11:04:03#
8#2013-11-10-527f6ec41d6ad.html#<p>Require.js是一个支持javascript模块化编程的类库，不了解的读者请移步至：<a href="http://www.ruanyifeng.com/blog/2012/11/require_js.html" target="_blank">Javascript模块化编程（三）：require.js的用法</a>。</p> <p>require在单页面应用中能够如鱼得水，然而对于传统的多页面应用，使用require多少会有些困惑和不方便。</p> <p>多页面应用的一个典型的例子是<a href="https://github.com/requirejs/example-multipage">https://github.com/requirejs/example-multipage</a>，读者可以clone下来参考。本文参考这个例子在ASP.NET MVC的结构中应用require，并且给出了压缩脚本，实现半自动化压缩。</p> <h2>将js代码分离</h2> <p>一般而言ASP.NET MVC的一个路由对应一个视图，视图的文件结构可能如下：</p><pre>Views%n |--Shared%n     |--_layout.cshtml%n |--Home%n     |--Index.cshtml%n |--Blog%n     |--Create.cshtml%n     |--Edit.cshtml%n     |--Detail.cshtml%n     |--Index.cshtml%n</pre>%n<p>这里假设<code>_layout.cshtml</code>是所有页面共享的。一般情况下，我们会在_layout中引用公共的js类库，比如<strong>jQuery</strong>，<strong>bootstrap</strong>等，这样的话其他的页面就不需要对这些类库再引用一遍，提高了编码的效率。然而，不同的页面终究会依赖不同的js，尤其是实现页面本身功能的自定义的js，这样我们不得不在其他页面中再引用特殊的js，甚至将js直接写在页面中，例如下面的代码经常会出现在View中：</p><pre>&lt;script type="text/javascript"&gt;%n   $(function(){...});%n&lt;/script&gt;%n</pre>%n<p>这样会导致页面比较混乱，而且页面&lt;script&gt;标签中代码不能被浏览器缓存，增加了页面代码的长度。更为重要的缺陷是，诸如jQuery之类的类库会在加载到页面后执行匿名函数，这需要一些时间，而如果有些页面根本不需要jQuery的话，只要页面把_layout作为布局页面，那么jQuery的初始化代码将不可避免的执行，这是一种浪费。事实上，javascript的模块化加载的思想就是为了解决这些问题的。</p>%n<p>接下来我们来用require规划我们的js，构建诸如下面结构的js目录</p><pre>js%n|--app%n    |--home.index.js%n    |--blog.create.js%n    |--blog.edit.js%n    |--blog.detail.js%n    |--blog.index.js%n|--jquery.js%n|--bootstrap.js%n|--underscore.js%n|--jquery.ui.js%n|--jquery.customplugin.js%n|--config.js%n|--require.js%n</pre>%n<p>把公共的类库级别的js模块直接放在js目录下，而把页面级别的js放在一个app的子目录下。注意，在app中，每个页面一个js文件，这意味着我们需要把页面各自的js提取出来，虽然这样增加了结构复杂度，但是避免了在页面中随手写&lt;script&gt;标签的陋习。另外，在js目录下的公共库，除了第三方的库，还包括自己开发的库，还有一个叫<code>config.js</code>的文件，这个文件很关键，稍后会说到。</p>%n<p>然后，我们可以删除_layout中所有的js引用，并使用@RenderSection的命令要求子页面提供js引用：</p>%n<p><em><font color="%hff0000">_layout.cshtml</font></em></p><pre>&lt;head&gt;%n...%n@RenderSection("require_js_module", false)%n...%n&lt;/head&gt;%n</pre>%n<p>这样对js的需求就下放到每个view页面中了，根据require的用法，我们需要在各个子View中引用require.js，并指定主模块，而这些主模块就是上面app目录下的一个个js</p><pre>@section require_js_module{%n    &lt;script src="@Url.Content("~/js/require.js")" data-main="@Url.Content("~/js/app/home.index.js")" &gt;&lt;/script&gt;%n}%n</pre>%n<p>所有的js代码都将写到app下的js中，这样规范了js，使得页面更干净，更为重要的是这些js还可以经过压缩，以及被浏览器缓存等，进一步提高执行效率</p>%n<h2>公共的config</h2>%n<p>我们知道主模块除了使用<code>require</code>方法外，经常需要通过<code>require.config</code>来配置其他模块的路径，甚至需要<code>shim</code>，例如下面的代码经常会出现在主模块的开头：</p><pre>require.config({%n	paths: {%n　　　　　　"jquery": "lib/jquery.min",%n　　　　　　"underscore": "lib/underscore.min",%n　　　　　　"backbone": "lib/backbone.min"%n　　　　},%n　　　　shim: {%n　　　　　　'underscore':{%n　　　　　　　　exports: '_'%n　　　　　　},%n　　　　　　'backbone': {%n　　　　　　　　deps: ['underscore', 'jquery'],%n　　　　　　　　exports: 'Backbone'%n　　　　　　}%n　　　　}%n　　});%n</pre>%n<p>对于单页面应用来说，主模块往往只有一个，所以上面的代码写一遍也就OK了。但是，在多页面的情况下，主模块有多个，每个主模块都要包含这样的代码，岂不是很不科学？于是，希望有一个统一配置的地方，但是应该如何来写呢？我们想到，将这些配置作为一个模块config.js，让其他的主模块对这个模块产生依赖就可以了，例如下面的config.js：</p>%n<p><em><font color="%hff0000">config.js</font></em></p><pre>requirejs.config({%n	paths: {%n　　　　　　"jquery": "/js/jquery.min",%n	    "bootstrap": "/js/bootstrap"%n　　　　},%n　　　　shim: {%n	    'bootstrap': {%n                deps: ['jquery'],%n                exports: "jQuery.fn.popover"%n            }%n　　　　}%n　　});%n%n</pre>%n<p>config.js的写法没有什么特别的，接下来只要在home.index.js中引用</p>%n<p><em><font color="%hff0000">home.index.js</font></em></p><pre>require(['../config','jquery', 'bootstrap'], function () {%n    //main module code here%n%n});%n</pre>%n<p>不过这样写还是不对的，因为，被主模块依赖的模块(这里的config,jquery,bootstrap)，在加载的时候，加载顺序是不确定的，但是又需要config模块在其他模块之前加载，怎么办呢？一个折衷的方案是修改home.index.js，成为如下代码：</p>%n<p><em><font color="%hff0000">home.index.js</font></em></p><pre>require(['../config'], function () {%n    require(['home.index2']);%n})%n, define("home.index2", ['jquery', 'bootstrap'], function () {%n	//main module code here%n})%n</pre>%n<p>使用一个命名的模块home.index2作为过渡，在主模块中手动require，这样可以保证config在主模块执行之前加载，也就使得home.index2在加载的时候已经加载了config了。</p>%n<h2>压缩</h2>%n<p>require提供一个压缩工具，用于压缩和合并js，详情请移步至<a href="http://requirejs.org/docs/optimization.html">http://requirejs.org/docs/optimization.html</a>。简单的说，require提供一个叫<code>r.js</code>的文件，通过本地的node程序（Node.js），执行这个r.js并传入一些参数，即可自动分析模块互相之间的依赖，以达到合并和压缩的目的。同样的，这对于单页面应用来说是容易的，因为主模块只有一个，但是对于多页面又如何做呢？好在这个压缩工具支持用一个配置文件来指导压缩，这样的话，我们可以编写下面的配置脚本：</p>%n<p><em><font color="%hff0000">build.js</font></em></p><pre>var build = {%n    appDir: '../js',%n    baseUrl: '.',%n    dir: '../js-built',%n    modules: [%n        //First set up the common build layer.%n        {%n            //module names are relative to baseUrl%n            name: 'config',%n            //List common dependencies here. Only need to list%n            //top level dependencies, "include" will find%n            //nested dependencies.%n            include: ["bootstrap", "config","jquery"]%n        },%n	//Now set up a build layer for each page, but exclude%n        //the common one. "exclude" will exclude nested%n        //the nested, built dependencies from "common". Any%n        //"exclude" that includes built modules should be%n        //listed before the build layer that wants to exclude it.%n        //"include" the appropriate "app/main*" module since by default%n        //it will not get added to the build since it is loaded by a nested%n        //require in the page*.js files.%n	{%n	    name:"app/home.index",%n	    exclude:["config"]%n	},%n	{%n	    name:"app/blog.create",%n	    exclude:["config"]%n	},%n	...%n    ]%n%n}%n</pre>%n<p>通过这个命令来执行压缩，压缩的结果将被保存到js-build目录：</p><pre>node.exe r.js -o build.js%n</pre>%n<p>build.js脚本实际上是一个js对象，我们将config加入公共模块，而在各个主模块中将其排除。这样，所有的公共库包括config将压缩成一个js，而主模块又不会包含多余的config。这样可想而知，每个页面在加载时最多只会下载两个js，而且公共模块的代码会“按需执行”。</p>%n<p>执行上面的脚本压缩，需要安装有node。可以在从这里<a href="http://nodejs.org/download/" target="_blank">下载</a>。</p>%n<h2>自动脚本</h2>%n<p>但是，随着主模块的增加，需要随时跟踪和修改这个build文件，这也是很麻烦的。于是，笔者基于node.js开发了一个叫<code>build-build.js</code>的脚本，用来根据目录结构自动生成build.js：</p>%n<p><em><font color="%hff0000">build-build.js</font></em></p><pre>fs = require('fs');%nvar target_build = process.argv[2];%n//console.log(__filename);%nvar pwd = __dirname;%nvar js_path = pwd.substring(0,pwd.lastIndexOf('\\')) + '\\js';%nconsole.log('js path : ' + js_path);%nvar app_path = js_path + '\\app';%nconsole.log('js app path : ' +app_path);%n%nvar app_modules = [];%nvar global_modules = [];%n%n//build json object%nvar build = {%n	appDir: '../js',%n    baseUrl: '.',%n    dir: '../js-built',%n    modules: [%n        //First set up the common build layer.%n        {%n            //module names are relative to baseUrl%n            name: 'config',%n            //List common dependencies here. Only need to list%n            //top level dependencies, "include" will find%n            //nested dependencies.%n            include: []%n        }%n    ]%n}%n%nfs.readdir(app_path,function (err,files) {%n	// body...%n	if (err) throw err;%n	for(var i in files){%n		//put module in app_modules%n		var dotindex = files[i].lastIndexOf('.');%n		if(dotindex &gt;= 0){%n			var extension = files[i].substring(dotindex+1,files[i].length);%n			if(extension == 'js'){%n				app_modules.push({%n					name: 'app/' + files[i].substring(0,dotindex),%n            		exclude: ['config']%n				});%n			}%n		}%n	}%n%n	for(var j in app_modules){%n		build.modules.push(app_modules[j]);%n	}%n	%n	fs.readdir(js_path,function (err,files){%n		if (err) throw err;%n		for(var i in files){%n			//put module in app_modules%n			var dotindex = files[i].lastIndexOf('.');%n			if(dotindex &gt;= 0){%n				var extension = files[i].substring(dotindex+1,files[i].length);%n				if(extension == 'js'){%n					global_modules.push(files[i].substring(0,dotindex));%n				}%n			}	%n		}%n%n		build.modules[0].include = global_modules;%n		//console.log(build);%n		var t = pwd + '\\' + target_build;%n		console.log(t);%n		var fd = fs.openSync(t, 'w');%n		fs.closeSync(fd);%n		var json = JSON.stringify(build);%n		fs.writeFileSync(t, json);%n	});%n});%n</pre>%n<p>这里的代码并不复杂，主要是遍历目录，生成对象，最后将对象序列化为build.js。读者可以自行阅读并修改。最后，编写一个bat，完成一键压缩功能：</p>%n<p><em><font color="%hff0000">build.bat</font></em></p><pre>@echo off%nset PWD=%p~p0%nset PWD=%pPWD:\=/%p%ncd "D:\node"%nnode.exe %pPWD%pbuild-build.js build.js%nnode.exe %pPWD%pr.js -o %pPWD%pbuild.js%ncd %p~dp0%n</pre>%n<p>这样，我们就简单实现了一个方便的多页面require方案，最后项目目录可能是这样的：</p><pre>Views%n |--Shared%n     |--_layout.cshtml%n |--Home%n     |--Index.cshtml%n |--Blog%n     |--Create.cshtml%n     |--Edit.cshtml%n     |--Detail.cshtml%n     |--Index.cshtml%n%nbuild%n|--build.js%n|--r.js%n|--build-build.js%n|--build.bat%n%njs%n|--app%n    |--home.index.js%n    |--blog.create.js%n    |--blog.edit.js%n    |--blog.detail.js%n    |--blog.index.js%n|--jquery.js%n|--bootstrap.js%n|--underscore.js%n|--jquery.ui.js%n|--jquery.customplugin.js%n|--config.js%n|--require.js%n</pre>%n<p>可以从<a href="https://github.com/PChou/mvc-require-mutilpage-example" target="_blank">这里</a>fork示例程序</p>#ASP.NET MVC应用require.js实践#postlayout#本文探讨如何在ASP.NET MVC多页面环境下应用js的模块化编程框架require，并给出压缩相关的自动化脚本#require_logo.png#[javascript,asp.net]#[require.js,asp.net mvc,node.js]#2013-11-10 19:32:20#2013-11-11 13:30:11#
9#2013-11-28-529753c0d8e54.html#<p>同一个网段需要用2层设备互联  <ul> <li>Hub：共享性网络，同一个Hub上的设备实际上可以看成连接在同一根线上，产生冲突的可能性很大，所以带宽是平分的，现在基本已经淘汰  <li>网桥：二层隔离性，能够互联多个网段，并隔离不同的网段。软件实现不同网段数据之间的过滤 </li></ul> <p><img style="background-image: none; border-right-width: 0px; padding-left: 0px; padding-right: 0px; display: inline; border-top-width: 0px; border-bottom-width: 0px; border-left-width: 0px; padding-top: 0px" class="img-responsive" title="image" border="0" alt="image" src="http://fakelocalhost/assert/img/2013-11-28-529753c09bdb6.png" width="508" height="378"></p> <ul> <li>交换机：多端口网桥，硬件实现过滤，能够达到线速转发。微分段（micro segmentation）技术：每个端口处在独立的冲突域（multiple collision domain）中，所以网络中不会出现线路冲突 </li></ul> <p><strong></strong>&nbsp; <p><strong><u>交换机的特点</u></strong>  <ol> <li>可靠安全的通信  <li>多端口链接  <li>全双工模式（Full-Duplex Communication）  <li>适应接口的不同速率（Media-Rate Adaptation）  <li>交换机通过桥接表来过滤和转发数据帧，并且具有学习能力  <li>交换机对广播和组播一般执行泛洪操作（交换机一般无法识别组播组），所以交换机一共会对3种包执行泛洪操作，分别为：目标地址未知的单播包（学习桥接表时）、广播包、组播包 </li></ol> <p><img style="background-image: none; border-right-width: 0px; padding-left: 0px; padding-right: 0px; display: inline; border-top-width: 0px; border-bottom-width: 0px; border-left-width: 0px; padding-top: 0px" class="img-responsive" title="image" border="0" alt="image" src="http://fakelocalhost/assert/img/2013-11-28-529753c0b5bcc.png" width="532" height="338">  <p><strong></strong>&nbsp; <p><strong><u>交换机的工作方式 </u></strong> <ul> <li>直通模式：当交换机读到源和目标mac地址时就开始转发（一般只需要读取20-30字节），不进行校验，无法识别碎片帧和损坏帧，最快但最不可靠  <li>无碎片转发：读前64个字节，然后立刻转发数据帧，因为一般冲突的数据碎片大小小于64字节，能够识别碎片帧，无法识别损坏帧  <li>存储转发：完整读取数据帧，并校验后转发，可靠性最高但最慢 </li></ul> <p><img style="background-image: none; border-right-width: 0px; padding-left: 0px; padding-right: 0px; display: inline; border-top-width: 0px; border-bottom-width: 0px; border-left-width: 0px; padding-top: 0px" class="img-responsive" title="image" border="0" alt="image" src="http://fakelocalhost/assert/img/2013-11-28-529753c0c2307.png" width="535" height="332"></p> <p>&nbsp; <p><strong><u>交换机指标</u></strong>  <ul> <li>接口数量  <li>接口速率  <li>背板带宽：即交换机的总流量速率。假设24口，每个口1000M，那么理论速率总速率为24G，但是背板带宽可能会限制这个速率。背板带宽实际上表征了交换机内部交换处理速度。例如思科6500系列核心交换机的背板带宽可达720G/s </li></ul> <p><img style="background-image: none; border-right-width: 0px; padding-left: 0px; padding-right: 0px; display: inline; border-top-width: 0px; border-bottom-width: 0px; border-left-width: 0px; padding-top: 0px" class="img-responsive" title="image" border="0" alt="image" src="http://fakelocalhost/assert/img/2013-11-28-529753c0cbf49.png" width="238" height="216"></p> <p><a href="http://itercast.com/lecture/195" target="_blank">源视频地址</a></p> <p><a href="http://pchou.info/resource/2013/01/06/linuxcast-video-link.html" target="_blank">视频教学资源汇总</a></p>#交换基础#postlayout#简单概括了交换机的基础知识，包括交换机优于网桥、交换机的特点、交换机的工作方式，交换机的选择指标#Services-network-cloud.jpg#[network,hardware]#[network,switch]#2013-11-28 22:31:28#2013-12-19 15:26:34#
10#2013-11-29-529882f34bf57.html#<p>现代企业网络架构：核心层、汇聚层、接入层，冗余链路  <ul> <li>接入层：直接连接终端设备，一般在大楼的每层都有若干接入层设备。通常只做基本的安全防护策略。常用中低端交换机，常见的有2960、3560  <li>汇聚层：连接接入层设备，而且一般都是带路由功能的交换机。大多数策略在这层应用。常用中高端交换机，常见的有3560、3750、4500  <li>核心层：连接汇聚层设备，通常为了高速转发数据，不做策略。常用高端交换机，常见的有4500、6500  <li>冗余链路：为了保证可靠性，采用双核心多汇聚多线路互联 </li></ul> <p><img style="background-image: none; border-right-width: 0px; padding-left: 0px; padding-right: 0px; display: inline; border-top-width: 0px; border-bottom-width: 0px; border-left-width: 0px; padding-top: 0px" class="img-responsive" title="Image" border="0" alt="Image" src="http://fakelocalhost/assert/img/2013-11-29-529882f2e778a.png" width="605" height="372"> </p> <p>交换机隔离冲突域，但是不隔离广播域，容易造成广播风暴。为了解决这个问题，交换机开始支持<font color="%hff0000"><strong>VLAN</strong></font>（虚拟局域网）：可以将同一个交换机的物理端口划分在不同的网段中，这样2层的广播就被限制在某个网段中，不同的VLAN之间需要通过3层设备才能通信  <p><img style="background-image: none; border-right-width: 0px; padding-left: 0px; padding-right: 0px; display: inline; border-top-width: 0px; border-bottom-width: 0px; border-left-width: 0px; padding-top: 0px" class="img-responsive" title="Image(1)" border="0" alt="Image(1)" src="http://fakelocalhost/assert/img/2013-11-29-529882f3111e1.png" width="612" height="392">  <p>一般划分VLAN基于两种策略：基于职能部门或基于数据流量（比如语音流量、管理流量跟一般的不同）  <p>根据交换机对VLAN的设计，一个端口只能属于一个VLAN，特定VLAN的数据帧也只会从属于该VLAN的端口发出，那么不同交换机之间VLAN的通信怎么实现？如下图，只能将交换机互联，并且互联的两端都属于同一个VLAN，这样有几个VLAN，交换机之间就需要几根线：  <p><img style="background-image: none; border-right-width: 0px; padding-left: 0px; padding-right: 0px; display: inline; border-top-width: 0px; border-bottom-width: 0px; border-left-width: 0px; padding-top: 0px" class="img-responsive" title="Image(2)" border="0" alt="Image(2)" src="http://fakelocalhost/assert/img/2013-11-29-529882f31e8bc.png" width="618" height="354">  <p>但是这样做显然不科学。使用Trunk可以允许在一根线路上承载多个VLAN的数据。trunk的实现原理是在Trunk的入口对数据打上标记，在出口的地方进行再分类。有两种trunk协议：802.1Q（标准协议）、ISL（思科私有）。思科的交换机能够自动识别并自动配置端口为Trunk  <p><img style="background-image: none; border-right-width: 0px; padding-left: 0px; padding-right: 0px; display: inline; border-top-width: 0px; border-bottom-width: 0px; border-left-width: 0px; padding-top: 0px" class="img-responsive" title="Image(3)" border="0" alt="Image(3)" src="http://fakelocalhost/assert/img/2013-11-29-529882f32755e.png" width="585" height="442">  <p>ISL：思科私有协议，支持PVST，使用封装算法，在数据帧的前端加入26字节的报头表征VLAN，尾部增加4字节的校验，优点是不修改原始数据帧  <p><img style="background-image: none; border-right-width: 0px; padding-left: 0px; padding-right: 0px; display: inline; border-top-width: 0px; border-bottom-width: 0px; border-left-width: 0px; padding-top: 0px" class="img-responsive" title="Image(4)" border="0" alt="Image(4)" src="http://fakelocalhost/assert/img/2013-11-29-529882f335bda.png" width="571" height="202">  <p>802.1Q：IEEE标准协议，在数据帧中增加4字节的标记，并重新计算校验。所有没有打标记的数据包，统一划归为Native VLAN（这种情况很少见）  <p><img style="background-image: none; border-right-width: 0px; padding-left: 0px; padding-right: 0px; display: inline; border-top-width: 0px; border-bottom-width: 0px; border-left-width: 0px; padding-top: 0px" class="img-responsive" title="Image(5)" border="0" alt="Image(5)" src="http://fakelocalhost/assert/img/2013-11-29-529882f33dcc4.png" width="472" height="258"> <p><a href="http://itercast.com/lecture/196" target="_blank">源视频地址</a></p> <p><a href="http://pchou.info/resource/2013/01/06/linuxcast-video-link.html" target="_blank">视频教学资源汇总</a></p>#交换机VLAN和Trunks#postlayout#现代企业网通常以三层架构，配合VLAN实现。VLAN的划分和原理，Trunk解决VLAN跨交换机通信的问题，Trunk有两种常见的协议#Services-network-cloud.jpg#[network,hardware]#[network,switch,VLAN,Trunk]#2013-11-29 20:05:07#2013-12-19 15:23:20#
11#2013-12-08-52a4192fa4715.html#<p>VTP协议用来简化和方便企业网的VLAN管理，实现动态的集中化的VLAN管理。采用C/S结构，用户只需要在一个“服务端交换机”配置VLAN信息，即可以自动同步到其他交换机。VTP只会通过交换机之间的Trunk发送  <p><img title="Image" class="img-responsive" style="border-left-width: 0px; border-right-width: 0px; background-image: none; border-bottom-width: 0px; padding-top: 0px; padding-left: 0px; display: inline; padding-right: 0px; border-top-width: 0px" border="0" alt="Image" src="http://fakelocalhost/assert/img/2013-12-08-52a4192f9d5cb.png" width="577" height="376">  <p>针对VTP协议，交换机可以配置成三种工作方式：  <ul> <li>服务端：能够创建、修改、删除VLAN，并将配置定期或立即转发，实现同步  <li>客户端：不能创建、修改、删除VLAN，能够同步服务端的配置，也可以转发  <li>透明模式：能够创建、修改、删除私有的VLAN，不同步服务端的通告，但可以转发通告 </li></ul> <p>VTP通过2层组播发送，每5分钟同步一次，或者当有更新时立刻同步。每个VTP通告会有一个序列号标识（revision number），序列号自增长，客户端交换机只会选择序列号较大的通告作为最新的通告。这个因为，VTP会在所有的Trunk间转发，有可能会在较短的时间内从其他交换机接收到一个版本较老的通告。因此，需要注意的是将一台曾经工作过的交换机加入到网络中时，务必要将配置清空后加入，否则该交换机的序列号有可能大于当前网络的VTP序列号，这样会使得这台交换机的VLAN配置覆盖当前网络的VLAN配置</p> <p><a href="http://itercast.com/lecture/197" target="_blank">源视频地址</a></p> <p><a href="http://pchou.info/resource/2013/01/06/linuxcast-video-link.html" target="_blank">视频教学资源汇总</a></p>#VTP协议#postlayout#VTP是专为VLAN开发的，用于快速维护全网VLAN配置，避免单台交换机逐一配置的协议#Services-network-cloud.jpg#[network,hardware]#[network,switch,VLAN,VTP]#2013-12-08 15:01:03#2013-12-19 15:22:25#
12#2013-12-19-52b293e0c4123.html#<h2>问题</h2> <p>为了提高网络的可用性，需要进行冗余和备份。但是冗余路径会产生环路  <p><img title="Image(1)" class="img-responsive" style="border-left-width: 0px; border-right-width: 0px; background-image: none; border-bottom-width: 0px; padding-top: 0px; padding-left: 0px; display: inline; padding-right: 0px; border-top-width: 0px" border="0" alt="Image(1)" src="http://fakelocalhost/assert/img/2013-12-19-52b293e073d9c.png" width="539" height="337">  <p>环路会导致以下问题  <ul> <li>广播风暴：由于交换机会对广播、多播、和未知目标MAC的单播包进行泛洪，在存在环路的情况下，很短的时间内就会产生风暴</li></ul> <p><img title="Image(2)" class="img-responsive" style="border-left-width: 0px; border-right-width: 0px; background-image: none; border-bottom-width: 0px; padding-top: 0px; padding-left: 0px; display: inline; padding-right: 0px; border-top-width: 0px" border="0" alt="Image(2)" src="http://fakelocalhost/assert/img/2013-12-19-52b293e080ef7.png" width="531" height="349"></p> <ul> <li>多帧拷贝、MAC地址表不稳定：当交换机刚刚启动时，MAC地址表是空的，所以，所有的单播帧都会进行泛洪操作。但是如果存在环路的话，交换机在特定情况下，会从不同的接口收到相同的MAC地址，这样的话，MAC地址表将不稳定</li></ul> <p><img title="Image(3)" class="img-responsive" style="border-left-width: 0px; border-right-width: 0px; background-image: none; border-bottom-width: 0px; padding-top: 0px; padding-left: 0px; display: inline; padding-right: 0px; border-top-width: 0px" border="0" alt="Image(3)" src="http://fakelocalhost/assert/img/2013-12-19-52b293e08a579.png" width="531" height="354"></p> <p>STP（spanning tree protocal，IEEE802.1D）就是通过软件防止环路的产生，通过逻辑的禁用接口，使得环路在逻辑上不存在；当线路出现故障时，将禁用的接口启用，使得网络能够发挥物理冗余路径带来的高可用性  <p>&nbsp; <h2>STP协议的工作原理</h2> <p>STP协议的原则如下：  <ol> <li>每个广播域中只有一个<b>根网桥</b>，根网桥的接口都是指定接口  <li>每一个非根网桥上都有一个<b>根接口</b>，根接口就是到达根网桥最近（带宽最高，开销最小）的接口  <li>每个网段中只有一个<b>指定接口（</b>发送方的桥ID较小的，或者端口优先级较小，或者端口ID较小的）  <li><b>非指定接口</b>不使用</li></ol> <p><img title="Image(4)" class="img-responsive" style="border-left-width: 0px; border-right-width: 0px; background-image: none; border-bottom-width: 0px; padding-top: 0px; padding-left: 0px; display: inline; padding-right: 0px; border-top-width: 0px" border="0" alt="Image(4)" src="http://fakelocalhost/assert/img/2013-12-19-52b293e09c65a.png" width="550" height="197"></p> <p>假如上图的Switch X是根网桥，那么它的两个接口都是指定接口；Switch Y是非根网桥，由于100BASE的带宽更高，所以Switch Y上面的接口是根接口；上下两个segement中，s1和s2都已经有指定接口了，所以Switch Y下面的接口既不是根接口，也不是指定接口，那么将其阻断。  <p>上述的过程是交换机通过STP协议和交换<strong>BPDU</strong>（Bridge Protocol Data Unit）桥接协议数据单元，自动协商得到的。BPDU每2秒钟发送一次。  <p>BPDU的数据结构  <p><img title="Image(5)" class="img-responsive" style="border-left-width: 0px; border-right-width: 0px; background-image: none; border-bottom-width: 0px; padding-top: 0px; padding-left: 0px; display: inline; padding-right: 0px; border-top-width: 0px" border="0" alt="Image(5)" src="http://fakelocalhost/assert/img/2013-12-19-52b293e0a407a.png" width="201" height="229">  <p><strong>Root ID（8Bytes）：</strong>根网桥ID，每个交换机通过桥ID进行标识，桥ID由桥优先级+MAC地址组成（64个字节）。桥优先级的默认值为32768，最大值为65535。<b>桥ID最小的为根网桥</b>  <p><strong>Cost of path（4Bytes）：</strong>接口的Cost值，端口速率对应的开销值如下：  <p><img title="Image(6)" class="img-responsive" style="border-left-width: 0px; border-right-width: 0px; background-image: none; border-bottom-width: 0px; padding-top: 0px; padding-left: 0px; display: inline; padding-right: 0px; border-top-width: 0px" border="0" alt="Image(6)" src="http://fakelocalhost/assert/img/2013-12-19-52b293e0ab96e.png" width="365" height="161">  <p><strong>Bridge ID（8Bytes）：</strong>本网桥（交换机）的桥ID  <p><strong>Port ID（2Bytes）：</strong>端口编号  <p><strong>Hellotime（2Bytes）：</strong>BPDU间隔发送时间，默认为2秒  <p><strong>Max age：</strong>详见下面  <p><strong>Forward delay：</strong>详见下面  <p>&nbsp; <p>上述四个字段，在交换机交换BPDU的过程中就能够协商出结果。  <p>在STP协议故障转移过程中，交换机接口状态有如下四个状态  <p><img title="Image(7)" class="img-responsive" style="border-left-width: 0px; border-right-width: 0px; background-image: none; border-bottom-width: 0px; padding-top: 0px; padding-left: 0px; display: inline; padding-right: 0px; border-top-width: 0px" border="0" alt="Image(7)" src="http://fakelocalhost/assert/img/2013-12-19-52b293e0b393b.png" width="534" height="256">  <p>当某个指定接口出现故障时，需要将原先的非指定接口转为指定接口。如何检测故障呢？  <p>一种情况是，直接端口故障，交换机能够立即得知这样的故障，则将Blocking的非指定接口立即切换到Listening状态  <p>另一种情况是，线路故障，交换机无法直接检测到，此时通过BPDU检测。正常情况下两台交换机之间会每两秒钟收到对方的BPDU，如果在<strong>Max age</strong>时间后，仍然无法收到BPDU的话，需要进行重选举，将原先Blocking的非指定接口，切换到Listening状态。  <p>Listening状态持续<strong>Forward Delay</strong>时间，这段时间后，选举完成。之后进入Learning状态，交换机在该端口上进行学习MAC地址，但是不转发数据，以防止对未知单播帧的广播，这个时间持续<strong>Forward Delay</strong>时间；最后进入正常的Forwarding状态  <p>一般情况下根据超时时间的设置，最长有可能需要经过30-50秒，STP协议才能重新选举完成  <p>总结：  <ul> <li>Blocking：非指定接口的状态，即不转发数据也不学习MAC地址  <li>Forwarding：指定接口或根接口，转发数据和学习MAC地址  <li>Listening：进入重选举的状态  <li>Learning：重选举完成后，进入MAC地址学习，但不转发数据</li></ul> <p>&nbsp;</p> <p>下面是一个例子  <p><img title="Image(8)" class="img-responsive" style="border-left-width: 0px; border-right-width: 0px; background-image: none; border-bottom-width: 0px; padding-top: 0px; padding-left: 0px; display: inline; padding-right: 0px; border-top-width: 0px" border="0" alt="Image(8)" src="http://fakelocalhost/assert/img/2013-12-19-52b293e0bd010.png" width="532" height="322">  <ol> <li>SWR的网桥优先级最小，所以SWR为根网桥，其接口为指定接口  <li>SWA、SWD的上面的两个接口到SWR的开销最小（都是19），所以都是根接口；同理，可以得到SWB和SWC的根接口  <li>SWA和SWD下面的端口都是其各自segement的指定接口（每个segment有且只有一个指定接口）  <li>SWB和SWC组成的segement还没有指定接口，此时由于SWB的桥优先级较小，所以SWB侧的接口为指定接口，而SWC侧的接口即为非指定接口，进入Blocking状态</li></ol> <p>&nbsp; <h2>PortFast</h2> <p>如果终端设备直接连接在交换机上，也需要等待30秒的话，会出现问题，比如DHCP超时。所以，可以配置交换机的接口为PortFast模式，PortFast的接口不会介入STP选举的过程，不需要等待30秒的选举过程。但是不能用在Trunck接口上，因为如果用在Trunck接口上启用PortFast，交换机之间无法进行STP选举，极易产生环路。所以PortFast一般只用在直连终端的“接入接口”。  <p><a href="http://itercast.com/lecture/198" target="_blank">源视频地址</a></p> <p><a href="http://pchou.info/resource/2013/01/06/linuxcast-video-link.html" target="_blank">视频教学资源汇总</a></p>#STP生成树协议#postlayout#交换机由于冗余拓扑会产生环路，导致广播风暴等问题，STP生成树协议利用软件协议暂时逻辑上阻断冗余接口，使得全网没有环路。当网络出现故障的时候，逻辑上被阻断的接口能够自动在30-50秒内重新开启并保证全网的畅通#Services-network-cloud.jpg#[network,hardware]#[network,switch,STP]#2013-12-19 14:36:16#2013-12-19 15:21:19#
13#2014-01-05-52c8e87d41fab.html#<p><img title="Happy-New-Year.-Inscription-2014-Image-5" class="img-responsive" style="display: inline" alt="Happy-New-Year.-Inscription-2014-Image-5" src="http://fakelocalhost/assert/img/2014-01-05-52c8e9a40fadd.jpeg" width="335" height="251">  <p>上次写类似的年终总结恐怕要追溯到大学了，这些年鲜有心情和动力，另外就是我对待事物喜欢往坏的方面想，消极的情绪也不便传播。元旦这段时间因为公司装修，有了一些时间静下来思考，回顾过去展望未来。  <p>过去的一年，外包在携程待了大半年，要说技术上的收获倒是不多，更多的是见识了大型互联网民企公司的状态：跟外企相比员工的工作积极性要高不少，沟通交流也更趋于高效和实际，也是人才辈出的地方。国企就不谈了，大家都有数。  <p>之后由于个人发展方面的考虑，来到现在这家创业公司。走之前是挺纠结的，身边比我年长的几乎都不支持。有人说，难以决定的时候就抛硬币吧，也许当你拿起硬币的时候你已经有了选择了。其实我一旦心动恐怕覆水也难收了。每个人都有对未知未来的恐惧，但是在现在社会，变化如此之快，“已知的未来”难道就不让人不安吗？联想当年父母下岗这么个社会变化，不就是不能适应变化而带来的“灾难”吗？因此，这样想来没有必要恐惧什么，只要努力去付出，成不成功只在天，但求无怨无悔。  <p>在新公司的几个月，由于公司小，凡事亲历亲为，IT管理、招聘都要自己做，没有专门的人协助。不过这段时间虽然辛苦，但是乐在其中，这种状态就像刚刚参加工作一般，很积极很乐观，每天工作到很晚也没什么倦意。反而，不在踌躇，不在犹豫，生活也多了几分乐趣的东西：养花、旅游、博客...  <p>过去的一年，过的很快，说不浮躁，那是假的，开始收藏各种文章却鲜有打开看看。开始关心时政、经济。  <p>新的一年要办件人生大事，希望顺利。希望家人身体健康，小伙伴们安居乐业，更快的成长，自己也要对自己好些。希望公司继续在正确的轨道上前行。  #过去的2013#postlayout#2013年度总结#2014-01-05-52c8e9a40fadd.jpeg#[life]#[life]#2014-01-05 13:07:09#2014-01-05 13:12:04#
14#2014-01-05-52c91a4fdf938.html#<p>STP标准生成树协议中，每个物理的交换机只能有一个STP实例，也就是说一个物理交换机只能接受一套STP协定结果。然而，STP通过阻断冗余链路，达到防环的目的，但是这样做，也使得无法最大限度的利用交换机的带宽资源。因为，如果冗余链路能够在某些特定情况下仍然工作，那么就能够在一定程度上利用这些原本阻断的接口提供额外的带宽。  <p>思科的交换机实现每VLAN生成树协议（Per VLAN Spanning Tree）。顾名思义，思科的交换机为每个VLAN维护独立的STP实例，这样用户可以配置不同的VLAN使用不同的根交换机，达到这样的负载均衡效果。  <p><img title="Image(9)" class="img-responsive" style="display: inline" alt="Image(9)" src="http://fakelocalhost/assert/img/2014-01-05-52c91a4fcb6e5.png" width="523" height="257">  <p>如上图，有两个VLAN：VLAN1和VLAN2，可以将SW1配置成VLAN1的根交换机，将SW2配置成VLAN2的根交换机，这样VLAN1的数据都会通过SW1转发，而VLAN2的数据都会通过SW2转发，一定程度上实现了带宽的负载均衡  <p>PVST协议通过拆分标准生成树的2个字节的birdge ID实现，如下图：</p> <p><img title="Image(10)" class="img-responsive" style="display: inline" alt="Image(10)" src="http://fakelocalhost/assert/img/2014-01-05-52c91a4fd7947.png" width="515" height="333"></p> <p>将bridge ID的后12位作为“系统扩展”来表示VLAN，仅保留4位给网桥优先级。这样就能精确的表征VLAN和桥ID的关系。但是，4位的桥ID显然不能用来表示0~65535的范围。所以，思科规定，在PVST中配置网桥优先级的时候，只能是4096(2的12次方)的倍数。所以针对上面的例子可以做如下配置： </p> <p><img title="KU~K]GL930_%p~7~}@EAZ$6C" style="display: inline" alt="KU~K]GL930_%p~7~}@EAZ$6C" src="http://fakelocalhost/assert/img/2014-01-05-52c91bdea8646.jpeg" width="541" height="284"> <p>将SWA的网桥优先级配置成<font color="%hff0000"><strong>VLAN1：4096、VLAN2：32768</strong></font>  <p>将SWB的网桥优先级配置成<font color="%hff0000"><strong>VLAN1：32768、VLAN2：4096</strong></font>  <p>&nbsp; <p>思科的交换机已经不支持标准STP，而是支持如下几种：  <ol> <li>PVST+（默认）  <li>PVRST+  <li>MSTP</li></ol>#PVST - 每VLAN生成树#postlayout#思科扩展了STP协议，实现了每VLAN STP，即每个VLAN实现一个STP协商实例，这样即可以避免冗余链路成环，又能够在逻辑层面复用这些冗余链路，以达到一定程度上的负载均衡#Services-network-cloud.jpg#[network,hardware]#[network,switch,PVST]#2014-01-05 16:39:43#2014-01-05 16:47:19#
15#2014-01-14-52d542e7c6ced.html#<p>前段时间听说一个新名词："全栈程序员"，google了一下，被引导到了知乎的一个讨论上： <a href="http://www.zhihu.com/question/22420900">http://www.zhihu.com/question/22420900</a> 。楼主提出了一个问题：怎样成为全栈程工程师，本人也在上面情不自禁地回复了一下。回头想来似乎还有话要说。由于这个话题很容易跑偏，本文只把范围限定在全栈Web软件工程师，简称<strong>FSD（Full Stack Developer）</strong>。  <p>&nbsp; <h3><font style="font-weight: bold">把技术当成生活，自己逼自己的结果</font></h3> <p>其实在任何公司工作，光凭工作的内容，很难成为FSD。有朋友可能不同意了，说在创业公司有很多机会做不同的工作啊，我想说的是，即便是创业公司，公司总是有主营的业务和方向的，就算能从前到后一个人做一个网站，那又怎样，从技术上说，无非也就是掌握了一种或几种数据库，一门或几门后台语言，掌握了html,js,css...大公司呢？更难了，大公司虽然方向很多，但是越是大的公司，个人的螺丝钉效应越明显，你可能成为领域专家，但很难有机会成为完整的机器的。那么全栈程序员的磨练靠的是什么？靠的是一种打心底里的执着和毅力，把技术当成生活，自己逼自己不断的猎取知识。  <p>&nbsp; <h3><strong>难以界定，每个人都有不同的理解</strong></h3> <p>刚才其实没有鄙视能够完整做网站的人，相反，很是钦佩。至少本人现在在css上还不能算能完全独立。不过每个人对FSD的定义其实不一样，这跟个人的阅历有一定的关系。只想说，既不要对自己过分自信，也不要过分贬低。一方面，人外有人，天外有天，每个人覆盖到技术领域是有差异的；另一方面，FSD其实挺不容易的，不仅不容易达到，而且不容易获得存在感。正因为见的多，所以就越觉得自己渺小，我们经常说的，真正的大牛从来就是低调和谦虚的。而FSD在任何领域都不是那种呼风唤雨的专家，别人在讨论的时候可能永远都没有你插话的机会，其实你心里知道，自己还很肤浅。个人自认为是比较接近这么一个性质的程序猿，可以从我的博客的文章内容略窥一二。但是正如我不敢斩钉截铁地将自己定性到这么个层次，恐怕很多全栈程序员也不能将自己明确在这个定位上，因为总有人能站出来给你一个"反例"。  <p>&nbsp; <h3><strong>何去何从</strong></h3> <p>从知乎上的回答来看，FSD似乎并不吃香。纵观人类发展历程，更细致的社会分工造就了生产力的提高。就程序员行业而言，越来越趋于细分话，似乎也是正常的趋势。作为FSD，实际上挺难的，主要是因为精力的限制，无法在广度和深度上兼顾。尽管如此，个人觉得FSD还是有很明显的优势的：  <ol> <li>见多识广，解决问题的手段比较多，而且往往能够触类旁通的思考；  <li>不容易被某种技术的新衰而左右，很容易转型；  <li>合格的FSD往往具有超强的毅力和极客精神，这在某些情况下是很有用的；  <li>由于能力广泛，又吃苦耐劳，适合创业；</li></ol> <p>&nbsp;</p> <h3><strong>个人理解</strong></h3> <p>针对Web开发的话，稍稍谈一谈个人对全栈程序员能力的界定，大牛们轻拍：  <ol> <li>用户体验层面，<code>html45</code>，<code>javascript</code>，<code>css23</code>，各种前端的框架...  <li>后台业务逻辑层面，各种编程语言，现在主流的有<code>Java</code>、<code>C%h</code>、<code>Python</code>、<code>Ruby</code>、<code>PHP</code>、<code>Node.js</code>...，以及配套的各种开发框架...  <li>辅助层面可能会涉及到<code>C</code>、<code>C++</code>等较为古老的编程语言，需要一定程度上熟悉掌握...  <li>数据库，会设计和使用几种常用的数据库，<code>mssql</code>、<code>mysql</code>、<code>oracle</code>...，数据库分析和优化  <li>架构层面，能够设计灵活可靠，易扩展的软件架构和硬件架构。这个层面上要掌握的东西就很多了，网络、存储、操作系统、web服务器、web架构，安全等等...  <li>一些基础理论层面的东西，算法数据结构、编译原理、网络基础...  <li>数据分析，数据挖掘  <li>管理层面，众人拾柴火焰高，一个人再牛b，精力是有限的，如果能够聚集并领导更多的人，那就更全面了。这包括项目管理，持续集成，敏捷开发，版本控制...  <li>移动开发</li></ol> <p>如果你是FSD，有什么想说的呢？欢迎全栈程序员们留言交流</p> <p>&nbsp;</p> <h3><font style="font-weight: bold">程序员能力矩阵</font></h3> <p>一个挺有意思的程序员能力界定，从<a href="http://static.icybear.net/%p5BCN%p5DProgrammer%p20competency%p20matrix.htm" target="_blank">程序员能力矩阵</a>转载：</p> <blockquote>注意:每个层次的知识都是渐增的，位于层次<em>n</em>，也蕴涵了你需了解所有低于层次<em>n</em>的知识。 </blockquote> <div class="table-responsive"> <table class="table-bordered table"> <caption>计算机科学 Computer Science</caption> <tbody> <tr class="headers"> <td>&nbsp;</td> <td>2<sup>n</sup> <span class="explain">(Level 0)</span></td> <td>n<sup>2</sup> <span class="explain">(Level 1)</span></td> <td>n <span class="explain">(Level 2)</span></td> <td>log(n) <span class="explain">(Level 3)</span></td></tr> <tr class="q"> <td>数据结构</td> <td>不知道数组和链表的差异 </td> <td>能够解释和使用数组，链表，字典等，并且能够用于实际的编程任务。</td> <td>了解基本数据结构时间和空间的折中，比如数组vs 链表，能够解释如何实现哈希表和处理冲突，了解优先队列及其实现。 </td> <td>高等的数据结构的知识，比如B-树、二项堆、斐波那契堆、AVL树、红黑树、伸展树、跳跃表以及前缀树等。</td></tr> <tr class="q"> <td>算法</td> <td>不能够找出一个数组各数的平均值(这令人难以置信，但是我的确在应聘者中遇到过) </td> <td>基本的排序，搜索和数据的遍历和检索算法。</td> <td>树，图，简单的贪婪算法和分而治之算法，能够适度了解矩阵该层的含义。</td> <td>能够辨识和编写动态规划方案，良好的图算法知识，良好的数值估算的知识，能够辨别NP问题等。 </td></tr> <tr class="q"> <td>编程体系</td> <td>不知道何为编译器、链接器和解释器。 </td> <td>对编译器、链接器、解释器有基本的了解。知道什么是汇编代码以及在硬件层如何工作。有一些虚拟内存和分页知识。 </td> <td>了解内核模式vs用户模式,多线程，同步原语以及它们如何实现，能够阅读汇编代码。了解网络如何工作，了解网络协议和socket级别编程。 </td> <td>了解整个程序堆栈、硬件(CPU+内存+中断+微码)、二进制代码、汇编、静态和动态链接、编码、解释、JIT（just-in-time）编译、内存碎片回收、堆、栈、存储器编址…</td></tr></tbody></table></div> <div class="table-responsive"> <table class="table-bordered table"> <caption>软件工程 Software Engineering </caption> <tbody> <tr class="headers"> <td>&nbsp;</td> <td>2<sup>n</sup> <span class="explain">(Level 0)</span></td> <td>n<sup>2</sup> <span class="explain">(Level 1)</span></td> <td>n <span class="explain">(Level 2)</span></td> <td>log(n) <span class="explain">(Level 3)</span></td></tr> <tr class="q"> <td>源码版本控制</td> <td>通过日期备份文件夹 </td> <td>VSS和初级的CVS/SVN用户</td> <td>熟练地使用CVS和SVN特性。知道如何分支和归并，使用程序库补丁安装特性等 </td> <td>有分布式VCS系统的知识。尝试过Bzr/Mercurial/Darcs/Git</td></tr> <tr class="q"> <td>自动化编译</td> <td>只知道在IDE下编译 </td> <td>知道如何编译在命令行下编译系统 </td> <td>能够安装一个脚本构建基本的系统 </td> <td>能够安装一个脚本来构建系统并且归档，安装程序，生成发布记录和给源码控制中的代码分配标签。</td></tr> <tr class="q"> <td>自动化测试</td> <td>认为所有的测试都是测试员的工作。 </td> <td>能够编写自动化的单元测试，能够为正在编写的代码提出良好的测试用例。 </td> <td>按照TDD （Test Driven Development）方式编写代码。</td> <td>了解并且能够有效自动化安装，载入/性能和UI测试</td></tr> <tr></tr></tbody></table></div> <div class="table-responsive"> <table class="table-bordered table"> <caption>程序设计 Programming</caption> <tbody> <tr class="headers"> <td>&nbsp;</td> <td>2<sup>n</sup> <span class="explain">(Level 0)</span></td> <td>n<sup>2</sup> <span class="explain">(Level 1)</span></td> <td>n <span class="explain">(Level 2)</span></td> <td>log(n) <span class="explain">(Level 3)</span></td></tr> <tr class="q"> <td>问题分解</td> <td>只有直线式的代码，通过复制粘贴来复用 </td> <td>能够把问题分散到多个函数中 </td> <td>能够想出可复用的函数/对象来解决大题的问题 </td> <td>使用适宜的数据结构和算法，写出通用的/面向对象的代码来封装问题的易改变的层面。</td></tr> <tr class="q"> <td>系统分解</td> <td>N想不出比单一的文件/类更好的层面 </td> <td>如果不在同一平台或没采用相同的技术，能够把问题空间和设计方案分解。 </td> <td>能够设计跨技术/平台的系统。 </td> <td>能够在多个产品线和与外部体系一体化中虚拟化和设计复制的系统。同时也能够设计支持系统监视、报告、故障恢复等。</td></tr> <tr class="q"> <td>交流</td> <td>不能向同伴表达想法/主意。匮乏拼写和语法的能力。 </td> <td>同伴能了解你在说什么。有良好的拼写和语法能力。 </td> <td>能够和同伴进行高效的交流</td> <td>能够使用清晰的方式了解和交流想法/设计/主意/细则，能适应每种环境的交流 </td></tr> <tr class="q"> <td>同一文件中代码组织</td> <td>同一文件中组织没有依据 </td> <td>按照逻辑性或者易接近的方法 </td> <td>代码分块和对于其他源文件来说是易于是释,引用其他源文件时有良好的注释 </td> <td>文档头部有许可声明，总结，良好的注释，一致的空格缩进。文档外观美观。</td></tr> <tr class="q"> <td>跨文件代码组织</td> <td>没够想过给代码跨文件组织</td> <td>相关文件按文件夹分组 </td> <td>每个物理文件都有独立的目的，比如一个类的定义，一个特性的实现等。 </td> <td>代码在物理层组织紧密，在文件名上与设计和外观相匹配，可以通过文件分布方式洞察设计理念。</td></tr> <tr class="q"> <td>源码树组织</td> <td>一切都放在一个文件夹内 </td> <td>初步地将代码分散进对应逻辑的文件夹。 </td> <td>没有循环依赖，二进制文件，库，文档，构建，第三方的代码都组织进合适的文件夹内。 </td> <td>源码树的物理布局与逻辑层次、组织方式相匹配。可以通过目录名称和组织方式洞察设计理念。 </td></tr> <tr class="q"> <td>代码可读性</td> <td>单音节的名称（在国内应该是那些类似用汉语拼音命名的习惯） </td> <td>对文件、变量、类、方法等，有良好的命名。 </td> <td>没有长函数、注释解释不常规的代码，bug修复,代码假设。 </td> <td>代码假设验证使用断言，自然的代码流，没有深层嵌套的条件和方法</td></tr> <tr class="q"> <td>防御性编码</td> <td>不知道这个概念</td> <td>检查代码中所有的参数，对关键的假设进行断言 </td> <td>确保检查了返回值和使代码失败的异常。 </td> <td>有自己的库来帮助防御性编程、编写单元测试模拟故障</td></tr> <tr class="q"> <td>错误处理</td> <td>只给乐观的情形编码 </td> <td>基本的代码错误处理，抛出异常/生成错误 </td> <td>确保错误/异常留在程序中有良好的状态，资源，连接，内存都有被合适的清理。 </td> <td>在编码之前察觉可能出现的异常，在代码的所有层次中维持一致性的异常处理策略，提出整个系统的错误处理准则。</td></tr> <tr class="q"> <td>IDE</td> <td>IDE大部分用来进行文本编辑 </td> <td>了解其周围的接口，能够高效地通过菜单来使用IDE</td> <td>了解最常操作的键盘快捷键 </td> <td>编写自定义宏</td></tr> <tr class="q"> <td>API</td> <td>需要频繁地查阅文档 </td> <td>把最频繁使用的API记在脑子里 </td> <td>广阔且深入的API知识。 </td> <td>为了使实际任务中常用API使用更加便捷，编写过API的上层库，填补API之间的缺口。 </td></tr> <tr class="q"> <td>框架</td> <td>没有使用过主平台外的任何框架 </td> <td>听过但没用过平台下流行的可用框架</td> <td>在专业的职位中使用过一个以上的框架，通晓各框架的特色。</td> <td>某框架的作者</td></tr> <tr class="q"> <td>需求分析</td> <td>接受给定的需求和代码规格 </td> <td>能对规格的遗漏提出疑问 </td> <td>了解全面情况，提出需要被规格化的整体范围。</td> <td>能够提出更好的可选方案，根据经验的浮现给出需求</td></tr> <tr class="q"> <td>脚本</td> <td>不具备脚本工具的知识 </td> <td>批处理文件/shell脚本 </td> <td>Perl/Python/Ruby/VBScript/Powershell </td> <td>写过并且发表过可重用的代码</td></tr> <tr class="q"> <td>数据库</td> <td>认为Excel就是数据库 </td> <td>知道基本的数据库概念，规范化、ACID（原子性Atomicity、一致性Consistency、隔离性Isolation、持久性Durability）、事务化，能够写简单的select语句 </td> <td>能够牢记在运行时必要查询中设计良好的规范化数据库模式， 精通用户视图，存储过程，触发器和用户定义类型。知道聚集与非聚集索引之间的差异。精通使用ORM（Object Relational Mapping对象关系映射）工具 </td> <td>能做基本的数据库管理，性能优化，索引优化，编写高级的select查询，能够使用相关sql来替换游标，理解数据内部的存储，了解如何镜像、复制数据库。知道两段数据提交如何工作</td></tr></tbody></table></div> <div class="table-responsive"> <table class="table-bordered table"> <caption>经验 Experience </caption> <tbody> <tr class="headers"> <td>&nbsp;</td> <td>2<sup>n</sup> <span class="explain">(Level 0)</span></td> <td>n<sup>2</sup> <span class="explain">(Level 1)</span></td> <td>n <span class="explain">(Level 2)</span></td> <td>log(n) <span class="explain">(Level 3)</span></td></tr> <tr class="q"> <td>专业语言经验</td> <td>命令式语言和面向对象语言 </td> <td>命令式语言,面向对象语言和说明型语言(SQL),如果了解静态类型vs动态类型，弱类型vs强类型则有加分 </td> <td>函数式语言,如果了解延缓求值，局部套用函数，延续则有加分 </td> <td>并发语言(Erlang, Oz) 逻辑语言(Prolog)</td></tr> <tr class="q"> <td>专业平台经验</td> <td>1 </td> <td>2-3 </td> <td>4-5 </td> <td>6+</td></tr> <tr class="q"> <td>专业经验年龄</td> <td>1 </td> <td>2-5 </td> <td>6-9 </td> <td>10+</td></tr> <tr class="q"> <td>领域知识</td> <td>没有该领域的知识 </td> <td>在该领域中曾经至少为一个产品工作过</td> <td>在同一领域中为多个产品工作过 </td> <td>领域专家。在该领域设计和实现数种产品/方案。精通该领域使用的标准条款和协议</td></tr></tbody></table></div> <div class="table-responsive"> <table class="table-bordered table"> <caption>学识 Knowledge </caption> <tbody> <tr class="headers"> <td>&nbsp;</td> <td>2<sup>n</sup> <span class="explain">(Level 0)</span></td> <td>n<sup>2</sup> <span class="explain">(Level 1)</span></td> <td>n <span class="explain">(Level 2)</span></td> <td>log(n) <span class="explain">(Level 3)</span></td></tr> <tr class="q"> <td>工具知识</td> <td>仅限于主要的IDE(VS.Net, Eclipse等) </td> <td>知道一些流行和标准工具的备选方案 </td> <td>对编辑器、调试器、IDE、开源的备选方案有很好的了解。比如某人了解大多数Scott Hanselman的威力工具列表中的工具，使用过ORM工具。</td> <td>实际地编写过工具和脚本，如果这些被发布则有加分</td></tr> <tr class="q"> <td>语言接触</td> <td>命令式语言和面向对象语言</td> <td>命令式语言、面向对象语言和说明型语言(SQL),如果了解静态类型vs动态类型、弱类型vs强类型则有加分 </td> <td>函数式语言,如果了解延缓求值、局部套用函数、continuations （源于scheme中的一种高级控制结构）则有加分 </td> <td>并发语言(Erlang, Oz) 逻辑语言(Prolog) </td></tr> <tr class="q"> <td>代码库知识</td> <td>从来没有查询过代码库 </td> <td>基本的代码层知识，了解如果构建系统 </td> <td>良好的代码库工作知识，实现过几次bug修复或者完成了一些细小的特性 </td> <td>实现了代码库中多个大型特性，能够轻松地将多数特性的需求变更具体化，从容地处理bug修复。</td></tr> <tr class="q"> <td>下一代技术知识</td> <td>从来没听说过即将到来的技术 </td> <td>听说过某领域即将到来的技术 </td> <td>下载过alpha preview/CTP/beta版本，并且读过一些文章和手册 </td> <td>试用过预览版而且实际地构建过某物，如果共享给其他人的话则有加分</td></tr> <tr class="q"> <td>平台内部</td> <td>对平台内部毫无所知 </td> <td>有平台基本的内部工作的知识 </td> <td>深度的平台内部知识，能够设想平台如何将程序转换成可执行代码。 </td> <td>编写过增强平台或者为其平台内部提供信息的工具。比如，反汇编工具，反编译工具，调试工具等。</td></tr> <tr class="q"> <td>书籍</td> <td>菜鸟系列，21天系列，24小时系列，蠢货系列... </td> <td>《代码大全》，《别让我思考》, 《精通正则表达式》 </td> <td>《设计模式》，《人件》，《代码珠玑》，《算法设计手册》，《程序员修炼之道》，《人月神话》 </td> <td>《计算机程序设计与解释》，《事务处理:概念与技术》，《计算机程序设计模型》，《计算机程序设计艺术》，《数据库系统导论》 C.J Date版，《Thinking Forth》 ，《Little Schemer》（没找到其中译本）</td></tr> <tr class="q"> <td>博客</td> <td>听过但是从来抽不出空去接触 </td> <td>阅读一些科技/编程/软件工程的博客，并且经常的收听一些播客</td> <td>维护一些博客的链接，收集博主分享的有用的文章和工具</td> <td>维护一个在编程方面，分享有个人见解和思考的博客</td></tr></tbody></table></div>#伤不起的全栈程序员#postlayout#全栈程序员是一群特殊的程序员，他们从前到后，由内而外，几乎无所不能。很多全栈程序员都认为创业是最好的体现能力和价值的地方#138_120531111023_1.jpg#[life]#[FSD,Programmer]#2014-01-14 22:00:07#2014-01-15 13:09:36#
16#2014-01-18-52da47204d4cb.html#<p>本文是<a href="http://www.dabeaz.com/ply/ply.html" target="_blank">PLY (Python Lex-Yacc)</a>的中文翻译版。转载请注明<a href="http://pchou.info/open-source/2014/01/18/52da47204d4cb.html">出处</a>。</p> <p>如果你从事编译器或解析器的开发工作，你可能对lex和yacc不会陌生，PLY是<a href="http://www.dabeaz.com/" target="_blank">David Beazley</a>实现的基于Python的lex和yacc。作者最著名的成就可能是其撰写的<a href="http://www.dabeaz.com/cookbook.html" target="_blank">Python Cookbook, 3rd Edition</a>。我因为偶然的原因接触了PLY，觉得是个好东西，但是似乎国内没有相关的资料。于是萌生了翻译的想法，虽然内容不算多，但是由于能力有限，很多概念不了解，还专门补习了编译原理，这对我有很大帮助。为了完成翻译，经过初译，复审，排版等，花费我很多时间，最终还是坚持下来了，希望对需要的人有所帮助。另外，第一次大规模翻译英文，由于水平有限，如果错误或者不妥的地方还请指正，非常感谢。</p> <h3><font style="font-weight: bold">目录</font></h3> <ul> <li><a href="%h1">1 前言和预备</a>  <li><a href="%h2">2 介绍</a>  <li><a href="%h3">3 PLY概要</a>  <li><a href="%h4">4 Lex</a>  <ul> <li><a href="%h4_1">4.1 Lex的例子</a>  <li><a href="%h4_2">4.2 标记列表</a>  <li><a href="%h4_3">4.3 标记的规则</a>  <li><a href="%h4_4">4.4 标记的值</a>  <li><a href="%h4_5">4.5 丢弃标记</a>  <li><a href="%h4_6">4.6 行号和位置信息</a>  <li><a href="%h4_7">4.7 忽略字符</a>  <li><a href="%h4_8">4.8 字面字符</a>  <li><a href="%h4_9">4.9 错误处理</a>  <li><a href="%h4_10">4.10 构建和使用lexer</a>  <li><a href="%h4_11">4.11 @TOKEN装饰器</a>  <li><a href="%h4_12">4.12 优化模式</a>  <li><a href="%h4_13">4.13 调试</a>  <li><a href="%h4_14">4.14 其他方式定义词法规则</a>  <li><a href="%h4_15">4.15 额外状态维护</a>  <li><a href="%h4_16">4.16 Lexer克隆</a>  <li><a href="%h4_17">4.17 Lexer的内部状态</a>  <li><a href="%h4_18">4.18 基于条件的扫描和启动条件</a>  <li><a href="%h4_19">4.19 其他问题</a></li></ul> <li><a href="%h5">5 语法分析基础</a>  <li><a href="%h6">6 Yacc</a>  <ul> <li><a href="%h6_1">6.1 一个例子</a>  <li><a href="%h6_2">6.2 将语法规则合并</a>  <li><a href="%h6_3">6.3 字面字符</a>  <li><a href="%h6_4">6.4 空产生式</a>  <li><a href="%h6_5">6.5 改变起始符号</a>  <li><a href="%h6_6">6.6 处理二义文法</a>  <li><a href="%h6_7">6.7 parser.out调试文件</a>  <li><a href="%h6_8">6.8 处理语法错误</a>  <ul> <li><a href="%h6_8_1">6.8.1 根据error规则恢复和再同步</a>  <li><a href="%h6_8_2">6.8.2 悲观恢复模式</a>  <li><a href="%h6_8_3">6.8.3 从产生式中抛出错误</a>  <li><a href="%h6_8_4">6.8.4 错误恢复总结</a> </li></ul> <li><a href="%h6_9">6.9 行号和位置的跟踪</a>  <li><a href="%h6_10">6.10 构造抽象语法树</a>  <li><a href="%h6_11">6.11 嵌入式动作</a>  <li><a href="%h6_12">6.12 Yacc的其他</a> </li></ul> <li><a href="%h7">7 多个语法和词法分析器</a>  <li><a href="%h8">8 使用Python的优化模式</a>  <li><a href="%h9">9 高级调试</a>  <ul> <li><a href="%h9_1">9.1 调试lex()和yacc()命令</a>  <li><a href="%h9_2">9.2 运行时调试</a> </li></ul> <li><a href="%h10">10 如何继续</a> </li></ul> <p>&nbsp;</p> <p>&nbsp;</p><a name="1"></a> <h3><font style="font-weight: bold">1 前言和预备</font></h3> <p>本文指导你使用PLY进行词法分析和语法解析的，鉴于解析本身是个复杂性的事情，在你使用PLY投入大规模的开发前，我强烈建议你完整地阅读或者浏览本文档。</p> <p>PLY-3.0能同时兼容Python2和Python3。需要注意的是，对于Python3的支持是新加入的，还没有广泛的测试（尽管所有的例子和单元测试都能够在Pythone3下通过）。如果你使用的是Python2，应该使用Python2.4以上版本，虽然，PLY最低能够支持到Python2.2，不过一些可选的功能需要新版本模块的支持。</p> <p>&nbsp;</p><a name="2"></a> <h3><font style="font-weight: bold">2 介绍</font></h3> <p>PLY是纯粹由Python实现的Lex和yacc（流行的编译器构建工具）。PLY的设计目标是尽可能的沿袭传统lex和yacc工具的工作方式，包括支持LALR(1)分析法、提供丰富的输入验证、错误报告和诊断。因此，如果你曾经在其他编程语言下使用过yacc，你应该能够很容易的迁移到PLY上。</p> <p>2001年，我在芝加哥大学教授“编译器简介”课程时开发了的早期的PLY。学生们使用Python和PLY构建了一个类似Pascal的语言的完整编译器，其中的语言特性包括：词法分析、语法分析、类型检查、类型推断、嵌套作用域，并针对SPARC处理器生成目标代码等。最终他们大约实现了30种不同的编译器！PLY在接口设计上影响使用的问题也被学生们所提出。从2001年以来，PLY继续从用户的反馈中不断改进。为了适应对未来的改进需求，PLY3.0在原来基础上进行了重大的重构。</p> <p>由于PLY是作为教学工具来开发的，你会发现它对于标记和语法规则是相当严谨的，这一定程度上是为了帮助新手用户找出常见的编程错误。不过，高级用户也会发现这有助于处理真实编程语言的复杂语法。还需要注意的是，PLY没有提供太多花哨的东西（例如，自动构建抽象语法树和遍历树），我也不认为它是个分析框架。相反，你会发现它是一个用Python实现的，基本的，但能够完全胜任的lex/yacc。</p> <p>本文的假设你多少熟悉分析理论、语法制导的翻译、基于其他编程语言使用过类似lex和yacc的编译器构建工具。如果你对这些东西不熟悉，你可能需要先去一些书籍中学习一些基础，比如：Aho, Sethi和Ullman的《Compilers: Principles, Techniques, and Tools》（《编译原理》），和O'Reilly'出版的John Levine的《lex and yacc》。事实上，《lex and yacc》和PLY使用的概念几乎相同。</p> <p>&nbsp;</p><a name="3"></a> <h3><font style="font-weight: bold">3 PLY概要</font></h3> <p>PLY包含两个独立的模块：lex.py和yacc.py，都定义在ply包下。lex.py模块用来将输入字符通过一系列的正则表达式分解成标记序列，yacc.py通过一些上下文无关的文法来识别编程语言语法。yacc.py使用LR解析法，并使用LALR(1)算法（默认）或者SLR算法生成分析表。</p> <p>这两个工具是为了一起工作的。lex.py通过向外部提供<code>token()</code>方法作为接口，方法每次会从输入中返回下一个有效的标记。yacc.py将会不断的调用这个方法来获取标记并匹配语法规则。yacc.py的的功能通常是生成抽象语法树(AST)，不过，这完全取决于用户，如果需要，yacc.py可以直接用来完成简单的翻译。</p> <p>就像相应的unix工具，yacc.py提供了大多数你期望的特性，其中包括：丰富的错误检查、语法验证、支持空产生式、错误的标记、通过优先级规则解决二义性。事实上，传统yacc能够做到的PLY都应该支持。</p> <p>yacc.py与Unix下的yacc的主要不同之处在于，yacc.py没有包含一个独立的代码生成器，而是在PLY中依赖反射来构建词法分析器和语法解析器。不像传统的lex/yacc工具需要一个独立的输入文件，并将之转化成一个源文件，Python程序必须是一个可直接可用的程序，这意味着不能有额外的源文件和特殊的创建步骤（像是那种执行yacc命令来生成Python代码）。又由于生成分析表开销较大，PLY会缓存生成的分析表，并将它们保存在独立的文件中，除非源文件有变化，会重新生成分析表，否则将从缓存中直接读取。</p> <p>&nbsp;</p><a name="4"></a> <h3><font style="font-weight: bold">4 Lex</font></h3> <p>lex.py是用来将输入字符串标记化。例如，假设你正在设计一个编程语言，用户的输入字符串如下：</p><pre><code>x = 3 + 42 * (s - t)</code></pre>%n<p>标记器将字符串分割成独立的标记：</p><pre><code>'x','=', '3', '+', '42', '*', '(', 's', '-', 't', ')'</code></pre>%n<p>标记通常用一组名字来命名和表示：</p><pre><code>'ID','EQUALS','NUMBER','PLUS','NUMBER','TIMES','LPAREN','ID','MINUS','ID','RPAREN'</code></pre>%n<p>将标记名和标记值本身组合起来：</p><pre><code>('ID','x'), ('EQUALS','='), ('NUMBER','3'),('PLUS','+'), ('NUMBER','42), ('TIMES','*'),('LPAREN','('), ('ID','s'),('MINUS','-'),('ID','t'), ('RPAREN',')</code></pre>%n<p>正则表达式是描述标记规则的典型方法，下一节展示如何用lex.py实现。</p>%n<p>&nbsp;</p><a name="4_1"></a>%n<h4><font style="font-weight: bold">4.1 Lex的例子</font></h4>%n<p>下面的例子展示了如何使用lex.py对输入进行标记</p><pre><code>%n%h ------------------------------------------------------------%n%h calclex.py%n%h%n%h tokenizer for a simple expression evaluator for%n%h numbers and +,-,*,/%n%h ------------------------------------------------------------%nimport ply.lex as lex%n%n%h List of token names.   This is always required%ntokens = (%n   'NUMBER',%n   'PLUS',%n   'MINUS',%n   'TIMES',%n   'DIVIDE',%n   'LPAREN',%n   'RPAREN',%n)%n%n%h Regular expression rules for simple tokens%nt_PLUS    = r'\+'%nt_MINUS   = r'-'%nt_TIMES   = r'\*'%nt_DIVIDE  = r'/'%nt_LPAREN  = r'\('%nt_RPAREN  = r'\)'%n%n%h A regular expression rule with some action code%ndef t_NUMBER(t):%n    r'\d+'%n    t.value = int(t.value)    %n    return t%n%n%h Define a rule so we can track line numbers%ndef t_newline(t):%n    r'\n+'%n    t.lexer.lineno += len(t.value)%n%n%h A string containing ignored characters (spaces and tabs)%nt_ignore  = ' \t'%n%n%h Error handling rule%ndef t_error(t):%n    print "Illegal character '%ps'" %p t.value[0]%n    t.lexer.skip(1)%n%n%h Build the lexer%nlexer = lex.lex()%n</code></pre>%n<p>为了使lexer工作，你需要给定一个输入，并传递给input()方法。然后，重复调用token()方法来获取标记序列，下面的代码展示了这种用法：</p><pre><code>%n%h Test it out%ndata = '''%n3 + 4 * 10%n  + -20 *2%n'''%n%n%h Give the lexer some input%nlexer.input(data)%n%n%h Tokenize%nwhile True:%n    tok = lexer.token()%n    if not tok: break      %h No more input%n    print tok%n</code></pre>%n<p>程序执行，将给出如下输出：</p><pre><code>$ python example.py%nLexToken(NUMBER,3,2,1)%nLexToken(PLUS,'+',2,3)%nLexToken(NUMBER,4,2,5)%nLexToken(TIMES,'*',2,7)%nLexToken(NUMBER,10,2,10)%nLexToken(PLUS,'+',3,14)%nLexToken(MINUS,'-',3,16)%nLexToken(NUMBER,20,3,18)%nLexToken(TIMES,'*',3,20)%nLexToken(NUMBER,2,3,21)%n</code></pre>%n<p>Lexers也同时支持迭代，你可以把上面的循环写成这样：</p><pre><code>%nfor tok in lexer:%n    print tok%n</code></pre>%n<p>由<code>lexer.token()</code>方法返回的标记是<code>LexToken</code>类型的实例，拥有<code>tok.type</code>,<code>tok.value</code>,<code>tok.lineno</code>和<code>tok.lexpos</code>属性，下面的代码展示了如何访问这些属性： </p><pre><code>%h Tokenize%nwhile True:%n    tok = lexer.token()%n    if not tok: break      %h No more input%n    print tok.type, tok.value, tok.line, tok.lexpos%n</code></pre>%n<p><code>tok.type</code>和<code>tok.value</code>属性表示标记本身的类型和值。<code>tok.line</code>和<code>tok.lexpos</code>属性包含了标记的位置信息，<code>tok.lexpos</code>表示标记相对于输入串起始位置的偏移。 </p>%n<p>&nbsp;</p><a name="4_2"></a>%n<h4><font style="font-weight: bold">4.2 标记列表</font></h4>%n<p>词法分析器必须提供一个标记的列表，这个列表将所有可能的标记告诉分析器，用来执行各种验证，同时也提供给yacc.py作为终结符。</p>%n<p>在上面的例子中，是这样给定标记列表的：</p><pre><code>tokens = (%n   'NUMBER',%n   'PLUS',%n   'MINUS',%n   'TIMES',%n   'DIVIDE',%n   'LPAREN',%n   'RPAREN',%n)</code></pre>%n<p>&nbsp;</p><a name="4_3"></a>%n<h4><font style="font-weight: bold">4.3 标记的规则</font></h4>%n<p>每种标记用一个正则表达式规则来表示，每个规则需要以"t_"开头声明，表示该声明是对标记的规则定义。对于简单的标记，可以定义成这样（在Python中使用raw string能比较方便的书写正则表达式）：</p><pre><code>t_PLUS = r'\+'</code></pre>%n<p>这里，紧跟在t_后面的单词，必须跟标记列表中的某个标记名称对应。如果需要执行动作的话，规则可以写成一个方法。例如，下面的规则匹配数字字串，并且将匹配的字符串转化成Python的整型：</p><pre><code>def t_NUMBER(t):%n    r'\d+'%n    t.value = int(t.value)%n    return t</code></pre>%n<p>如果使用方法的话，正则表达式写成方法的文档字符串。方法总是需要接受一个<code>LexToken</code>实例的参数，该实例有一个<code>t.type</code>的属性（字符串表示）来表示标记的类型名称，<code>t.value</code>是标记值（匹配的实际的字符串），<code>t.lineno</code>表示当前在源输入串中的作业行，<code>t.lexpos</code>表示标记相对于输入串起始位置的偏移。默认情况下，<code>t.type</code>是以t_开头的变量或方法的后面部分。方法可以在方法体里面修改这些属性。但是，如果这样做，应该返回结果token，否则，标记将被丢弃。 <br>在lex内部，lex.py用<code>re</code>模块处理模式匹配，在构造最终的完整的正则式的时候，用户提供的规则按照下面的顺序加入：</p>%n<ol>%n<li>所有由方法定义的标记规则，按照他们的出现顺序依次加入 %n<li>由字符串变量定义的标记规则按照其正则式长度倒序后，依次加入（长的先入） </li></ol>%n<p>顺序的约定对于精确匹配是必要的。比如，如果你想区分‘=’和‘==’，你需要确保‘==’优先检查。如果用字符串来定义这样的表达式的话，通过将较长的正则式先加入，可以帮助解决这个问题。用方法定义标记，可以显示地控制哪个规则优先检查。 <br>为了处理保留字，你应该写一个单一的规则来匹配这些标识，并在方法里面作特殊的查询：</p><pre><code>reserved = {%n   'if' : 'IF',%n   'then' : 'THEN',%n   'else' : 'ELSE',%n   'while' : 'WHILE',%n   ...%n}%n%ntokens = ['LPAREN','RPAREN',...,'ID'] + list(reserved.values())%n%ndef t_ID(t):%n    r'[a-zA-Z_][a-zA-Z_0-9]*'%n    t.type = reserved.get(t.value,'ID')    %h Check for reserved words%n    return t</code></pre>%n<p>这样做可以大大减少正则式的个数，并稍稍加快处理速度。注意：你应该避免为保留字编写单独的规则，例如，如果你像下面这样写：</p><pre><code>t_FOR   = r'for'%nt_PRINT = r'print'</code></pre>%n<p>但是，这些规则照样也能够匹配以这些字符开头的单词，比如'forget'或者'printed'，这通常不是你想要的。</p>%n<p>&nbsp;</p><a name="4_4"></a>%n<h4><font style="font-weight: bold">4.4 标记的值</font></h4>%n<p>标记被lex返回后，它们的值被保存在<code>value</code>属性中。正常情况下，<code>value</code>是匹配的实际文本。事实上，<code>value</code>可以被赋为任何Python支持的类型。例如，当扫描到标识符的时候，你可能不仅需要返回标识符的名字，还需要返回其在符号表中的位置，可以像下面这样写：</p><pre><code>def t_ID(t):%n    ...%n    %h Look up symbol table information and return a tuple%n    t.value = (t.value, symbol_lookup(t.value))%n    ...%n    return t%n</code></pre>%n<p>需要注意的是，不推荐用其他属性来保存值，因为yacc.py模块只会暴露出标记的<code>value</code>属性，访问其他属性会变得不自然。如果想保存多种属性，可以将元组、字典、或者对象实例赋给value。</p>%n<p>&nbsp;</p><a name="4_5"></a>%n<h4><font style="font-weight: bold">4.5 丢弃标记</font></h4>%n<p>想丢弃像注释之类的标记，只要不返回value就行了，像这样：</p><pre><code>def t_COMMENT(t):%n    r'\%h.*'%n    pass%n    %h No return value. Token discarded</code></pre>%n<p>为标记声明添加"ignore_"前缀同样可以达到目的：</p><pre><code>t_ignore_COMMENT = r'\%h.*'</code></pre>%n<p>如果有多种文本需要丢弃，建议使用方法来定义规则，因为方法能够提供更精确的匹配优先级控制（方法根据出现的顺序，而字符串的正则表达式依据正则表达式的长度）</p>%n<p>&nbsp;</p><a name="4_6"></a>%n<h4><font style="font-weight: bold">4.6 行号和位置信息</font></h4>%n<p>默认情况下，lex.py对行号一无所知。因为lex.py根本不知道何为"行"的概念（换行符本身也作为文本的一部分）。不过，可以通过写一个特殊的规则来记录行号：</p><pre><code>%h Define a rule so we can track line numbers%ndef t_newline(t):%n    r'\n+'%n    t.lexer.lineno += len(t.value)</code></pre>%n<p>在这个规则中，当前lexer对象t.lexer的lineno属性被修改了，而且空行被简单的丢弃了，因为没有任何的返回。</p>%n<p>lex.py也不自动做列跟踪。但是，位置信息被记录在了每个标记对象的lexpos属性中，这样，就有可能来计算列信息了。例如：每当遇到新行的时候就重置列值：</p><pre><code>%h Compute column. %n%h     input is the input text string%n%h     token is a token instance%ndef find_column(input,token):%n    last_cr = input.rfind('\n',0,token.lexpos)%n    if last_cr &lt; 0:%n        last_cr = 0%n    column = (token.lexpos - last_cr) + 1%n    return column</code></pre>%n<p>通常，计算列的信息是为了指示上下文的错误位置，所以只在必要时有用。</p>%n<p>&nbsp;</p><a name="4_7"></a>%n<h4><font style="font-weight: bold">4.7 忽略字符</font></h4>%n<p><code>t_ignore</code>规则比较特殊，是lex.py所保留用来忽略字符的，通常用来跳过空白或者不需要的字符。虽然可以通过定义像<code>t_newline()</code>这样的规则来完成相同的事情，不过使用t_ignore能够提供较好的词法分析性能，因为相比普通的正则式，它被特殊化处理了。</p>%n<p>&nbsp;</p><a name="4_8"></a>%n<h4><font style="font-weight: bold">4.8 字面字符</font></h4>%n<p>字面字符可以通过在词法模块中定义一个<code>literals</code>变量做到，例如：</p><pre><code>literals = [ '+','-','*','/' ]</code></pre>%n<p>或者</p><pre><code>literals = "+-*/"</code></pre>%n<p>字面字符是指单个字符，表示把字符本身作为标记，标记的<code>type</code>和<code>value</code>都是字符本身。不过，字面字符是在其他正则式之后被检查的，因此如果有规则是以这些字符开头的，那么这些规则的优先级较高。</p>%n<p>&nbsp;</p><a name="4_9"></a>%n<h4><font style="font-weight: bold">4.9 错误处理</font></h4>%n<p>最后，在词法分析中遇到非法字符时，<code>t_error()</code>用来处理这类错误。这种情况下，<code>t.value</code>包含了余下还未被处理的输入字串，在之前的例子中，错误处理方法是这样的：</p><pre><code>%h Error handling rule%ndef t_error(t):%n    print "Illegal character '%ps'" %p t.value[0]%n    t.lexer.skip(1)</code></pre>%n<p>这个例子中，我们只是简单的输出不合法的字符，并且通过调用<code>t.lexer.skip(1)</code>跳过一个字符。</p>%n<p>&nbsp;</p><a name="4_10"></a>%n<h4><font style="font-weight: bold">4.10 构建和使用lexer</font></h4>%n<p>函数<code>lex.lex()</code>使用Python的反射机制读取调用上下文中的正则表达式，来创建lexer。lexer一旦创建好，有两个方法可以用来控制lexer对象：</p>%n<ul>%n<li><code>lexer.input(data)</code> 重置lexer和输入字串 %n<li><code>lexer.token()</code> 返回下一个<code>LexToken</code>类型的标记实例，如果进行到输入字串的尾部时将返回<code>None</code> </li></ul>%n<p>推荐直接在<code>lex()</code>函数返回的lexer对象上调用上述接口，尽管也可以向下面这样用模块级别的<code>lex.input()</code>和<code>lex.token()</code>：</p><pre><code>lex.lex()%nlex.input(sometext)%nwhile 1:%n    tok = lex.token()%n    if not tok: break%n    print tok</code></pre>%n<p>在这个例子中，<code>lex.input()</code>和<code>lex.token()</code>是模块级别的方法，在lex模块中，<code>input()</code>和<code>token()</code>方法绑定到最新创建的lexer对象的对应方法上。最好不要这样用，因为这种接口可能不知道在什么时候就失效（译者注：垃圾回收？）</p>%n<p>&nbsp;</p><a name="4_11"></a>%n<h4><font style="font-weight: bold">4.11 @TOKEN装饰器</font></h4>%n<p>在一些应用中，你可能需要定义一系列辅助的记号来构建复杂的正则表达式，例如：</p><pre><code>digit            = r'([0-9])'%nnondigit         = r'([_A-Za-z])'%nidentifier       = r'(' + nondigit + r'(' + digit + r'|' + nondigit + r')*)'        %n%ndef t_ID(t):%n    %h want docstring to be identifier above. ?????%n    ...</code></pre>%n<p>在这个例子中，我们希望ID的规则引用上面的已有的变量。然而，使用文档字符串无法做到，为了解决这个问题，你可以使用<strong>@TOKEN</strong>装饰器：</p><pre><code>from ply.lex import TOKEN%n%n@TOKEN(identifier)%ndef t_ID(t):%n    ...</code></pre>%n<p>装饰器可以将identifier关联到t_ID()的文档字符串上以使lex.py正常工作，一种等价的做法是直接给文档字符串赋值：</p><pre><code>def t_ID(t):%n    ...%n%nt_ID.__doc__ = identifier</code></pre>%n<p>注意：@TOKEN装饰器需要Python-2.4以上的版本。如果你在意老版本Python的兼容性问题，使用上面的等价办法。</p>%n<p>&nbsp;</p><a name="4_12"></a>%n<h4><font style="font-weight: bold">4.12 优化模式</font></h4>%n<p>为了提高性能，你可能希望使用Python的优化模式（比如，使用-o选项执行Python）。然而，这样的话，Python会忽略文档字串，这是lex.py的特殊问题，可以通过在创建lexer的时候使用<code>optimize</code>选项：</p><pre><code>lexer = lex.lex(optimize=1)</code></pre>%n<p>接着，用Python常规的模式运行，这样，lex.py会在当前目录下创建一个lextab.py文件，这个文件会包含所有的正则表达式规则和词法分析阶段的分析表。然后，lextab.py可以被导入用来构建lexer。这种方法大大改善了词法分析程序的启动时间，而且可以在Python的优化模式下工作。</p>%n<p>想要更改生成的文件名，使用如下参数：</p><pre><code>lexer = lex.lex(optimize=1,lextab="footab")</code></pre>%n<p>在优化模式下执行，需要注意的是lex会被禁用大多数的错误检查。因此，建议只在确保万事俱备准备发布最终代码时使用。</p>%n<p>&nbsp;</p><a name="4_13"></a>%n<h4><font style="font-weight: bold">4.13 调试</font></h4>%n<p>如果想要调试，可以使lex()运行在调试模式：</p><pre><code>lexer = lex.lex(debug=1)</code></pre>%n<p>这将打出一些调试信息，包括添加的规则、最终的正则表达式和词法分析过程中得到的标记。</p>%n<p>除此之外，lex.py有一个简单的主函数，不但支持对命令行参数输入的字串进行扫描，还支持命令行参数指定的文件名：</p><pre><code>if __name__ == '__main__':%n     lex.runmain()</code></pre>%n<p>想要了解高级调试的详情，请移步至最后的<a href="%h9">高级调试</a>部分。</p>%n<p>&nbsp;</p><a name="4_14"></a>%n<h4><font style="font-weight: bold">4.14 其他方式定义词法规则</font></h4>%n<p>上面的例子，词法分析器都是在单个的Python模块中指定的。如果你想将标记的规则放到不同的模块，使用<code>module</code>关键字参数。例如，你可能有一个专有的模块，包含了标记的规则：</p><pre><code>%h module: tokrules.py%n%h This module just contains the lexing rules%n%n%h List of token names.   This is always required%ntokens = (%n   'NUMBER',%n   'PLUS',%n   'MINUS',%n   'TIMES',%n   'DIVIDE',%n   'LPAREN',%n   'RPAREN',%n)%n%n%h Regular expression rules for simple tokens%nt_PLUS    = r'\+'%nt_MINUS   = r'-'%nt_TIMES   = r'\*'%nt_DIVIDE  = r'/'%nt_LPAREN  = r'\('%nt_RPAREN  = r'\)'%n%n%h A regular expression rule with some action code%ndef t_NUMBER(t):%n    r'\d+'%n    t.value = int(t.value)    %n    return t%n%n%h Define a rule so we can track line numbers%ndef t_newline(t):%n    r'\n+'%n    t.lexer.lineno += len(t.value)%n%n%h A string containing ignored characters (spaces and tabs)%nt_ignore  = ' \t'%n%n%h Error handling rule%ndef t_error(t):%n    print "Illegal character '%ps'" %p t.value[0]%n    t.lexer.skip(1)</code></pre>%n<p>现在，如果你想要从不同的模块中构建分析器，应该这样（在交互模式下）：</p><pre><code>&gt;&gt;&gt; import tokrules%n&gt;&gt;&gt; <b>lexer = lex.lex(module=tokrules)</b>%n&gt;&gt;&gt; lexer.input("3 + 4")%n&gt;&gt;&gt; lexer.token()%nLexToken(NUMBER,3,1,1,0)%n&gt;&gt;&gt; lexer.token()%nLexToken(PLUS,'+',1,2)%n&gt;&gt;&gt; lexer.token()%nLexToken(NUMBER,4,1,4)%n&gt;&gt;&gt; lexer.token()%nNone</code></pre>%n<p><code>module</code>选项也可以指定类型的实例，例如：</p><pre><code>import ply.lex as lex%n%nclass MyLexer:%n    %h List of token names.   This is always required%n    tokens = (%n       'NUMBER',%n       'PLUS',%n       'MINUS',%n       'TIMES',%n       'DIVIDE',%n       'LPAREN',%n       'RPAREN',%n    )%n%n    %h Regular expression rules for simple tokens%n    t_PLUS    = r'\+'%n    t_MINUS   = r'-'%n    t_TIMES   = r'\*'%n    t_DIVIDE  = r'/'%n    t_LPAREN  = r'\('%n    t_RPAREN  = r'\)'%n%n    %h A regular expression rule with some action code%n    %h Note addition of self parameter since we're in a class%n    def t_NUMBER(self,t):%n        r'\d+'%n        t.value = int(t.value)    %n        return t%n%n    %h Define a rule so we can track line numbers%n    def t_newline(self,t):%n        r'\n+'%n        t.lexer.lineno += len(t.value)%n%n    %h A string containing ignored characters (spaces and tabs)%n    t_ignore  = ' \t'%n%n    %h Error handling rule%n    def t_error(self,t):%n        print "Illegal character '%ps'" %p t.value[0]%n        t.lexer.skip(1)%n%n    <b>%h Build the lexer%n    def build(self,**kwargs):%n        self.lexer = lex.lex(module=self, **kwargs)</b>%n    %n    %h Test it output%n    def test(self,data):%n        self.lexer.input(data)%n        while True:%n             tok = lexer.token()%n             if not tok: break%n             print tok%n%n%h Build the lexer and try it out%nm = MyLexer()%nm.build()           %h Build the lexer%nm.test("3 + 4")     %h Test it</code></pre>%n<p>当从类中定义lexer，你需要创建类的实例，而不是类本身。这是因为，lexer的方法只有被绑定（bound-methods）对象后才能使PLY正常工作。 </p>%n<p>当给<code>lex()</code>方法使用<code>module</code>选项时，PLY使用<code>dir()</code>方法，从对象中获取符号信息，因为不能直接访问对象的<code>__dict__</code>属性。（译者注：可能是因为兼容性原因<code>，__dict__</code>这个方法可能不存在）</p>%n<p>最后，如果你希望保持较好的封装性，但不希望什么东西都写在类里面，lexers可以在闭包中定义，例如：</p><pre><code>import ply.lex as lex%n%n%h List of token names.   This is always required%ntokens = (%n  'NUMBER',%n  'PLUS',%n  'MINUS',%n  'TIMES',%n  'DIVIDE',%n  'LPAREN',%n  'RPAREN',%n)%n%ndef MyLexer():%n    %h Regular expression rules for simple tokens%n    t_PLUS    = r'\+'%n    t_MINUS   = r'-'%n    t_TIMES   = r'\*'%n    t_DIVIDE  = r'/'%n    t_LPAREN  = r'\('%n    t_RPAREN  = r'\)'%n%n    %h A regular expression rule with some action code%n    def t_NUMBER(t):%n        r'\d+'%n        t.value = int(t.value)    %n        return t%n%n    %h Define a rule so we can track line numbers%n    def t_newline(t):%n        r'\n+'%n        t.lexer.lineno += len(t.value)%n%n    %h A string containing ignored characters (spaces and tabs)%n    t_ignore  = ' \t'%n%n    %h Error handling rule%n    def t_error(t):%n        print "Illegal character '%ps'" %p t.value[0]%n        t.lexer.skip(1)%n%n    %h Build the lexer from my environment and return it    %n    return lex.lex()</code></pre>%n<p>&nbsp;</p><a name="4_15"></a>%n<h4><font style="font-weight: bold">4.15 额外状态维护</font></h4>%n<p>在你的词法分析器中，你可能想要维护一些状态。这可能包括模式设置，符号表和其他细节。例如，假设你想要跟踪<code>NUMBER</code>标记的出现个数。</p>%n<p>一种方法是维护一个全局变量：</p><pre><code>num_count = 0%ndef t_NUMBER(t):%n    r'\d+'%n    global num_count%n    num_count += 1%n    t.value = int(t.value)    %n    return t</code></pre>%n<p>如果你不喜欢全局变量，另一个记录信息的地方是lexer对象内部。可以通过当前标记的lexer属性访问：</p><pre><code>def t_NUMBER(t):%n    r'\d+'%n    t.lexer.num_count += 1     %h Note use of lexer attribute%n    t.value = int(t.value)    %n    return t%n%nlexer = lex.lex()%nlexer.num_count = 0            %h Set the initial count</code></pre>%n<p>上面这样做的优点是当同时存在多个lexer实例的情况下，简单易行。不过这看上去似乎是严重违反了面向对象的封装原则。lexer的内部属性（除了<code>lineno</code>）都是以lex开头命名的（<code>lexdata</code>、<code>lexpos</code>）。因此，只要不以lex开头来命名属性就很安全的。</p>%n<p>如果你不喜欢给lexer对象赋值，你可以自定义你的lexer类型，就像前面看到的那样：</p><pre><code>class MyLexer:%n    ...%n    def t_NUMBER(self,t):%n        r'\d+'%n        self.num_count += 1%n        t.value = int(t.value)    %n        return t%n%n    def build(self, **kwargs):%n        self.lexer = lex.lex(object=self,**kwargs)%n%n    def __init__(self):%n        self.num_count = 0</code></pre>%n<p>如果你的应用会创建很多lexer的实例，并且需要维护很多状态，上面的类可能是最容易管理的。</p>%n<p>状态也可以用闭包来管理，比如，在Python3中：</p><pre><code>def MyLexer():%n    num_count = 0%n    ...%n    def t_NUMBER(t):%n        r'\d+'%n        nonlocal num_count%n        num_count += 1%n        t.value = int(t.value)    %n        return t%n    ...</code></pre>%n<p>&nbsp;</p><a name="4_16"></a>%n<h4><font style="font-weight: bold">4.16 Lexer克隆</font></h4>%n<p>如果有必要的话，lexer对象可以通过<code>clone()</code>方法来复制：</p><pre><code>lexer = lex.lex()%n...%nnewlexer = lexer.clone()</code></pre>%n<p>当lexer被克隆后，复制品能够精确的保留输入串和内部状态，不过，新的lexer可以接受一个不同的输出字串，并独立运作起来。这在几种情况下也许有用：当你在编写的解析器或编译器涉及到递归或者回退处理时，你需要扫描先前的部分，你可以clone并使用复制品，或者你在实现某种预编译处理，可以clone一些lexer来处理不同的输入文件。</p>%n<p>创建克隆跟重新调用<code>lex.lex()</code>的不同点在于，PLY不会重新构建任何的内部分析表或者正则式。当lexer是用类或者闭包创建的，需要注意类或闭包本身的的状态。换句话说你要注意新创建的lexer会共享原始lexer的这些状态，比如：</p><pre><code>m = MyLexer()%na = lex.lex(object=m)      %h Create a lexer%n%nb = a.clone()              %h Clone the lexer</code></pre>%n<p>&nbsp;</p><a name="4_17"></a>%n<h4><font style="font-weight: bold">4.17 Lexer的内部状态</font></h4>%n<p>lexer有一些内部属性在特定情况下有用：</p>%n<ul>%n<li><code>lexer.lexpos</code>。这是一个表示当前分析点的位置的整型值。如果你修改这个值的话，这会改变下一个<code>token()</code>的调用行为。在标记的规则方法里面，这个值表示紧跟匹配字串后面的第一个字符的位置，如果这个值在规则中修改，下一个返回的标记将从新的位置开始匹配 %n<li><code>lexer.lineno</code>。表示当前行号。PLY只是声明这个属性的存在，却永远不更新这个值。如果你想要跟踪行号的话，你需要自己添加代码（ <a href="%h4_6">4.6 行号和位置信息</a>） %n<li><code>lexer.lexdata</code>。当前lexer的输入字串，这个字符串就是input()方法的输入字串，更改它可能是个糟糕的做法，除非你知道自己在干什么。 %n<li><code>lexer.lexmatch</code>。PLY内部调用Python的re.match()方法得到的当前标记的原始的Match对象，该对象被保存在这个属性中。如果你的正则式中包含分组的话，你可以通过这个对象获得这些分组的值。注意：这个属性只在有标记规则定义的方法中才有效。</li></ul>%n<p>&nbsp;</p><a name="4_18"></a>%n<h4><font style="font-weight: bold">4.18 基于条件的扫描和启动条件</font></h4>%n<p>在高级的分析器应用程序中，使用状态化的词法扫描是很有用的。比如，你想在出现特定标记或句子结构的时候触发开始一个不同的词法分析逻辑。PLY允许lexer在不同的状态之间转换。每个状态可以包含一些自己独特的标记和规则等。这是基于GNU flex的“启动条件”来实现的，关于flex详见<a href="http://flex.sourceforge.net/manual/Start-Conditions.html%hStart-Conditions">http://flex.sourceforge.net/manual/Start-Conditions.html%hStart-Conditions</a></p>%n<p>要使用lex的状态，你必须首先声明。通过在lex模块中声明"states"来做到：</p><pre><code>states = (%n   ('foo','exclusive'),%n   ('bar','inclusive'),%n)</code></pre>%n<p>这个声明中包含有两个状态：'foo'和'bar'。状态可以有两种类型：'排他型'和'包容型'。排他型的状态会使得lexer的行为发生完全的改变：只有能够匹配在这个状态下定义的规则的标记才会返回；包容型状态会将定义在这个状态下的规则添加到默认的规则集中，进而，只要能匹配这个规则集的标记都会返回。</p>%n<p>一旦声明好之后，标记规则的命名需要包含状态名：</p><pre><code>t_foo_NUMBER = r'\d+'                      %h Token 'NUMBER' in state 'foo'        %nt_bar_ID     = r'[a-zA-Z_][a-zA-Z0-9_]*'   %h Token 'ID' in state 'bar'%n%ndef t_foo_newline(t):%n    r'\n'%n    t.lexer.lineno += 1</code></pre>%n<p>一个标记可以用在多个状态中，只要将多个状态名包含在声明中：</p><pre><code>t_foo_bar_NUMBER = r'\d+'         %h Defines token 'NUMBER' in both state 'foo' and 'bar'</code></pre>%n<p>同样的，在任何状态下都生效的声明可以在命名中使用<code>ANY</code>：</p><pre><code>t_ANY_NUMBER = r'\d+'         %h Defines a token 'NUMBER' in all states</code></pre>%n<p>不包含状态名的情况下，标记被关联到一个特殊的状态<code>INITIAL</code>，比如，下面两个声明是等价的：</p><pre><code>t_NUMBER = r'\d+'%nt_INITIAL_NUMBER = r'\d+'</code></pre>%n<p>特殊的<code>t_ignore()</code>和<code>t_error()</code>也可以用状态关联：</p><pre><code>t_foo_ignore = " \t\n"       %h Ignored characters for state 'foo'%n%ndef t_bar_error(t):          %h Special error handler for state 'bar'%n    pass </code></pre>%n<p>词法分析默认在<code>INITIAL</code>状态下工作，这个状态下包含了所有默认的标记规则定义。对于不希望使用“状态”的用户来说，这是完全透明的。在分析过程中，如果你想要改变词法分析器的这种的状态，使用<code>begin()</code>方法： </p><pre><code>def t_begin_foo(t):%n    r'start_foo'%n    t.lexer.begin('foo')             %h Starts 'foo' state</code></pre>%n<p>使用<code>begin()</code>切换回初始状态：</p><pre><code>def t_foo_end(t):%n    r'end_foo'%n    t.lexer.begin('INITIAL')        %h Back to the initial state</code></pre>%n<p>状态的切换可以使用栈：</p><pre><code>def t_begin_foo(t):%n    r'start_foo'%n    t.lexer.push_state('foo')             %h Starts 'foo' state%n%ndef t_foo_end(t):%n    r'end_foo'%n    t.lexer.pop_state()                   %h Back to the previous state</code></pre>%n<p>当你在面临很多状态可以选择进入，而又仅仅想要回到之前的状态时，状态栈比较有用。</p>%n<p>举个例子会更清晰。假设你在写一个分析器想要从一堆C代码中获取任意匹配的闭合的大括号里面的部分：这意味着，当遇到起始括号'{'，你需要读取与之匹配的'}'以上的所有部分。并返回字符串。使用通常的正则表达式几乎不可能，这是因为大括号可以嵌套，而且可以有注释，字符串等干扰。因此，试图简单的匹配第一个出现的'}'是不行的。这里你可以用lex的状态来做到：</p><pre><code>%h Declare the state%nstates = (%n  ('ccode','exclusive'),%n)%n%n%h Match the first {. Enter ccode state.%ndef t_ccode(t):%n    r'\{'%n    t.lexer.code_start = t.lexer.lexpos        %h Record the starting position%n    t.lexer.level = 1                          %h Initial brace level%n    t.lexer.begin('ccode')                     %h Enter 'ccode' state%n%n%h Rules for the ccode state%ndef t_ccode_lbrace(t):     %n    r'\{'%n    t.lexer.level +=1                %n%ndef t_ccode_rbrace(t):%n    r'\}'%n    t.lexer.level -=1%n%n    %h If closing brace, return the code fragment%n    if t.lexer.level == 0:%n         t.value = t.lexer.lexdata[t.lexer.code_start:t.lexer.lexpos+1]%n         t.type = "CCODE"%n         t.lexer.lineno += t.value.count('\n')%n         t.lexer.begin('INITIAL')           %n         return t%n%n%h C or C++ comment (ignore)    %ndef t_ccode_comment(t):%n    r'(/\*(.|\n)*?*/)|(//.*)'%n    pass%n%n%h C string%ndef t_ccode_string(t):%n   r'\"([^\\\n]|(\\.))*?\"'%n%n%h C character literal%ndef t_ccode_char(t):%n   r'\'([^\\\n]|(\\.))*?\''%n%n%h Any sequence of non-whitespace characters (not braces, strings)%ndef t_ccode_nonspace(t):%n   r'[^\s\{\}\'\"]+'%n%n%h Ignored characters (whitespace)%nt_ccode_ignore = " \t\n"%n%n%h For bad characters, we just skip over it%ndef t_ccode_error(t):%n    t.lexer.skip(1)</code></pre>%n<p>这个例子中，第一个'{'使得lexer记录了起始位置，并且进入新的状态'ccode'。一系列规则用来匹配接下来的输入，这些规则只是丢弃掉标记（不返回值），如果遇到闭合右括号，t_ccode_rbrace规则收集其中所有的代码（利用先前记录的开始位置），并保存，返回的标记类型为'CCODE'，与此同时，词法分析的状态退回到初始状态。</p>%n<p>&nbsp;</p><a name="4_19"></a>%n<h4><font style="font-weight: bold">4.19 其他问题</font></h4>%n<ul>%n<li>lexer需要输入的是一个字符串。好在大多数机器都有足够的内存，这很少导致性能的问题。这意味着，lexer现在还不能用来处理文件流或者socket流。这主要是受到re模块的限制。 %n<li>lexer支持用Unicode字符描述标记的匹配规则，也支持输入字串包含Unicode %n<li>如果你想要向re.compile()方法提供flag，使用reflags选项：<code>lex.lex(reflags=re.UNICODE)</code> %n<li>由于lexer是全部用Python写的，性能很大程度上取决于Python的re模块，即使已经尽可能的高效了。当接收极其大量的输入文件时表现并不尽人意。如果担忧性能，你可以升级到最新的Python，或者手工创建分析器，或者用C语言写lexer并做成扩展模块。</li></ul>%n<p>如果你要创建一个手写的词法分析器并计划用在yacc.py中，只需要满足下面的要求：</p>%n<ul>%n<li>需要提供一个<code>token()</code>方法来返回下一个标记，如果没有可用的标记了，则返回None。 %n<li><code>token()</code>方法必须返回一个tok对象，具有<code>type</code>和<code>value</code>属性。如果行号需要跟踪的话，标记还需要定义<code>lineno</code>属性。</li></ul>%n<p>&nbsp;</p><a name="5"></a>%n<h3><font style="font-weight: bold">5 语法分析基础</font></h3>%n<p>yacc.py用来对语言进行语法分析。在给出例子之前，必须提一些重要的背景知识。首先，‘语法’通常用BNF范式来表达。例如，如果想要分析简单的算术表达式，你应该首先写下无二义的文法：</p><pre><code>expression : expression + term%n           | expression - term%n           | term%n%nterm       : term * factor%n           | term / factor%n           | factor%n%nfactor     : NUMBER%n           | ( expression )%n</code></pre>%n<p>在这个文法中，像<code>NUMBER</code>,<code>+</code>,<code>-</code>,<code>*</code>,<code>/</code>的符号被称为终结符，对应原始的输入。类似<code>term</code>，<code>factor</code>等称为非终结符，它们由一系列终结符或其他规则的符号组成，用来指代语法规则。</p>%n<p>通常使用一种叫语法制导翻译的技术来指定某种语言的语义。在语法制导翻译中，符号及其属性出现在每个语法规则后面的动作中。每当一个语法被识别，动作就能够描述需要做什么。比如，对于上面给定的文法，想要实现一个简单的计算器，应该写成下面这样：</p><pre><code>Grammar                             Action%n--------------------------------    -------------------------------------------- %nexpression0 : expression1 + term    expression0.val = expression1.val + term.val%n            | expression1 - term    expression0.val = expression1.val - term.val%n            | term                  expression0.val = term.val%n%nterm0       : term1 * factor        term0.val = term1.val * factor.val%n            | term1 / factor        term0.val = term1.val / factor.val%n            | factor                term0.val = factor.val%n%nfactor      : NUMBER                factor.val = int(NUMBER.lexval)%n            | ( expression )        factor.val = expression.val%n</code></pre>%n<p>一种理解语法指导翻译的好方法是将符号看成对象。与符号相关的值代表了符号的“状态”（比如上面的val属性），语义行为用一组操作符号及符号值的函数或者方法来表达。</p>%n<p>Yacc用的分析技术是著名的LR分析法或者叫移进-归约分析法。LR分析法是一种自下而上的技术：首先尝试识别右部的语法规则，每当右部得到满足，相应的行为代码将被触发执行，当前右边的语法符号将被替换为左边的语法符号。（归约）</p>%n<p>LR分析法一般这样实现：将下一个符号进栈，然后结合栈顶的符号和后继符号（译者注：下一个将要输入符号），与文法中的某种规则相比较。具体的算法可以在编译器的手册中查到，下面的例子展现了如果通过上面定义的文法，来分析3 + 5 * ( 10 - 20 )这个表达式，$用来表示输入结束</p><pre><code>Step Symbol Stack           Input Tokens            Action%n---- ---------------------  ---------------------   -------------------------------%n1                           3 + 5 * ( 10 - 20 )$    Shift 3%n2    3                        + 5 * ( 10 - 20 )$    Reduce factor : NUMBER%n3    factor                   + 5 * ( 10 - 20 )$    Reduce term   : factor%n4    term                     + 5 * ( 10 - 20 )$    Reduce expr : term%n5    expr                     + 5 * ( 10 - 20 )$    Shift +%n6    expr +                     5 * ( 10 - 20 )$    Shift 5%n7    expr + 5                     * ( 10 - 20 )$    Reduce factor : NUMBER%n8    expr + factor                * ( 10 - 20 )$    Reduce term   : factor%n9    expr + term                  * ( 10 - 20 )$    Shift *%n10   expr + term *                  ( 10 - 20 )$    Shift (%n11   expr + term * (                  10 - 20 )$    Shift 10%n12   expr + term * ( 10                  - 20 )$    Reduce factor : NUMBER%n13   expr + term * ( factor              - 20 )$    Reduce term : factor%n14   expr + term * ( term                - 20 )$    Reduce expr : term%n15   expr + term * ( expr                - 20 )$    Shift -%n16   expr + term * ( expr -                20 )$    Shift 20%n17   expr + term * ( expr - 20                )$    Reduce factor : NUMBER%n18   expr + term * ( expr - factor            )$    Reduce term : factor%n19   expr + term * ( expr - term              )$    Reduce expr : expr - term%n20   expr + term * ( expr                     )$    Shift )%n21   expr + term * ( expr )                    $    Reduce factor : (expr)%n22   expr + term * factor                      $    Reduce term : term * factor%n23   expr + term                               $    Reduce expr : expr + term%n24   expr                                      $    Reduce expr%n25                                             $    Success!%n</code></pre>%n<p>（译者注：action里面的Shift就是进栈动作，简称移进；Reduce是归约）</p>%n<p>在分析表达式的过程中，一个相关的自动状态机和后继符号决定了下一步应该做什么。如果下一个标记看起来是一个有效语法（产生式）的一部分（通过栈上的其他项判断这一点），那么这个标记应该进栈。如果栈顶的项可以组成一个完整的右部语法规则，一般就可以进行“归约”，用产生式左边的符号代替这一组符号。当归约发生时，相应的行为动作就会执行。如果输入标记既不能移进也不能归约的话，就会发生语法错误，分析器必须进行相应的错误恢复。分析器直到栈空并且没有另外的输入标记时，才算成功。<br>需要注意的是，这是基于一个有限自动机实现的，有限自动器被转化成分析表。分析表的构建比较复杂，超出了本文的讨论范围。不过，这构建过程的微妙细节能够解释为什么在上面的例子中，解析器选择在步骤<code>9</code>将标记转移到堆栈中，而不是按照规则expr : expr + term做归约。</p>%n<p><br>&nbsp;</p><a name="6"></a>%n<h3><font style="font-weight: bold">6 Yacc</font></h3>%n<p>ply.yacc模块实现了PLY的分析功能，‘yacc’是‘Yet Another Compiler Compiler’的缩写并保留了其作为Unix工具的名字。<br></p>%n<h4><font style="font-weight: bold">6.1 一个例子</font></h4>%n<p>假设你希望实现上面的简单算术表达式的语法分析，代码如下：</p><pre><code>%h Yacc example%n%nimport ply.yacc as yacc%n%n%h Get the token map from the lexer.  This is required.%nfrom calclex import tokens%n%ndef p_expression_plus(p):%n    'expression : expression PLUS term'%n    p[0] = p[1] + p[3]%n%ndef p_expression_minus(p):%n    'expression : expression MINUS term'%n    p[0] = p[1] - p[3]%n%ndef p_expression_term(p):%n    'expression : term'%n    p[0] = p[1]%n%ndef p_term_times(p):%n    'term : term TIMES factor'%n    p[0] = p[1] * p[3]%n%ndef p_term_div(p):%n    'term : term DIVIDE factor'%n    p[0] = p[1] / p[3]%n%ndef p_term_factor(p):%n    'term : factor'%n    p[0] = p[1]%n%ndef p_factor_num(p):%n    'factor : NUMBER'%n    p[0] = p[1]%n%ndef p_factor_expr(p):%n    'factor : LPAREN expression RPAREN'%n    p[0] = p[2]%n%n%h Error rule for syntax errors%ndef p_error(p):%n    print "Syntax error in input!"%n%n%h Build the parser%nparser = yacc.yacc()%n%nwhile True:%n   try:%n       s = raw_input('calc &gt; ')%n   except EOFError:%n       break%n   if not s: continue%n   result = parser.parse(s)%n   print result%n</code></pre>%n<p>在这个例子中，每个语法规则被定义成一个Python的方法，方法的文档字符串描述了相应的上下文无关文法，方法的语句实现了对应规则的语义行为。每个方法接受一个单独的<code>p</code>参数，<code>p</code>是一个包含有当前匹配语法的符号的序列，<code>p[i]</code>与语法符号的对应关系如下：</p><pre><code>def p_expression_plus(p):%n    'expression : expression PLUS term'%n    %h   ^            ^        ^    ^%n    %h  p[0]         p[1]     p[2] p[3]%n%n    p[0] = p[1] + p[3]%n</code></pre>%n<p>其中，<code>p[i]</code>的值相当于词法分析模块中对<code>p.value</code>属性赋的值，对于非终结符的值，将在归约时由<code>p[0]</code>的赋值决定，这里的值可以是任何类型，当然，大多数情况下只是Python的简单类型、元组或者类的实例。在这个例子中，我们依赖这样一个事实：<code>NUMBER</code>标记的值保存的是整型值，所有规则的行为都是得到这些整型值的算术运算结果，并传递结果。</p>%n<p>注意：在这里负数的下标有特殊意义--这里的p[-1]不等同于p[3]。详见下面的<a href="%h6_11">嵌入式动作</a>部分</p>%n<p>在yacc中定义的第一个语法规则被默认为起始规则（这个例子中的第一个出现的expression规则）。一旦起始规则被分析器归约，而且再无其他输入，分析器终止，最后的值将返回（这个值将是起始规则的p[0]）。注意：也可以通过在<code>yacc()</code>中使用start关键字参数来指定起始规则</p>%n<p><code>p_error</code>(p)规则用于捕获语法错误。详见<a href="%h6_8">处理语法错误</a>部分</p>%n<p>为了构建分析器，需要调用<code>yacc.yacc()</code>方法。这个方法查看整个当前模块，然后试图根据你提供的文法构建LR分析表。第一次执行<code>yacc.yacc()</code>，你会得到如下输出：</p><pre><code>$ python calcparse.py%nGenerating LALR tables%ncalc &gt;%n</code></pre>%n<p>由于分析表的得出相对开销较大（尤其包含大量的语法的情况下），分析表被写入当前目录的一个叫<code>parsetab.py</code>的文件中。除此之外，会生成一个调试文件<code>parser.out</code>。在接下来的执行中，yacc直到发现文法发生变化，才会重新生成分析表和parsetab.py文件，否则yacc会从parsetab.py中加载分析表。注：如果有必要的话这里输出的文件名是可以改的。</p>%n<p>如果在你的文法中有任何错误的话，yacc.py会产生调试信息，而且可能抛出异常。一些可以被检测到的错误如下：</p>%n<ul>%n<li>方法重复定义（在语法文件中具有相同名字的方法） %n<li>二义文法产生的移进-归约和归约-归约冲突 %n<li>指定了错误的文法 %n<li>不可终止的递归（规则永远无法终结） %n<li>未使用的规则或标记 %n<li>未定义的规则或标记</li></ul>%n<p>下面几个部分将更详细的讨论语法规则</p>%n<p>这个例子的最后部分展示了如何执行由<code>yacc()</code>方法创建的分析器。你只需要简单的调用<code>parse()</code>，并将输入字符串作为参数就能运行分析器。它将运行所有的语法规则，并返回整个分析的结果，这个结果就是在起始规则中赋给<code>p[0]</code>的值。</p>%n<p>&nbsp;</p><a name="6_2"></a>%n<h4><font style="font-weight: bold">6.2 将语法规则合并</font></h4>%n<p>如果语法规则类似的话，可以合并到一个方法中。例如，考虑前面例子中的两个规则：</p><pre><code>def p_expression_plus(p):%n    'expression : expression PLUS term'%n    p[0] = p[1] + p[3]%n%ndef p_expression_minus(t):%n    'expression : expression MINUS term'%n    p[0] = p[1] - p[3]%n</code></pre>%n<p>比起写两个方法，你可以像下面这样写在一个方法里面：</p><pre><code>def p_expression(p):%n    '''expression : expression PLUS term%n                  | expression MINUS term'''%n    if p[2] == '+':%n        p[0] = p[1] + p[3]%n    elif p[2] == '-':%n        p[0] = p[1] - p[3]%n</code></pre>%n<p>总之，方法的文档字符串可以包含多个语法规则。所以，像这样写也是合法的（尽管可能会引起困惑）：</p><pre><code>def p_binary_operators(p):%n    '''expression : expression PLUS term%n                  | expression MINUS term%n       term       : term TIMES factor%n                  | term DIVIDE factor'''%n    if p[2] == '+':%n        p[0] = p[1] + p[3]%n    elif p[2] == '-':%n        p[0] = p[1] - p[3]%n    elif p[2] == '*':%n        p[0] = p[1] * p[3]%n    elif p[2] == '/':%n        p[0] = p[1] / p[3]%n</code></pre>%n<p>如果所有的规则都有相似的结构，那么将语法规则合并才是个不错的注意（比如，产生式的项数相同）。不然，语义动作可能会变得复杂。不过，简单情况下，可以使用len()方法区分，比如：<br></p><pre><code>def p_expressions(p):%n    '''expression : expression MINUS expression%n                  | MINUS expression'''%n    if (len(p) == 4):%n        p[0] = p[1] - p[3]%n    elif (len(p) == 3):%n        p[0] = -p[2]%n</code></pre>%n<p>如果考虑解析的性能，你应该避免像这些例子一样在一个语法规则里面用很多条件来处理。因为，每次检查当前究竟匹配的是哪个语法规则的时候，实际上重复做了分析器已经做过的事（分析器已经准确的知道哪个规则被匹配了）。为每个规则定义单独的方法，可以消除这点开销。</p>%n<p>&nbsp;</p><a name="6_3"></a>%n<h4><font style="font-weight: bold">6.3 字面字符</font></h4>%n<p>如果愿意，可以在语法规则里面使用单个的字面字符，例如：</p><pre><code>def p_binary_operators(p):%n    '''expression : expression '+' term%n                  | expression '-' term%n       term       : term '*' factor%n                  | term '/' factor'''%n    if p[2] == '+':%n        p[0] = p[1] + p[3]%n    elif p[2] == '-':%n        p[0] = p[1] - p[3]%n    elif p[2] == '*':%n        p[0] = p[1] * p[3]%n    elif p[2] == '/':%n        p[0] = p[1] / p[3]%n</code></pre>%n<p>字符必须像'+'那样使用单引号。除此之外，需要将用到的字符定义单独定义在lex文件的<code>literals</code>列表里：<br></p><pre><code>%h Literals.  Should be placed in module given to lex()%nliterals = ['+','-','*','/' ]%n</code></pre>%n<p><strong>字面的字符只能是单个字符</strong>。因此，像'&lt;='或者'=='都是不合法的，只能使用一般的词法规则（例如t_EQ = r'==')。</p>%n<p>&nbsp;</p><a name="6_4"></a>%n<h4><font style="font-weight: bold">6.4 空产生式</font></h4>%n<p>yacc.py可以处理空产生式，像下面这样做：</p><pre><code>def p_empty(p):%n    'empty :'%n    pass%n</code></pre>%n<p>现在可以使用空匹配，只要将'<code>empty</code>'当成一个符号使用：<br></p><pre><code>def p_optitem(p):%n    'optitem : item'%n    '        | empty'%n    ...%n</code></pre>%n<p>注意：你可以将产生式保持'空'，来表示空匹配。然而，我发现用一个'<code>empty</code>'规则并用其来替代'空'，更容易表达意图，并有较好的可读性。</p>%n<p>&nbsp;</p><a name="6_5"></a>%n<h4><font style="font-weight: bold">6.5 改变起始符号</font></h4>%n<p>默认情况下，在yacc中的第一条规则是起始语法规则（顶层规则）。可以用<code>start</code>标识来改变这种行为：</p><pre><code>start = 'foo'%n%ndef p_bar(p):%n    'bar : A B'%n%n%h This is the starting rule due to the start specifier above%ndef p_foo(p):%n    'foo : bar X'%n...%n</code></pre>%n<p>用<code>start</code>标识有助于在调试的时候将大型的语法规则分成小部分来分析。也可把start符号作为yacc的参数：</p><pre><code>yacc.yacc(start='foo')%n</code></pre>%n<p>&nbsp;</p><a name="6_6"></a>%n<h4><font style="font-weight: bold">6.6 处理二义文法</font></h4>%n<p>上面例子中，对表达式的文法描述用一种特别的形式规避了二义文法。然而，在很多情况下，这样的特殊文法很难写，或者很别扭。一个更为自然和舒服的语法表达应该是这样的：</p><pre><code>expression : expression PLUS expression%n           | expression MINUS expression%n           | expression TIMES expression%n           | expression DIVIDE expression%n           | LPAREN expression RPAREN%n           | NUMBER%n</code></pre>%n<p>不幸的是，这样的文法是存在二义性的。举个例子，如果你要解析字符串"3 * 4 + 5"，操作符如何分组并没有指明，究竟是表示"(3 * 4) + 5"还是"3 * (4 + 5)"呢？</p>%n<p>如果在yacc.py中存在二义文法，会输出"移进归约冲突"或者"归约归约冲突"。在分析器无法确定是将下一个符号移进栈还是将当前栈中的符号归约时会产生移进归约冲突。例如，对于"3 * 4 + 5"，分析器内部栈是这样工作的：</p><pre><code>Step Symbol Stack           Input Tokens            Action%n---- ---------------------  ---------------------   -------------------------------%n1    $                                3 * 4 + 5$    Shift 3%n2    $ 3                                * 4 + 5$    Reduce : expression : NUMBER%n3    $ expr                             * 4 + 5$    Shift *%n4    $ expr *                             4 + 5$    Shift 4%n5    $ expr * 4                             + 5$    Reduce: expression : NUMBER%n6    $ expr * expr                          + 5$    SHIFT/REDUCE CONFLICT ????%n</code></pre>%n<p>在这个例子中，当分析器来到第6步的时候，有两种选择：一是按照expr : expr * expr归约，一是将标记'+'继续移进栈。两种选择对于上面的上下文无关文法而言都是合法的。</p>%n<p>默认情况下，所有的移进归约冲突会倾向于使用移进来处理。因此，对于上面的例子，分析器总是会将'+'进栈，而不是做归约。虽然在很多情况下，这个策略是合适的（像"if-then"和"if-then-else"），但这对于算术表达式是不够的。事实上，对于上面的例子，将'+'进栈是完全错误的，应当先将expr * expr归约，因为乘法的优先级要高于加法。</p>%n<p>为了解决二义文法，尤其是对表达式文法，yacc.py允许为标记单独指定优先级和结合性。需要像下面这样增加一个precedence变量：</p><pre><code>precedence = (%n    ('left', 'PLUS', 'MINUS'),%n    ('left', 'TIMES', 'DIVIDE'),%n)%n</code></pre>%n<p>这样的定义说明<code>PLUS/MINUS</code>标记具有相同的优先级和左结合性，<code>TIMES/DIVIDE</code>具有相同的优先级和左结合性。在precedence声明中，标记的优先级从低到高。因此，这个声明表明<code>TIMES/DIVIDE</code>（他们较晚加入<code>precedence</code>）的优先级高于<code>PLUS/MINUS</code>。</p>%n<p>由于为标记添加了数字表示的优先级和结合性的属性，所以，对于上面的例子，将会得到：</p><pre><code>PLUS      : level = 1,  assoc = 'left'%nMINUS     : level = 1,  assoc = 'left'%nTIMES     : level = 2,  assoc = 'left'%nDIVIDE    : level = 2,  assoc = 'left'%n</code></pre>%n<p>随后这些值被附加到语法规则的优先级和结合性属性上，<strong>这些值由最右边的终结符的优先级和结合性决定</strong>：</p><pre><code>expression : expression PLUS expression                 %h level = 1, left%n           | expression MINUS expression                %h level = 1, left%n           | expression TIMES expression                %h level = 2, left%n           | expression DIVIDE expression               %h level = 2, left%n           | LPAREN expression RPAREN                   %h level = None (not specified)%n           | NUMBER                                     %h level = None (not specified)%n</code></pre>%n<p>当出现移进归约冲突时，分析器生成器根据下面的规则解决二义文法：</p>%n<ol>%n<li>如果当前的标记的优先级高于栈顶规则的优先级，移进当前标记 %n<li>如果栈顶规则的优先级更高，进行归约 %n<li>如果当前的标记与栈顶规则的优先级相同，如果标记是左结合的，则归约，否则，如果是右结合的则移进 %n<li>如果没有优先级可以参考，默认对于移进归约冲突执行移进</li></ol>%n<p>比如，当解析到"expression PLUS expression"这个语法时，下一个标记是<code>TIMES</code>，此时将执行移进，因为<code>TIMES</code>具有比<code>PLUS</code>更高的优先级；当解析到"expression TIMES expression"，下一个标记是<code>PLUS</code>，此时将执行归约，因为<code>PLUS</code>的优先级低于<code>TIMES</code>。</p>%n<p>如果在使用前三种技术解决已经归约冲突后，yacc.py将不会报告语法中的冲突或者错误（不过，会在parser.out这个调试文件中输出一些信息）</p>%n<p>使用<code>precedence</code>指定优先级的技术会带来一个问题，有时运算符的优先级需要基于上下文。例如，考虑"3 + 4 * -5"中的一元的'-'。数学上讲，一元运算符应当拥有较高的优先级。然而，在我们的<code>precedence</code>定义中，<code>MINUS</code>的优先级却低于<code>TIMES</code>。为了解决这个问题，<code>precedene</code>规则中可以包含"虚拟标记"：</p><pre><code>precedence = (%n    ('left', 'PLUS', 'MINUS'),%n    ('left', 'TIMES', 'DIVIDE'),%n    ('right', 'UMINUS'),            %h Unary minus operator%n)%n</code></pre>%n<p>在语法文件中，我们可以这么表示一元算符：</p><pre><code>def p_expr_uminus(p):%n    'expression : MINUS expression %pprec UMINUS'%n    p[0] = -p[2]%n</code></pre>%n<p>在这个例子中，<code>%pprec UMINUS</code>覆盖了默认的优先级（<code>MINUS</code>的优先级），将<code>UMINUS</code>指代的优先级应用在该语法规则上。</p>%n<p>起初，<code>UMINUS</code>标记的例子会让人感到困惑。<code>UMINUS</code>既不是输入的标记也不是语法规则，你应当将其看成<code>precedence</code>表中的特殊的占位符。当你使用<code>%pprec</code>宏时，你是在告诉yacc，你希望表达式使用这个占位符所表示的优先级，而不是正常的优先级。</p>%n<p>还可以在<code>precedence</code>表中指定"非关联"。这表明你不希望链式运算符。比如，假如你希望支持比较运算符'&lt;'和'&gt;'，但是你不希望支持 a &lt; b &lt; c，只要简单指定规则如下：<br></p><pre><code>precedence = (%n    ('nonassoc', 'LESSTHAN', 'GREATERTHAN'),  %h Nonassociative operators%n    ('left', 'PLUS', 'MINUS'),%n    ('left', 'TIMES', 'DIVIDE'),%n    ('right', 'UMINUS'),            %h Unary minus operator%n)%n</code></pre>%n<p><br>此时，当输入形如 a &lt; b &lt; c时，将产生语法错误，却不影响形如 a &lt; b 的表达式。</p>%n<p>&nbsp;</p>%n<p>对于给定的符号集，存在多种语法规则可以匹配时会产生归约/归约冲突。这样的冲突往往很严重，而且总是通过匹配最早出现的语法规则来解决。归约/归约冲突几乎总是相同的符号集合具有不同的规则可以匹配，而在这一点上无法抉择，比如：</p><pre><code>assignment :  ID EQUALS NUMBER%n           |  ID EQUALS expression%n           %nexpression : expression PLUS expression%n           | expression MINUS expression%n           | expression TIMES expression%n           | expression DIVIDE expression%n           | LPAREN expression RPAREN%n           | NUMBER%n</code></pre>%n<p>这个例子中，对于下面这两条规则将产生归约/归约冲突：</p><pre><code>assignment  : ID EQUALS NUMBER%nexpression  : NUMBER%n</code></pre>%n<p>比如，对于"a = 5"，分析器不知道应当按照assignment&nbsp; : ID EQUALS NUMBER归约，还是先将5归约成expression，再归约成assignment : ID EQUALS expression。</p>%n<p>应当指出的是，只是简单的查看语法规则是很难减少归约/归约冲突。如果出现归约/归约冲突，yacc()会帮助打印出警告信息：</p><pre><code>WARNING: 1 reduce/reduce conflict%nWARNING: reduce/reduce conflict in state 15 resolved using rule (assignment -&gt; ID EQUALS NUMBER)%nWARNING: rejected rule (expression -&gt; NUMBER)%n</code></pre>%n<p>上面的信息标识出了冲突的两条规则，但是，并无法指出究竟在什么情况下会出现这样的状态。想要发现问题，你可能需要结合语法规则和parser.out调试文件的内容。</p>%n<p>&nbsp;</p><a name="6_7"></a>%n<h4><font style="font-weight: bold">6.7 parser.out调试文件</font></h4>%n<p>使用LR分析算法跟踪移进/归约冲突和归约/归约冲突是件乐在其中的事。为了辅助调试，yacc.py在生成分析表时会创建出一个调试文件叫<code>parser.out</code>：</p><pre><code>Unused terminals:%n%n%nGrammar%n%nRule 1     expression -&gt; expression PLUS expression%nRule 2     expression -&gt; expression MINUS expression%nRule 3     expression -&gt; expression TIMES expression%nRule 4     expression -&gt; expression DIVIDE expression%nRule 5     expression -&gt; NUMBER%nRule 6     expression -&gt; LPAREN expression RPAREN%n%nTerminals, with rules where they appear%n%nTIMES                : 3%nerror                : %nMINUS                : 2%nRPAREN               : 6%nLPAREN               : 6%nDIVIDE               : 4%nPLUS                 : 1%nNUMBER               : 5%n%nNonterminals, with rules where they appear%n%nexpression           : 1 1 2 2 3 3 4 4 6 0%n%n%nParsing method: LALR%n%n%nstate 0%n%n    S' -&gt; . expression%n    expression -&gt; . expression PLUS expression%n    expression -&gt; . expression MINUS expression%n    expression -&gt; . expression TIMES expression%n    expression -&gt; . expression DIVIDE expression%n    expression -&gt; . NUMBER%n    expression -&gt; . LPAREN expression RPAREN%n%n    NUMBER          shift and go to state 3%n    LPAREN          shift and go to state 2%n%n%nstate 1%n%n    S' -&gt; expression .%n    expression -&gt; expression . PLUS expression%n    expression -&gt; expression . MINUS expression%n    expression -&gt; expression . TIMES expression%n    expression -&gt; expression . DIVIDE expression%n%n    PLUS            shift and go to state 6%n    MINUS           shift and go to state 5%n    TIMES           shift and go to state 4%n    DIVIDE          shift and go to state 7%n%n%nstate 2%n%n    expression -&gt; LPAREN . expression RPAREN%n    expression -&gt; . expression PLUS expression%n    expression -&gt; . expression MINUS expression%n    expression -&gt; . expression TIMES expression%n    expression -&gt; . expression DIVIDE expression%n    expression -&gt; . NUMBER%n    expression -&gt; . LPAREN expression RPAREN%n%n    NUMBER          shift and go to state 3%n    LPAREN          shift and go to state 2%n%n%nstate 3%n%n    expression -&gt; NUMBER .%n%n    $               reduce using rule 5%n    PLUS            reduce using rule 5%n    MINUS           reduce using rule 5%n    TIMES           reduce using rule 5%n    DIVIDE          reduce using rule 5%n    RPAREN          reduce using rule 5%n%n%nstate 4%n%n    expression -&gt; expression TIMES . expression%n    expression -&gt; . expression PLUS expression%n    expression -&gt; . expression MINUS expression%n    expression -&gt; . expression TIMES expression%n    expression -&gt; . expression DIVIDE expression%n    expression -&gt; . NUMBER%n    expression -&gt; . LPAREN expression RPAREN%n%n    NUMBER          shift and go to state 3%n    LPAREN          shift and go to state 2%n%n%nstate 5%n%n    expression -&gt; expression MINUS . expression%n    expression -&gt; . expression PLUS expression%n    expression -&gt; . expression MINUS expression%n    expression -&gt; . expression TIMES expression%n    expression -&gt; . expression DIVIDE expression%n    expression -&gt; . NUMBER%n    expression -&gt; . LPAREN expression RPAREN%n%n    NUMBER          shift and go to state 3%n    LPAREN          shift and go to state 2%n%n%nstate 6%n%n    expression -&gt; expression PLUS . expression%n    expression -&gt; . expression PLUS expression%n    expression -&gt; . expression MINUS expression%n    expression -&gt; . expression TIMES expression%n    expression -&gt; . expression DIVIDE expression%n    expression -&gt; . NUMBER%n    expression -&gt; . LPAREN expression RPAREN%n%n    NUMBER          shift and go to state 3%n    LPAREN          shift and go to state 2%n%n%nstate 7%n%n    expression -&gt; expression DIVIDE . expression%n    expression -&gt; . expression PLUS expression%n    expression -&gt; . expression MINUS expression%n    expression -&gt; . expression TIMES expression%n    expression -&gt; . expression DIVIDE expression%n    expression -&gt; . NUMBER%n    expression -&gt; . LPAREN expression RPAREN%n%n    NUMBER          shift and go to state 3%n    LPAREN          shift and go to state 2%n%n%nstate 8%n%n    expression -&gt; LPAREN expression . RPAREN%n    expression -&gt; expression . PLUS expression%n    expression -&gt; expression . MINUS expression%n    expression -&gt; expression . TIMES expression%n    expression -&gt; expression . DIVIDE expression%n%n    RPAREN          shift and go to state 13%n    PLUS            shift and go to state 6%n    MINUS           shift and go to state 5%n    TIMES           shift and go to state 4%n    DIVIDE          shift and go to state 7%n%n%nstate 9%n%n    expression -&gt; expression TIMES expression .%n    expression -&gt; expression . PLUS expression%n    expression -&gt; expression . MINUS expression%n    expression -&gt; expression . TIMES expression%n    expression -&gt; expression . DIVIDE expression%n%n    $               reduce using rule 3%n    PLUS            reduce using rule 3%n    MINUS           reduce using rule 3%n    TIMES           reduce using rule 3%n    DIVIDE          reduce using rule 3%n    RPAREN          reduce using rule 3%n%n  ! PLUS            [ shift and go to state 6 ]%n  ! MINUS           [ shift and go to state 5 ]%n  ! TIMES           [ shift and go to state 4 ]%n  ! DIVIDE          [ shift and go to state 7 ]%n%nstate 10%n%n    expression -&gt; expression MINUS expression .%n    expression -&gt; expression . PLUS expression%n    expression -&gt; expression . MINUS expression%n    expression -&gt; expression . TIMES expression%n    expression -&gt; expression . DIVIDE expression%n%n    $               reduce using rule 2%n    PLUS            reduce using rule 2%n    MINUS           reduce using rule 2%n    RPAREN          reduce using rule 2%n    TIMES           shift and go to state 4%n    DIVIDE          shift and go to state 7%n%n  ! TIMES           [ reduce using rule 2 ]%n  ! DIVIDE          [ reduce using rule 2 ]%n  ! PLUS            [ shift and go to state 6 ]%n  ! MINUS           [ shift and go to state 5 ]%n%nstate 11%n%n    expression -&gt; expression PLUS expression .%n    expression -&gt; expression . PLUS expression%n    expression -&gt; expression . MINUS expression%n    expression -&gt; expression . TIMES expression%n    expression -&gt; expression . DIVIDE expression%n%n    $               reduce using rule 1%n    PLUS            reduce using rule 1%n    MINUS           reduce using rule 1%n    RPAREN          reduce using rule 1%n    TIMES           shift and go to state 4%n    DIVIDE          shift and go to state 7%n%n  ! TIMES           [ reduce using rule 1 ]%n  ! DIVIDE          [ reduce using rule 1 ]%n  ! PLUS            [ shift and go to state 6 ]%n  ! MINUS           [ shift and go to state 5 ]%n%nstate 12%n%n    expression -&gt; expression DIVIDE expression .%n    expression -&gt; expression . PLUS expression%n    expression -&gt; expression . MINUS expression%n    expression -&gt; expression . TIMES expression%n    expression -&gt; expression . DIVIDE expression%n%n    $               reduce using rule 4%n    PLUS            reduce using rule 4%n    MINUS           reduce using rule 4%n    TIMES           reduce using rule 4%n    DIVIDE          reduce using rule 4%n    RPAREN          reduce using rule 4%n%n  ! PLUS            [ shift and go to state 6 ]%n  ! MINUS           [ shift and go to state 5 ]%n  ! TIMES           [ shift and go to state 4 ]%n  ! DIVIDE          [ shift and go to state 7 ]%n%nstate 13%n%n    expression -&gt; LPAREN expression RPAREN .%n%n    $               reduce using rule 6%n    PLUS            reduce using rule 6%n    MINUS           reduce using rule 6%n    TIMES           reduce using rule 6%n    DIVIDE          reduce using rule 6%n    RPAREN          reduce using rule 6%n</code></pre>%n<p>文件中出现的不同状态，代表了有效输入标记的所有可能的组合，这是依据文法规则得到的。当得到输入标记时，分析器将构造一个栈，并找到匹配的规则。每个状态跟踪了当前输入进行到语法规则中的哪个位置，在每个规则中，'.'表示当前分析到规则的哪个位置，而且，对于在当前状态下，输入的每个有效标记导致的动作也被罗列出来。当出现移进/归约或归约/归约冲突时，被忽略的规则前面会添加!，就像这样：<br></p><pre><code>! TIMES           [ reduce using rule 2 ]%n  ! DIVIDE          [ reduce using rule 2 ]%n  ! PLUS            [ shift and go to state 6 ]%n  ! MINUS           [ shift and go to state 5 ]%n</code></pre>%n<p>通过查看这些规则并结合一些实例，通常能够找到大部分冲突的根源。应该强调的是，不是所有的移进归约冲突都是不好的，想要确定解决方法是否正确，唯一的办法就是查看parser.out。<br></p>%n<p>&nbsp;</p><a name="6_8"></a>%n<h4><font style="font-weight: bold">6.8 处理语法错误</font><br></h4>%n<p>如果你创建的分析器用于产品，处理语法错误是很重要的。一般而言，你不希望分析器在遇到错误的时候就抛出异常并终止，相反，你需要它报告错误，尽可能的恢复并继续分析，一次性的将输入中所有的错误报告给用户。这是一些已知语言编译器的标准行为，例如C,C++,Java。在PLY中，在语法分析过程中出现错误，错误会被立即检测到（分析器不会继续读取源文件中错误点后面的标记）。然而，这时，分析器会进入恢复模式，这个模式能够用来尝试继续向下分析。LR分析器的错误恢复是个理论与技巧兼备的问题，yacc.py提供的错误机制与Unix下的yacc类似，所以你可以从诸如O'Reilly出版的《Lex and yacc》的书中找到更多的细节。</p>%n<p>当错误发生时，yacc.py按照如下步骤进行：</p>%n<ol>%n<li>第一次错误产生时，用户定义的<code>p_error()</code>方法会被调用，出错的标记会作为参数传入；如果错误是因为到达文件结尾造成的，传入的参数将为<code>None</code>。随后，分析器进入到“错误恢复”模式，该模式下不会在产生<code>p_error()</code>调用，直到它成功的移进3个标记，然后回归到正常模式。 %n<li>如果在<code>p_error()</code>中没有指定恢复动作的话，这个导致错误的标记会被替换成一个特殊的<code>error</code>标记。 %n<li>如果导致错误的标记已经是<code>error</code>的话，原先的栈顶的标记将被移除。 %n<li>如果整个分析栈被放弃，分析器会进入重置状态，并从他的初始状态开始分析。 %n<li>如果此时的语法规则接受<code>error</code>标记，<code>error</code>标记会移进栈。 %n<li>如果当前栈顶是<code>error</code>标记，之后的标记将被忽略，直到有标记能够导致<code>error</code>的归约。</li></ol>%n<p>&nbsp;</p><a name="6_8_1"></a>%n<h5><font style="font-weight: bold">6.8.1 根据error规则恢复和再同步</font><br></h5>%n<p>最佳的处理语法错误的做法是在语法规则中包含<code>error</code>标记。例如，假设你的语言有一个关于print的语句的语法规则：</p><pre><code>def p_statement_print(p):%n     'statement : PRINT expr SEMI'%n     ...%n</code></pre>%n<p>为了处理可能的错误表达式，你可以添加一条额外的语法规则：</p><pre><code>def p_statement_print_error(p):%n     'statement : PRINT error SEMI'%n     print "Syntax error in print statement. Bad expression"%n</code></pre>%n<p>这样（expr错误时），<code>error</code>标记会匹配任意多个分号之前的标记（分号是<code>SEMI</code>指代的字符）。一旦找到分号，规则将被匹配，这样<code>error</code>标记就被归约了。</p>%n<p>这种类型的恢复有时称为"分析器再同步"。<code>error</code>标记扮演了表示所有错误标记的通配符的角色，而紧随其后的标记扮演了同步标记的角色。</p>%n<p>重要的一个说明是，通常<code>error</code>不会作为语法规则的最后一个标记，像这样：</p><pre><code>def p_statement_print_error(p):%n    'statement : PRINT error'%n    print "Syntax error in print statement. Bad expression"%n</code></pre>%n<p>这是因为，第一个导致错误的标记会使得该规则立刻归约，进而使得在后面还有错误标记的情况下，恢复变得困难。</p>%n<p><br>&nbsp;</p><a name="6_8_2"></a>%n<h5><font style="font-weight: bold">6.8.2 悲观恢复模式</font></h5>%n<p>另一个错误恢复方法是采用“悲观模式”：该模式下，开始放弃剩余的标记，直到能够达到一个合适的恢复机会。</p>%n<p>悲观恢复模式都是在<code>p_error()</code>方法中做到的。例如，这个方法在开始丢弃标记后，直到找到闭合的'}'，才重置分析器到初始化状态：</p><pre><code>def p_error(p):%n    print "Whoa. You are seriously hosed."%n    %h Read ahead looking for a closing '}'%n    while 1:%n        tok = yacc.token()             %h Get the next token%n        if not tok or tok.type == 'RBRACE': break%n    yacc.restart()%n</code></pre>%n<p><br>下面这个方法简单的抛弃错误的标记，并告知分析器错误被接受了：<br></p><pre><code>def p_error(p):%n    print "Syntax error at token", p.type%n    %h Just discard the token and tell the parser it's okay.%n    yacc.errok()%n</code></pre>%n<p>在p_error()方法中，有三个可用的方法来控制分析器的行为：</p>%n<ul>%n<li><code>yacc.errok()</code> 这个方法将分析器从恢复模式切换回正常模式。这会使得不会产生<code>error</code>标记，并重置内部的<code>error</code>计数器，而且下一个语法错误会再次产生<code>p_error()</code>调用 %n<li><code>yacc.token()</code> 这个方法用于得到下一个标记 %n<li><code>yacc.restart()</code> 这个方法抛弃当前整个分析栈，并重置分析器为起始状态</li></ul>%n<p>注意：这三个方法只能在<code>p_error()</code>中使用，不能用在其他任何地方。</p>%n<p><code>p_error()</code>方法也可以返回标记，这样能够控制将哪个标记作为下一个标记返回给分析器。这对于需要同步一些特殊标记的时候有用，比如：</p><pre><code>def p_error(p):%n    %h Read ahead looking for a terminating ";"%n    while 1:%n        tok = yacc.token()             %h Get the next token%n        if not tok or tok.type == 'SEMI': break%n    yacc.errok()%n%n    %h Return SEMI to the parser as the next lookahead token%n    return tok%n</code></pre>%n<p>&nbsp;</p><a name="6_8_3"></a>%n<h5><font style="font-weight: bold">6.8.3 从产生式中抛出错误</font></h5>%n<p>如果有需要的话，产生式规则可以主动的使分析器进入恢复模式。这是通过抛出<code>SyntacError</code>异常做到的：</p><pre><code>def p_production(p):%n    'production : some production ...'%n    raise SyntaxError%n</code></pre>%n<p><code>raise SyntaxError</code>错误的效果就如同当前的标记是错误标记一样。因此，当你这么做的话，最后一个标记将被弹出栈，当前的下一个标记将是<code>error</code>标记，分析器进入恢复模式，试图归约满足<code>error</code>标记的规则。此后的步骤与检测到语法错误的情况是完全一样的，<code>p_error()</code>也会被调用。</p>%n<p>手动设置错误有个重要的方面，就是<code>p_error()</code>方法在这种情况下不会调用。如果你希望记录错误，确保在抛出<code>SyntaxError</code>错误的产生式中实现。</p>%n<p>注：这个功能是为了模仿yacc中的<code>YYERROR</code>宏的行为</p>%n<p>&nbsp;</p><a name="6_8_4"></a>%n<h5><font style="font-weight: bold">6.8.4 错误恢复总结</font><br></h5>%n<p>对于通常的语言，使用<code>error</code>规则和再同步标记可能是最合理的手段。这是因为你可以将语法设计成在一个相对容易恢复和继续分析的点捕获错误。悲观恢复模式只在一些十分特殊的应用中有用，这些应用往往需要丢弃掉大量输入，再寻找合理的同步点。</p>%n<p>&nbsp;</p><a name="6_9"></a>%n<h4><font style="font-weight: bold">6.9 行号和位置的跟踪</font></h4>%n<p>位置跟踪通常是个设计编译器时的技巧性玩意儿。默认情况下，PLY跟踪所有标记的行号和位置，这些信息可以这样得到：</p>%n<ul>%n<li>%n<p><code>p.lineno(num)</code>返回第num个符号的行号</p>%n<li>%n<p><code>p.lexpos(num)</code>返回第num个符号的词法位置偏移</p></li></ul>%n<p>例如：</p><pre><code>def p_expression(p):%n    'expression : expression PLUS expression'%n    p.lineno(1)        %h Line number of the left expression%n    p.lineno(2)        %h line number of the PLUS operator%n    p.lineno(3)        %h line number of the right expression%n    ...%n    start,end = p.linespan(3)    %h Start,end lines of the right expression%n    starti,endi = p.lexspan(3)   %h Start,end positions of right expression%n</code></pre>%n<p>注意：<code>lexspan()</code>方法只会返回的结束位置是最后一个符号的起始位置。</p>%n<p>虽然，PLY对所有符号的行号和位置的跟踪很管用，但经常是不必要的。例如，你仅仅是在错误信息中使用行号，你通常可以仅仅使用关键标记的信息，比如：</p><pre><code>def p_bad_func(p):%n    'funccall : fname LPAREN error RPAREN'%n    %h Line number reported from LPAREN token%n    print "Bad function call at line", p.lineno(2)%n</code></pre>%n<p>类似的，为了改善性能，你可以有选择性的将行号信息在必要的时候进行传递，这是通过<code>p.set_lineno()</code>实现的，例如：</p><pre><code>def p_fname(p):%n    'fname : ID'%n    p[0] = p[1]%n    p.set_lineno(0,p.lineno(1))%n</code></pre>%n<p>对于已经完成分析的规则，PLY不会保留行号信息，如果你是在构建抽象语法树而且需要行号，你应该确保行号保留在树上。</p>%n<p>&nbsp;</p><a name="6_10"></a>%n<h4><font style="font-weight: bold">6.10 构造抽象语法树</font></h4>%n<p>yacc.py没有构造抽像语法树的特殊方法。不过，你可以自己很简单的构造出来。</p>%n<p>一个最为简单的构造方法是为每个语法规则创建元组或者字典，并传递它们。有很多中可行的方案，下面是一个例子：</p><pre><code>def p_expression_binop(p):%n    '''expression : expression PLUS expression%n                  | expression MINUS expression%n                  | expression TIMES expression%n                  | expression DIVIDE expression'''%n%n    p[0] = ('binary-expression',p[2],p[1],p[3])%n%ndef p_expression_group(p):%n    'expression : LPAREN expression RPAREN'%n    p[0] = ('group-expression',p[2])%n%ndef p_expression_number(p):%n    'expression : NUMBER'%n    p[0] = ('number-expression',p[1])%n</code></pre>%n<p>另一种方法可以是为不同的抽象树节点创建一系列的数据结构，并赋值给<code>p[0]</code>：</p><pre><code>class Expr: pass%n%nclass BinOp(Expr):%n    def __init__(self,left,op,right):%n        self.type = "binop"%n        self.left = left%n        self.right = right%n        self.op = op%n%nclass Number(Expr):%n    def __init__(self,value):%n        self.type = "number"%n        self.value = value%n%ndef p_expression_binop(p):%n    '''expression : expression PLUS expression%n                  | expression MINUS expression%n                  | expression TIMES expression%n                  | expression DIVIDE expression'''%n%n    p[0] = BinOp(p[1],p[2],p[3])%n%ndef p_expression_group(p):%n    'expression : LPAREN expression RPAREN'%n    p[0] = p[2]%n%ndef p_expression_number(p):%n    'expression : NUMBER'%n    p[0] = Number(p[1])%n</code></pre>%n<p>这种方式的好处是在处理复杂语义时比较简单：类型检查、代码生成、以及其他针对树节点的功能。</p>%n<p>为了简化树的遍历，可以创建一个通用的树节点结构，例如：</p><pre><code>class Node:%n    def __init__(self,type,children=None,leaf=None):%n         self.type = type%n         if children:%n              self.children = children%n         else:%n              self.children = [ ]%n         self.leaf = leaf%n         %ndef p_expression_binop(p):%n    '''expression : expression PLUS expression%n                  | expression MINUS expression%n                  | expression TIMES expression%n                  | expression DIVIDE expression'''%n%n    p[0] = Node("binop", [p[1],p[3]], p[2])%n</code></pre>%n<p>&nbsp;</p><a name="6_11"></a>%n<h4><font style="font-weight: bold">6.11 嵌入式动作</font></h4>%n<p>yacc使用的分析技术只允许在规则规约后执行动作。假设有如下规则：<br></p><pre><code>def p_foo(p):%n    "foo : A B C D"%n    print "Parsed a foo", p[1],p[2],p[3],p[4]%n</code></pre>%n<p>方法只会在符号A,B,C和D都完成后才能执行。可是有的时候，在中间阶段执行一小段代码是有用的。假如，你想在A完成后立即执行一些动作，像下面这样用空规则：</p><pre><code>def p_foo(p):%n    "foo : A seen_A B C D"%n    print "Parsed a foo", p[1],p[3],p[4],p[5]%n    print "seen_A returned", p[2]%n%ndef p_seen_A(p):%n    "seen_A :"%n    print "Saw an A = ", p[-1]   %h Access grammar symbol to left%n    p[0] = some_value            %h Assign value to seen_A%n</code></pre>%n<p>在这个例子中，空规则<code>seen_A</code>将在A移进分析栈后立即执行。<code>p[-1]</code>指代的是在分析栈上紧跟在seen_A左侧的符号。在这个例子中，是A符号。像其他普通的规则一样，在嵌入式行为中也可以通过为<code>p[0]</code>赋值来返回某些值。</p>%n<p>使用嵌入式动作可能会导致移进归约冲突，比如，下面的语法是没有冲突的：</p><pre><code>def p_foo(p):%n    """foo : abcd%n           | abcx"""%n%ndef p_abcd(p):%n    "abcd : A B C D"%n%ndef p_abcx(p):%n    "abcx : A B C X"%n</code></pre>%n<p>可是，如果像这样插入一个嵌入式动作：</p><pre><code>def p_foo(p):%n    """foo : abcd%n           | abcx"""%n%ndef p_abcd(p):%n    "abcd : A B C D"%n%ndef p_abcx(p):%n    "abcx : A B seen_AB C X"%n%ndef p_seen_AB(p):%n    "seen_AB :"%n</code></pre>%n<p>会产生移进归约冲，只是由于对于两个规则abcd和abcx中的C，分析器既可以根据abcd规则移进，也可以根据abcx规则先将空的<code>seen_AB</code>归约。</p>%n<p>嵌入动作的一般用于分析以外的控制，比如为本地变量定义作用于。对于C语言：</p><pre><code>def p_statements_block(p):%n    "statements: LBRACE new_scope statements RBRACE"""%n    %h Action code%n    ...%n    pop_scope()        %h Return to previous scope%n%ndef p_new_scope(p):%n    "new_scope :"%n    %h Create a new scope for local variables%n    s = new_scope()%n    push_scope(s)%n    ...%n</code></pre>%n<p>在这个例子中，new_scope作为嵌入式行为，在左大括号<code>{</code>之后立即执行。可以是调正内部符号表或者其他方面。<code>statements_block</code>一完成，代码可能会撤销在嵌入动作时的操作（比如，pop_scope())<br>&nbsp;</p><a name="6_12"></a>%n<h4><font style="font-weight: bold">6.12 Yacc的其他</font></h4>%n<ul>%n<li>默认的分析方法是LALR，使用SLR请像这样运行 <code>yacc()：yacc.yacc(method="SLR")</code> 注意：LRLR生成的分析表大约要比SLR的大两倍。解析的性能没有本质的区别，因为代码是一样的。由于LALR能力稍强，所以更多的用于复杂的语法。 %n<li>默认情况下，yacc.py依赖lex.py产生的标记。不过，可以用一个等价的词法标记生成器代替： <code>yacc.parse(lexer=x)</code> 这个例子中，x必须是一个<code>Lexer</code>对象，至少拥有<code>x.token()</code>方法用来获取标记。如果将输入字串提供给<code>yacc.parse()</code>，lexer还必须具有<code>x.input()</code>方法。 %n<li>默认情况下，yacc在调试模式下生成分析表（会生成parser.out文件和其他东西），使用<code>yacc.yacc(debug=0)</code>禁用调试模式。 %n<li>改变parsetab.py的文件名：<code>yacc.yacc(tabmodule="foo") </code>%n<li>改变parsetab.py的生成目录：<code>yacc.yacc(tabmodule="foo",outputdir="somedirectory") </code>%n<li>不生成分析表：<code>yacc.yacc(write_tables=0)</code>。注意：如果禁用分析表生成，yacc()将在每次运行的时候重新构建分析表（这里耗费的时候取决于语法文件的规模） %n<li>想在分析过程中输出丰富的调试信息，使用：<code>yacc.parse(debug=1)</code> %n<li>yacc.yacc()方法会返回分析器对象，如果你想在一个程序中支持多个分析器： <pre><code>p = yacc.yacc()%n...%np.parse()%n</code></pre>注意：<code>yacc.parse()</code>方法只绑定到最新创建的分析器对象上。 %n<li>由于生成生成LALR分析表相对开销较大，先前生成的分析表会被缓存和重用。判断是否重新生成的依据是对所有的语法规则和优先级规则进行MD5校验，只有不匹配时才会重新生成。生成分析表是合理有效的办法，即使是面对上百个规则和状态的语法。对于复杂的编程语言，像C语言，在一些慢的机器上生成分析表可能要花费30-60秒，请耐心。 %n<li>由于LR分析过程是基于分析表的，分析器的性能很大程度上取决于语法的规模。最大的瓶颈可能是词法分析器和语法规则的复杂度。</li></ul>%n<p>&nbsp;</p><a name="7"></a>%n<h3><font style="font-weight: bold">7 多个语法和词法分析器</font></h3>%n<p>在高级的分析器程序中，你可能同时需要多个语法和词法分析器。</p>%n<p>依照规则行事不会有问题。不过，你需要小心确定所有东西都正确的绑定(hooked up)了。首先，保证将lex()和yacc()返回的对象保存起来：</p><pre><code>lexer  = lex.lex()       %h Return lexer object%nparser = yacc.yacc()     %h Return parser object</code></pre>%n<p>接着，在解析时，确保给<code>parse()</code>方法一个正确的lexer引用：</p><pre><code>parser.parse(text,lexer=lexer)</code></pre>%n<p>如果遗漏这一步，分析器会使用最新创建的lexer对象，这可能不是你希望的。</p>%n<p>词法器和语法器的方法中也可以访问这些对象。在词法器中，标记的lexer属性指代的是当前触发规则的词法器对象：</p><pre><code>def t_NUMBER(t):%n   r'\d+'%n   ...%n   print t.lexer           %h Show lexer object</code></pre>%n<p>在语法器中，lexer和parser属性指代的是对应的词法器对象和语法器对象</p><pre><code>def p_expr_plus(p):%n   'expr : expr PLUS expr'%n   ...%n   print p.parser          %h Show parser object%n   print p.lexer           %h Show lexer object</code></pre>%n<p>如果有必要，lexer对象和parser对象都可以附加其他属性。例如，你想要有不同的解析器状态，可以为为parser对象附加更多的属性，并在后面用到它们。</p>%n<p>&nbsp;</p><a name="8"></a>%n<h3><font style="font-weight: bold">8 使用Python的优化模式</font></h3>%n<p>由于PLY从文档字串中获取信息，语法解析和词法分析信息必须通过正常模式下的Python解释器得到（不带有-O或者-OO选项）。不过，如果你像这样指定<code>optimize</code>模式：</p><pre><code>lex.lex(optimize=1)%nyacc.yacc(optimize=1)</code></pre>%n<p>PLY可以在下次执行，在Python的优化模式下执行。但你必须确保第一次执行是在Python的正常模式下进行，一旦词法分析表和语法分析表生成一次后，在Python优化模式下执行，PLY会使用生成好的分析表而不再需要文档字串。</p>%n<p>注意：在优化模式下执行PLY会禁用很多错误检查机制。你应该只在程序稳定后，不再需要调试的情况下这样做。使用优化模式的目的应该是大幅减少你的编译器的启动时间（万事俱备只欠东风时）</p>%n<p>&nbsp;</p><a name="9"></a>%n<h3><font style="font-weight: bold">9 高级调试</font></h3>%n<p>调试一个编译器不是件容易的事情。PLY提供了一些高级的调试能力，这是通过Python的<code>logging</code>模块实现的，下面两节介绍这一主题：</p>%n<p>&nbsp;</p><a name="9_1"></a>%n<h4><font style="font-weight: bold">9.1 调试lex()和yacc()命令</font></h4>%n<p><code>lex()</code>和<code>yacc()</code>命令都有调试模式，可以通过debug标识实现：</p><pre><code>lex.lex(debug=True)%nyacc.yacc(debug=True)</code></pre>%n<p>正常情况下，调试不仅输出标准错误，对于yacc()，还会给出parser.out文件。这些输出可以通过提供logging对象来精细的控制。下面这个例子增加了对调试信息来源的输出：</p><pre><code>%h Set up a logging object%nimport logging%nlogging.basicConfig(%n    level = logging.DEBUG,%n    filename = "parselog.txt",%n    filemode = "w",%n    format = "%p(filename)10s:%p(lineno)4d:%p(message)s"%n)%nlog = logging.getLogger()%n%nlex.lex(debug=True,debuglog=log)%nyacc.yacc(debug=True,debuglog=log)</code></pre>%n<p>如果你提供一个自定义的logger，大量的调试信息可以通过分级来控制。典型的是将调试信息分为<code>DEBUG</code>,<code>INFO</code>,或者<code>WARNING</code>三个级别。</p>%n<p>PLY的错误和警告信息通过日志接口提供，可以从<code>errorlog</code>参数中传入日志对象</p><pre><code>lex.lex(errorlog=log)%nyacc.yacc(errorlog=log)</code></pre>%n<p>如果想完全过滤掉警告信息，你除了可以使用带级别过滤功能的日志对象，也可以使用lex和yacc模块都内建的<code>Nulllogger</code>对象。例如：</p><pre><code>yacc.yacc(errorlog=yacc.NullLogger())</code></pre>%n<p>&nbsp;</p><a name="9_2"></a>%n<h4><font style="font-weight: bold">9.2 运行时调试</font></h4>%n<p>为分析器指定debug选项，可以激活语法分析器的运行时调试功能。这个选项可以是整数（表示对调试功能是开还是关），也可以是logger对象。例如：</p><pre><code>log = logging.getLogger()%nparser.parse(input,debug=log)</code></pre>%n<p>如果传入日志对象的话，你可以使用其级别过滤功能来控制内容的输出。<code>INFO</code>级别用来产生归约信息；<code>DEBUG</code>级别会显示分析栈的信息、移进的标记和其他详细信息。<code>ERROR</code>级别显示分析过程中的错误相关信息。</p>%n<p>对于每个复杂的问题，你应该用日志对象，以便输出重定向到文件中，进而方便在执行结束后检查。</p>%n<p>&nbsp;</p><a name="10"></a>%n<h3><font style="font-weight: bold">10 如何继续</font></h3>%n<p>PLY分发包中的<code>example</code>目录包含几个简单的示例。对于理论性的东西以及LR分析发的实现细节，应当从编译器相关的书籍中学习。</p>%n<div class="table-responsive">%n<table class="table">%n<caption>一些翻译约定</caption>%n<tbody>%n<tr>%n<td>token</td>%n<td>标记</td></tr>%n<tr>%n<td>context free grammar</td>%n<td>上下文无关文法</td></tr>%n<tr>%n<td>syntax directed translation</td>%n<td>语法制导的翻译</td></tr>%n<tr>%n<td>ambiguity</td>%n<td>二义</td></tr>%n<tr>%n<td>terminals</td>%n<td>终结符</td></tr>%n<tr>%n<td>non-terminals</td>%n<td>非终结符</td></tr>%n<tr>%n<td>documentation string</td>%n<td>文档字符串（python中的_docstring_）</td></tr>%n<tr>%n<td>shift-reduce</td>%n<td>移进-归约</td></tr>%n<tr>%n<td>Empty Productions</td>%n<td>空产生式</td></tr>%n<tr>%n<td>Panic mode recovery</td>%n<td>悲观恢复模式</td></tr></tbody></table></div>#【译】Python Lex Yacc手册#postlayout#PLY是基于Python的lex和yacc实现，由David Beazley开发并维护。相比C语言版的lex和yacc，发挥了Python的语言特点，使得开发类似编译器或解释器变得更轻松。#Open-Source-Software-.jpg#[open-source]#[PLY,Python,Lex,Yacc]#2014-01-18 17:19:28#2014-01-20 09:57:13#
17#2014-01-21-52de149d84a8f.html#<div id="_52de149d84a8f"> <p>作为下决心学习css的程序员，暗自觉得bootstrap3的源码应该是很好的学习地方。之前一直对bootstrap如何实现栅格系统比较好奇，今天就进入到源码来看一下所谓的grid系统是怎么回事。</p> <p>bootstrap是用less编写的，在开始之前自然需要对less有一定的了解：<a href="http://www.lesscss.net/" target="_blank">LESSCSS中文网站</a></p> <p>本文参考的是bootstrap3.0.3版本的源码，转载请注明<a href="http://pchou.info/open-source/2014/01/21/52de149d84a8f.html" target="_blank">出处</a>  <p>PS:我的博客使用的<a href="https://github.com/isagalaev/highlight.js" target="_blank">highlight.js</a>语法高亮插件，在发布这篇文章之前还没有less的语法插件，但<a href="https://github.com/calvinjuarez/less.js" target="_blank">calvinjuarez</a>正在开发，所以暂时先用<a href="http://www.lesscss.org" target="_blank">lesscss.org</a>上的语法高亮和样式。</p> <p>&nbsp; <h3><font style="font-weight: bold">一些相关的css修正</font></h3> <p>栅格系统的基本前提是<strong>修正的盒子模型</strong>，这使得在有<code>padding</code>和<code>border</code>的情况下，计算宽度不至于出错 <pre><code class="no-highlight">// Reset the box-sizing%n%n*,%n*:before,%n*:after {%n  .box-sizing(border-box);%n}%n</code></pre>%n<p>由于栅格系统基于<code>float</code>布局，需要清除浮动，bootstrap中统一的清除浮动的方法如下： <pre><code class="no-highlight">// Clearfix%n// Source: http://nicolasgallagher.com/micro-clearfix-hack/%n//%n// For modern browsers%n// 1. The space content is one way to avoid an Opera bug when the%n//    contenteditable attribute is included anywhere else in the document.%n//    Otherwise it causes space to appear at the top and bottom of elements%n//    that are clearfixed.%n// 2. The use of `table` rather than `block` is only necessary if using%n//    `:before` to contain the top-margins of child elements.%n.clearfix() {%n  &amp;:before,%n  &amp;:after {%n    content: " "; // 1%n    display: table; // 2%n  }%n  &amp;:after {%n    clear: both;%n  }%n}%n</code></pre>%n<p>笔者不是资深前端，对于这种hack不甚理解，读者可根据注释自己理解 %n<p>&nbsp; <h3><font style="font-weight: bold">变量定义</font></h3>%n<p>首先，将分辨率划分为几个档，这些值作为不同设备的基本划分依据： <pre><code class="no-highlight">// Extra small screen / phone%n// Note: Deprecated @screen-xs and @screen-phone as of v3.0.1%n@screen-xs:                  480px;%n@screen-xs-min:              @screen-xs;%n@screen-phone:               @screen-xs-min;%n%n// Small screen / tablet%n// Note: Deprecated @screen-sm and @screen-tablet as of v3.0.1%n@screen-sm:                  768px;%n@screen-sm-min:              @screen-sm;%n@screen-tablet:              @screen-sm-min;%n%n// Medium screen / desktop%n// Note: Deprecated @screen-md and @screen-desktop as of v3.0.1%n@screen-md:                  992px;%n@screen-md-min:              @screen-md;%n@screen-desktop:             @screen-md-min;%n%n// Large screen / wide desktop%n// Note: Deprecated @screen-lg and @screen-lg-desktop as of v3.0.1%n@screen-lg:                  1200px;%n@screen-lg-min:              @screen-lg;%n@screen-lg-desktop:          @screen-lg-min;%n%n// So media queries don't overlap when required, provide a maximum%n@screen-xs-max:              (@screen-sm-min - 1);%n@screen-sm-max:              (@screen-md-min - 1);%n@screen-md-max:              (@screen-lg-min - 1);%n</code></pre>%n<p>我们都知道bootstrap栅格系统使用的总列数为12，列与列之间的宽度（列间宽）为30px（30px会被分为两部分，分别应用到相邻的两列）这是通过下面的变量定义的： <pre><code class="no-highlight">// Number of columns in the grid system%n@grid-columns:              12;%n// Padding, to be divided by two and applied to the left and right of all columns%n@grid-gutter-width:         30px;%n</code></pre>%n<p>下面两个变量是当有导航栏的时候，导航栏在屏幕的什么尺寸下，开始变成可伸缩状态，这两个变量跟导航有关，不在本文的讨论范围，只是带过： <pre><code class="no-highlight">// Point at which the navbar becomes uncollapsed%n@grid-float-breakpoint:     @screen-sm-min;%n// Point at which the navbar begins collapsing%n@grid-float-breakpoint-max: (@grid-float-breakpoint - 1);%n</code></pre>%n<p>&nbsp; <h3><font style="font-weight: bold">容器与行定义</font></h3>%n<p>栅格系统必须被用在<code>container</code>下，<code>container</code>被定义在<code>grid.less</code>中 <pre><code class="no-highlight">// Set the container width, and override it for fixed navbars in media queries%n.container {%n  .container-fixed();%n%n  @media (min-width: @screen-sm) {%n    width: @container-sm;%n  }%n  @media (min-width: @screen-md) {%n    width: @container-md;%n  }%n  @media (min-width: @screen-lg-min) {%n    width: @container-lg;%n  }%n}%n</code></pre>%n<p>其中我们关注一下<code>container-fixed()</code>混合： <pre><code class="no-highlight">// Centered container element%n.container-fixed() {%n  margin-right: auto;%n  margin-left: auto;%n  padding-left:  (@grid-gutter-width / 2);%n  padding-right: (@grid-gutter-width / 2);%n  .clearfix();%n}%n</code></pre>%n<p>margin的auto可以使得<code>contianer</code>在水平方向上居中，这里需要注意的是<code>container</code>对左右两个方向有列间宽<code>1/2</code>的<code>padding</code>，这一点在后面有对应的修正 %n<p>bootstrap的栅格系统需要基于<code>row</code>来定义行，<code>row</code>的定义如下： <pre><code class="no-highlight">// mobile first defaults%n.row {%n  .make-row();%n}%n%n// Creates a wrapper for a series of columns%n.make-row(@gutter: @grid-gutter-width) {%n  margin-left:  (@gutter / -2);%n  margin-right: (@gutter / -2);%n  .clearfix();%n}%n</code></pre>%n<p>这里的负数<code>margin</code>正是对上面<code>container</code>的<code>padding</code>的修正。现在，我们再来看看对<code>.container</code>的宽度的定义 <pre><code class="no-highlight">// Container sizes%n// --------------------------------------------------%n%n// Small screen / tablet%n@container-tablet:             ((720px + @grid-gutter-width));%n@container-sm:                 @container-tablet;%n%n// Medium screen / desktop%n@container-desktop:            ((940px + @grid-gutter-width));%n@container-md:                 @container-desktop;%n%n// Large screen / wide desktop%n@container-large-desktop:      ((1140px + @grid-gutter-width));%n@container-lg:                 @container-large-desktop;%n</code></pre>%n<p>可以看到，在<code>width</code>上，<code>container</code>的各个宽度都加上了一个列间宽<code>@grid-gutter-width</code> %n<p>&nbsp; <h3><font style="font-weight: bold">列定义</font></h3>%n<p>行定义好后，接着是重点，定义列。我们知道bootsctrap的列是通过类似<code>.col-xs-1</code>, <code>.col-sm-2</code>, <code>.col-md-4</code>, <code>.col-lg-1</code>...这样的class来指定的，class被分成4种分辨率，每种分辨率理论上可以有12个数字组合，这样，一共有48个类需要写，还要再加上pull,push,offset等区分，数量将很大。所以必须解决两个问题： %n<ol>%n<li>为了减少css文件的体积，必须尽可能的将可重用的属性提出来 %n<li>为了方便编码和维护方便，必须利用迭代来产生css</li></ol>%n<p>下面我们就来看看bootstrap是如何做的 %n<p>列的元素是<code>div</code>，有一些基本的属性需要提出来，它们是： <pre><code class="no-highlight">//指定为相对位置，结合将来的left和right，是为了实现pull和push功能%nposition: relative;%n// 使div不至于因为没有内容而收缩%nmin-height: 1px;%n// 列宽被分成两部分，分别用在左padding和右padding，这样相邻的列的列间宽就是@grid-gutter-width了%npadding-left:  (@grid-gutter-width / 2);%npadding-right: (@grid-gutter-width / 2);%n</code></pre>%n<p>将这些基本属性应用到48个类上，需要使用迭代，bootsctrap是利用<code>递归</code>来实现迭代的，看下面的代码： <pre><code class="no-highlight">.make-grid-columns() {%n  // Common styles for all sizes of grid columns, widths 1-12%n  .col(@index) when (@index = 1) { // initial%n    @item: ~".col-xs-@{index}, .col-sm-@{index}, .col-md-@{index}, .col-lg-@{index}";%n    .col(@index + 1, @item);%n  }%n  .col(@index, @list) when (@index =&lt; @grid-columns) { // general; "=&lt;" isn't a typo%n    @item: ~".col-xs-@{index}, .col-sm-@{index}, .col-md-@{index}, .col-lg-@{index}";%n    .col(@index + 1, ~"@{list}, @{item}");%n  }%n  .col(@index, @list) when (@index &gt; @grid-columns) { // terminal%n    @{list} {%n      position: relative;%n      // Prevent columns from collapsing when empty%n      min-height: 1px;%n      // Inner gutter via padding%n      padding-left:  (@grid-gutter-width / 2);%n      padding-right: (@grid-gutter-width / 2);%n    }%n  }%n  .col(1); // kickstart it%n}%n</code></pre>%n<p>在这个闭包（姑且称为闭包）中定义了<code>col</code>混合，迭代的要素是列号@index(1~12)，<code>col</code>需要处理迭代要素的三种情况；在迭代的过程中，将每次的结果保存在@item字符串中，并不断的增加@item中的内容，直到@index超过@grid-columns。在这段代码中，我们可以学习到混合的递归迭代，注释的使用等less技巧。最后的输出结果将是： <pre><code>.col-xs-1,.col-sm-1,.col-md-1,.col-lg-1,%n.col-xs-2,.col-sm-2,.col-md-2,.col-lg-2,%n.col-xs-3,.col-sm-3,.col-md-3,.col-lg-3,%n.col-xs-4,.col-sm-4,.col-md-4,.col-lg-4,%n.col-xs-5,.col-sm-5,.col-md-5,.col-lg-5,%n.col-xs-6,.col-sm-6,.col-md-6,.col-lg-6,%n.col-xs-7,.col-sm-7,.col-md-7,.col-lg-7,%n.col-xs-8,.col-sm-8,.col-md-8,.col-lg-8,%n.col-xs-9,.col-sm-9,.col-md-9,.col-lg-9,%n.col-xs-10,.col-sm-10,.col-md-10,.col-lg-10,%n.col-xs-11,.col-sm-11,.col-md-11,.col-lg-11,%n.col-xs-12,.col-sm-12,.col-md-12,.col-lg-12 %n{%n  position: relative;%n  min-height: 1px;%n  padding-right: 15px;%n  padding-left: 15px;%n}%n</code></pre>%n<p>无论是xs,sm,md还是lg，都是在针对特定的媒体查询定义的，这里只有一个例外就是xs，xs不是定义在媒体查询中的。这个含义就是：除非尺寸大于<code>@screen-sm-min</code>时sm,md,lg的相关属性才会生效，否则像定义了sm,md,lg的div列只能是默认行为（默认width:100%p,成为堆叠）。&nbsp; 也就是说，bootstrap3从这个层面看，正是所谓的“移动设备优先的“。 %n<p>完成公共属性的提取后，需要针对不同的分辨率来生成不多的样式和属性，grid.less中的代码如下： <pre><code class="no-highlight">// Extra small grid%n//%n// Columns, offsets, pushes, and pulls for extra small devices like%n// smartphones.%n%n.make-grid-columns-float(xs);%n.make-grid(@grid-columns, xs, width);%n.make-grid(@grid-columns, xs, pull);%n.make-grid(@grid-columns, xs, push);%n.make-grid(@grid-columns, xs, offset);%n%n%n// Small grid%n//%n// Columns, offsets, pushes, and pulls for the small device range, from phones%n// to tablets.%n%n@media (min-width: @screen-sm-min) {%n  .make-grid-columns-float(sm);%n  .make-grid(@grid-columns, sm, width);%n  .make-grid(@grid-columns, sm, pull);%n  .make-grid(@grid-columns, sm, push);%n  .make-grid(@grid-columns, sm, offset);%n}%n%n%n// Medium grid%n//%n// Columns, offsets, pushes, and pulls for the desktop device range.%n%n@media (min-width: @screen-md-min) {%n  .make-grid-columns-float(md);%n  .make-grid(@grid-columns, md, width);%n  .make-grid(@grid-columns, md, pull);%n  .make-grid(@grid-columns, md, push);%n  .make-grid(@grid-columns, md, offset);%n}%n%n%n// Large grid%n//%n// Columns, offsets, pushes, and pulls for the large desktop device range.%n%n@media (min-width: @screen-lg-min) {%n  .make-grid-columns-float(lg);%n  .make-grid(@grid-columns, lg, width);%n  .make-grid(@grid-columns, lg, pull);%n  .make-grid(@grid-columns, lg, push);%n  .make-grid(@grid-columns, lg, offset);%n}%n</code></pre>%n<p>上面的代码调用了很多mix，用来生成不同媒体分辨率下的class样式，我们先姑且放下这些mix调用。bootstrap栅格系统的列一共支持4中模式，模式可以组合使用： %n<ol>%n<li><code>width</code>模式（默认），是指将一个row按照比重划分为不同的列宽，通过设置<code>width</code>为百分比实现。例如<code>.col-xs-6 { width:50%p }</code> %n<li><code>pull</code>模式，将列相对row的右边向左偏移，通过设置<code>right</code>为百分比实现（列本身已经是<code>relative</code>定位的了）。例如<code>.col-xs-pull-6 { right:50%p }</code> %n<li><code>push</code>模式，将列相对row的左边向右偏移，通过设置<code>left</code>为百分比实现（列本身已经是<code>relative</code>定位的了）。例如<code>.col-xs-push-6 { left:50%p }</code> %n<li><code>offset</code>模式，将列相对其左边元素向右偏移，通过设置<code>margin-left</code>为百分比的实现。例如<code>.col-xs-offset-6 { margin-left:50%p }</code></li></ol>%n<p>下面我们以xs的分辨率为例子来解析上面的代码，其他分辨率下的其实是完全一样的： <pre><code class="no-highlight">.make-grid-columns-float(xs);%n.make-grid(@grid-columns, xs, width);%n.make-grid(@grid-columns, xs, pull);%n.make-grid(@grid-columns, xs, push);%n.make-grid(@grid-columns, xs, offset);%n</code></pre>%n<p><code>.make-grid-columns-float</code>是设置.col-xs-{1-12}为左浮动，这是必须的，也是列div能够横排和自动换行的关键所在，我们来看看<code>.make-grid-columns-float</code>混合的代码： <pre><code class="no-highlight">.make-grid-columns-float(@class) {%n  .col(@index) when (@index = 1) { // initial%n    @item: ~".col-@{class}-@{index}";%n    .col(@index + 1, @item);%n  }%n  .col(@index, @list) when (@index =&lt; @grid-columns) { // general%n    @item: ~".col-@{class}-@{index}";%n    .col(@index + 1, ~"@{list}, @{item}");%n  }%n  .col(@index, @list) when (@index &gt; @grid-columns) { // terminal%n    @{list} {%n      float: left;%n    }%n  }%n  .col(1); // kickstart it%n}%n</code></pre>%n<p>这段代码跟上面<code>make-grid-columns</code>思想完全一样，这里就不解释了。唯一的不同点在于，传入的参数<code>@class</code>是xs,sm,md,lg中的一个。生成的代码将是：<pre><code>.col-xs-1,%n.col-xs-2,%n.col-xs-3,%n.col-xs-4,%n.col-xs-5,%n.col-xs-6,%n.col-xs-7,%n.col-xs-8,%n.col-xs-9,%n.col-xs-10,%n.col-xs-11,%n.col-xs-12 {%n  float: left;%n}%n</code></pre>%n<p>接下来的<code>.make-grid</code>是个通用混合，作用是根据<code>@index</code>输出某个分辨率<code>@class</code>(xs,sm,md,lg)下的某个属性<code>@type</code>的样式： <pre><code class="no-highlight">.calc-grid(@index, @class, @type) when (@type = width) and (@index &gt; 0) {%n  .col-@{class}-@{index} {%n    width: percentage((@index / @grid-columns));%n  }%n}%n.calc-grid(@index, @class, @type) when (@type = push) {%n  .col-@{class}-push-@{index} {%n    left: percentage((@index / @grid-columns));%n  }%n}%n.calc-grid(@index, @class, @type) when (@type = pull) {%n  .col-@{class}-pull-@{index} {%n    right: percentage((@index / @grid-columns));%n  }%n}%n.calc-grid(@index, @class, @type) when (@type = offset) {%n  .col-@{class}-offset-@{index} {%n    margin-left: percentage((@index / @grid-columns));%n  }%n}%n%n// Basic looping in LESS%n.make-grid(@index, @class, @type) when (@index &gt;= 0) {%n  .calc-grid(@index, @class, @type);%n  // next iteration%n  .make-grid(@index - 1, @class, @type);%n}%n</code></pre>%n<p>可以看到还是递归的迭代思想，针对四种模式，分别有四个子混合来输出属性，利用Less的<code>percentage</code>函数将计算值转化成百分比，比如当index迭代到6的时候，percentage(6/12)是50%p。需要注意的是针对<code>width</code>模式是没有<code>@index</code>为<code>0</code>的情况的，而且输出的class没有类似width的字眼，其他三种模式有针对0的输出，而且class有相应模式的字眼。 %n<p>此时在调用端调用.make-grid(@grid-columns, xs, width);将生成：<pre><code>.col-xs-12 {%n  width: 100%p;%n}%n%n.col-xs-11 {%n  width: 91.66666666666666%p;%n}%n%n.col-xs-10 {%n  width: 83.33333333333334%p;%n}%n%n.col-xs-9 {%n  width: 75%p;%n}%n%n.col-xs-8 {%n  width: 66.66666666666666%p;%n}%n%n.col-xs-7 {%n  width: 58.333333333333336%p;%n}%n%n.col-xs-6 {%n  width: 50%p;%n}%n...%n</code></pre>%n<p>其他的调用和结果就不一一分析了，几乎一样。 %n<p>至此，gird系统的源码就分析完了，其实挺简单的，收获是什么：</p>%n<ol>%n<li>笔者初学css，在行布局上，对<code>display:inline-block;</code>情有独钟，看了大师们的手笔，发现float还是更通用些 %n<li>比之前对less的理解更多了一些，尤其是可以巧妙的通过递归来实现迭代 %n<li>bootstrap在设计上经过有效的模块化和层次化，使得可维护性和可复用性更好，值得学习</li></ol></div>#bootstrap3栅格系统源码学习#postlayout#通过对bootstrap源码的学习，加深了对less的了解，也学习到了一些css的设计模式。本文分析bootstrap的grid系统的源码#Open-Source-Software-.jpg#[open-source]#[bootstrap,grid]#2014-01-21 14:33:01#2014-01-23 15:59:03#